---
title: "√âtudes qualitatives sur le web (netnographie)"
subtitle: "Analyse de sentiment et opinions"
author:
  - name: "Olivier Caron"
    affiliations: "Paris Dauphine - PSL"
format:
  ubd-revealjs:
    self-contained: false
    chalkboard: true
    transition: fade
    auto-stretch: false
    width: 1250
    height: 760
    toc: false
    toc-depth: 1
    code-block-height: 700px
execute:
  echo: true
bibliography: refs.bib
revealjs-plugins:
  - editable
filters:
  - editable
editor: 
  markdown: 
    wrap: 72
---

------------------------------------------------------------------------

## Objectifs du cours {style="font-size:0.75em"}

::::: columns
::: {.column width="50%"}
**1. Comprendre et mod√©liser les opinions**

-   D√©finir et distinguer **opinion**, **subjectivit√©** et **polarit√©**.
-   Ma√Ætriser les **niveaux d'analyse** (document, phrase, aspect) et
    leur pertinence marketing.
-   Identifier les **ph√©nom√®nes linguistiques** qui influencent le
    sentiment (n√©gation, intensit√©, "mais"...).

\
\

**2. Ma√Ætriser les approches classiques**

\
\

-   Appliquer des m√©thodes bas√©es sur des **lexiques** et des
    **r√®gles**.
-   Comprendre comment **adapter un lexique** √† un domaine sp√©cifique
    (induction *corpus-based*).
    
:::

::: {.column width="50%"}
**3. Comprendre le Machine Learning pour l'analyse de sentiment**

-   Comprendre les principes des apprentissages **supervis√©** et **non
    supervis√©**.
-   Distinguer le **ML "classique"** (Naive Bayes, SVM) du **Deep
    Learning / Transfer Learning**.
-   Conna√Ætre les avantages et les limites de chaque grande famille de
    mod√®les.

**4. Comprendre et mettre en oeuvre une d√©marche rigoureuse**

\

-   Concevoir un **sch√©ma d'annotation** clair et fiable.
-   Mesurer la qualit√© des donn√©es avec l'**accord inter-annotateurs
    (IAA)**.
-   **√âvaluer** un syst√®me avec les bonnes m√©triques (**F1-macro**) en
    √©vitant les pi√®ges (d√©s√©quilibre des classes).
    
:::
:::::

------------------------------------------------------------------------

## Qu‚Äôest-ce qu‚Äôune opinion ? Le mod√®le structur√© de Liu {style="font-size:0.80em"}

En analyse de sentiment, une opinion n'est pas qu'un simple "j'aime" ou
"je n'aime pas". Pour √™tre analysable, Bing Liu, l'un des pionniers du
domaine, la mod√©lise comme un objet structur√©, le **quintuple**
[@liuSentimentAnalysisOpinion, p. 19].

\

$$(e_i, a_{ij}, s_{ijkl}, h_k, t_l)$$\

-   **Entit√© (**$e_i$) : le produit, la marque, le service. *Ex: "iPhone
    15"*.
-   **Aspect (**$a_{ij}$) : une caract√©ristique sp√©cifique de l'entit√©.
    *Ex: "batterie", "qualit√© photo"*. Si l'opinion vise l'entit√©
    enti√®re, on utilise l'aspect **GENERAL**.
-   **Sentiment (**$s_{ijkl}$) : la polarit√© (+, 0, -) et/ou son
    intensit√©. *Ex: "tr√®s positif"*.
-   **Holder (**$h_k$) : la source de l'opinion. *Ex: "l'auteur du
    tweet", "le journaliste"*.
-   **Temps (**$t_l$) : la date de publication. Essentiel pour suivre
    les tendances.

------------------------------------------------------------------------

## Explicite vs. Implicite : lire entre les lignes {style="font-size:0.85em"}

Toutes les opinions ne sont pas exprim√©es de la m√™me mani√®re. La
distinction entre opinion explicite et implicite est cruciale car elle
d√©termine la difficult√© de l'analyse [@liuSentimentAnalysisOpinion, p.
26].

::::: columns
::: {.column width="50%"}
### **Opinion explicite**

C'est une **d√©claration subjective** qui utilise des mots de sentiment
clairs.

-   *"La batterie de ce t√©l√©phone est **excellente**."*
-   *"Je **d√©teste** le nouveau design."*
-   *"Le service client √©tait **d√©cevant**."*

**Facilit√©** : relativement simple √† d√©tecter avec des lexiques de mots
positifs/n√©gatifs.
:::

::: {.column width="50%"}
### **Opinion implicite**

C'est un **√©nonc√© factuel** qui, dans un contexte donn√©, implique une
opinion forte.

-   *"La batterie de ce t√©l√©phone **tient √† peine la journ√©e**."* (fait
    ind√©sirable ‚Üí opinion n√©gative)
-   *"J'ai d√ª **red√©marrer l'ordinateur trois fois** ce matin."* (fait
    ind√©sirable ‚Üí opinion n√©gative)
-   *"Le colis est **arriv√© en 24h**."* (fait d√©sirable ‚Üí opinion
    positive)

**Difficult√©** : beaucoup plus complexe √† d√©tecter. N√©cessite une
connaissance du domaine et des attentes des consommateurs.
:::
:::::

------------------------------------------------------------------------

## Subjectivit√©, polarit√© et valence {style="font-size:0.75em"}

Le langage des opinions a plusieurs facettes. Il est essentiel de distinguer si un texte exprime un point de vue (*subjectivit√©*) et si ce point de vue est positif ou n√©gatif (*polarit√©* ou *valence*) [@pangOpinionMiningSentiment, p. 5].

-   **Subjectivit√©** : c'est la pr√©sence d'un **√©tat priv√©** de l'auteur (croyance, jugement, sp√©culation) par opposition √† un **fait objectif** v√©rifiable.
    -   **Subjectif** : *"Je pense que ce film va plaire."*
    -   **Objectif** : *"Le film est sorti hier."*

-   **Polarit√© (ou valence)** : c'est l'**orientation** de l'opinion (+, -, 0). Le terme **valence**, issu de la psychologie, est souvent utilis√© pour d√©crire cette qualit√© intrins√®quement positive ou n√©gative d'un mot ou d'une expression.
    -   **Subjectif SANS polarit√© claire** : *"Je me demande si ce produit est fiable."*
    -   **Subjectif AVEC polarit√©** : *"Ce produit est incroyablement fiable."* (valence positive)

-   **Polarit√© (ou valence) contextuelle** : la polarit√© d'un mot n'est pas fixe ; elle d√©pend crucialement de son contexte. Les **n√©gations**, **intensificateurs** ou m√™me l'**aspect** concern√© peuvent tout changer.
    - *"long"* ‚Üí valence positive pour une batterie, valence n√©gative pour un temps d'attente.

::: {.callout-note title="Pourquoi cette distinction est-elle importante ?"}
La plupart des syst√®mes d'analyse de sentiment fonctionnent en deux √©tapes : d'abord, ils filtrent les phrases pour ne garder que les **subjectives**, puis ils d√©terminent la **polarit√©/valence** de ces derni√®res.
:::


------------------------------------------------------------------------

## Les niveaux d'analyse : quelle question se pose-t-on ? {style="font-size:0.72em"}

L'analyse de sentiment peut √™tre men√©e √† diff√©rentes √©chelles. Chaque
"granularit√©" r√©pond √† un besoin marketing diff√©rent
[@liuSentimentAnalysisOpinion, p. 10-11].

::::: columns
::: {.column width="50%"}
### **Document-level**

On analyse un texte entier (un avis, un article) pour en extraire un
sentiment global.

-   **Question m√©tier** : *"Quel est le score de satisfaction moyen de
    notre produit sur Amazon ?"*
-   **Limite** : tr√®s r√©ducteur. Un avis 3 √©toiles peut contenir des
    critiques tr√®s pr√©cises et des compliments sur d'autres aspects.

### **Sentence-level**

\

On analyse chaque phrase ind√©pendamment pour d√©terminer si elle est
subjective et quelle est sa polarit√©.

\

-   **Question m√©tier** : *"Quels sont les verbatims clients les plus
    percutants (positifs ou n√©gatifs) √† faire remonter en r√©union ?"*
-   **Limite** : une m√™me phrase peut contenir plusieurs opinions. *"Le
    design est super mais la batterie est nulle."*
:::

::: {.column width="50%"}
### **Aspect-level (ABSA)**

C'est le niveau le plus fin et le plus utile. On identifie les
**aspects** sp√©cifiques et on leur attribue une polarit√©.

-   **Question m√©tier** : *"Quels sont les **points forts et les points
    faibles** de notre produit ? Sur quoi devons-nous concentrer nos
    efforts R&D et marketing ?"*
-   **Avantage** : fournit des insights tr√®s **actionnables**.

\
\

### **Opinions Comparatives**

\

On analyse les phrases qui comparent plusieurs entit√©s sur un m√™me
aspect.

\

-   **Question m√©tier** : *"Comment notre produit se positionne-t-il
    face √† notre principal concurrent sur l'aspect 'prix' ou 'qualit√©'
    aux yeux des consommateurs ?"*
-   **Avantage** : le c≈ìur de l'**intelligence concurrentielle**.
:::
:::::

## Les ph√©nom√®nes linguistiques et leurs effets

::::: columns
::: {.column width="50%" style="font-size:0.75em"}
### **"Valence Shifters"** : n√©gation & intensit√©

-   **N√©gation** : inverse la polarit√© d'un mot (*pas bon*). La
    **port√©e** (scope) est cruciale : "Ce n'est pas bon, c'est
    excellent" ‚Üí la n√©gation ne s'applique qu'√† "bon".
-   **Intensificateurs** : augmentent la force (*tr√®s, vraiment,
    extr√™mement*).
-   **Att√©nuateurs** : diminuent la force (*un peu, l√©g√®rement*).

### **Connecteurs** : "Mais" et "Et"

-   **Adversatifs ("mais", "cependant")** : signalent un retournement.
    La r√®gle d'or est que l'opinion **apr√®s le "mais"** est la plus
    importante.
    -   *"Le design est super, **mais la batterie est nulle**."* ‚Üí avis
        globalement n√©gatif.
-   **Additifs ("et")** : tendent √† aligner des opinions de m√™me
    polarit√©.
    -   *"L√©ger **et** pratique."* ‚Üí deux aspects positifs.
:::

::: {.column width="50%" style="font-size:0.8em"}
### **Conditionnels & Modaux**

-   **Expriment une possibilit√©, pas une r√©alit√©** (*"Le service
    **pourrait** √™tre meilleur."*).
-   Ils **affaiblissent** l'opinion. Ce n'est pas une critique aussi
    ferme que *"Le service est mauvais."*

\
\

### **Implicites & Ironie**

-   **Implicite** : opinion cach√©e dans un fait.
    -   *"Le t√©l√©phone chauffe apr√®s 10 min."* ‚Üí fait objectif, mais
        opinion n√©gative implicite sur l'aspect *performance*.
-   **Ironie/Sarcasme** : dire le contraire de ce que l'on pense.
    -   *"Super, ma commande est encore arriv√©e en retard."* ‚Üí mots
        positifs, mais sentiment tr√®s n√©gatif. C'est le d√©fi le plus
        complexe de l'analyse.
:::
:::::

------------------------------------------------------------------------

## M√©thodes d'analyse classiques

::::: columns
::: {.column width="50%" style="font-size:0.7em"}
### **Approche par lexiques (dictionnaires)**

-   **Principe** : on attribue un score √† chaque mot (+1 pour "bon", -1
    pour "mauvais") et on fait la somme, ajust√©e par des **r√®gles de
    composition** (n√©gation, "mais"...).
-   **Construction de lexique** :
    -   **Dictionary-based** : on part de quelques mots et on √©tend avec
        des synonymes/antonymes.
    -   **Corpus-based** : on "d√©couvre" la polarit√© des mots en
        regardant avec quels autres mots ils apparaissent dans un grand
        corpus de textes (ex: PMI).

### **ABSA (Aspect-Based Sentiment Analysis)**

C'est l'approche la plus **actionnable** pour le marketing.

-   **Pipeline** :
    1.  **Extraire les aspects** dont les gens parlent (ex: "batterie",
        "√©cran", "prix").
    2.  **Lier l'opinion √† l'aspect** (ex: "excellent" ‚Üí "√©cran").
    3.  **Calculer la polarit√© pour chaque aspect**.
-   **R√©sultat** : une carte des points forts et faibles du produit.
:::

::: {.column width="50%" style="font-size:0.8em"}
### **Opinions comparatives**

-   **Objectif** : analyser les phrases qui comparent des entit√©s.
    -   *"La batterie de l'iPhone **dure plus longtemps que** celle du
        Samsung."*
-   **Extraction** : on identifie les deux entit√©s compar√©es (E1, E2),
    l'aspect de comparaison (A) et surtout, l'**entit√© pr√©f√©r√©e** (PE).
:::
:::::

------------------------------------------------------------------------

## Deux approches pour automatiser l'analyse : ML vs Deep Learning

![](images/clipboard-2246092486.png){fig-align="center" width="60%"}

::::: columns
::: {.column width="50%" style="font-size:0.478em"}
###  **Machine Learning "Classique"**

-   **Principe** : l'humain choisit et pr√©pare les *features*
    (caract√©ristiques) pertinentes du texte (ex: la pr√©sence de certains
    mots, des bigrammes...). C'est une √©tape de **feature extraction**
    manuelle.
-   **Le mod√®le apprend** √† associer ces *features* pr√©par√©es √† un
    sentiment (positif/n√©gatif).
-   **Analogie** : on pr√©pare les ingr√©dients (features) pour le chef
    (mod√®le) qui n'a plus qu'√† cuisiner.
:::

::: {.column width="50%" style="font-size:0.5em"}
### **Deep Learning**

-   **Principe** : le mod√®le apprend **directement √† partir des mots
    bruts**. Il d√©couvre lui-m√™me les *features* importantes dans ses
    couches cach√©es (*hidden layers*). L'√©tape de **feature extraction**
    est automatique.
-   **Le mod√®le apprend** des repr√©sentations complexes du langage
    (embeddings).
-   **Analogie** : on donne les produits bruts au chef (mod√®le) et il se
    charge de tout, de la d√©coupe √† la cuisson.
:::
:::::

::: {.callout-tip title="A retenir"}
Le **Deep Learning** automatise plus de t√¢ches et peut capturer des
relations plus complexes, ce qui conduit souvent √† de meilleures
performances [@hartmannMoreFeelingAccuracy2023]. C'est la base des
mod√®les les plus r√©cents.
:::

------------------------------------------------------------------------

## Transition : les limites des approches par lexiques {style="font-size:0.7em"}

Les m√©thodes par lexiques et r√®gles sont transparentes et rapides, mais
elles ont des faiblesses majeures :

-   **Aveugles au contexte** : elles peinent √† comprendre que **"pas
    mauvais"** est positif ou que **"long"** peut √™tre positif
    (batterie) ou n√©gatif (mise au point)
    [@liuSentimentAnalysisOpinion].
-   **Statiques et rigides** : un lexique ne s'adapte pas √† l'argot, aux
    nouveaux usages ou √† un domaine tr√®s sp√©cifique. Il faut le mettre √†
    jour manuellement.
-   **Couverture limit√©e** : elles ne g√®rent que les mots qu'elles
    connaissent et ratent toutes les opinions implicites (*"le t√©l√©phone
    a cess√© de fonctionner au bout de deux jours"*).

\

::: {.callout-note title="Quelle transition ?"}
Comment passer d'un syst√®me qui suit des r√®gles fixes √† un syst√®me qui
**apprend √† partir d'exemples** et s'adapte au contexte ?

**R√©ponse : le Machine Learning (ML)**
:::

------------------------------------------------------------------------

## Les 3 grandes approches du Machine Learning {style="font-size:0.65em"}

On peut classer les algorithmes de ML selon la mani√®re dont ils
"apprennent" √† partir des donn√©es [@ahmadMachineLearningTechniques2017].

::::::::: columns
:::: {.column width="33%"}
### **Apprentissage Supervis√©**

-   **Principe** : apprendre avec un **corrig√©**. Le mod√®le est entra√Æn√©
    sur des donn√©es o√π la "bonne r√©ponse" (l'√©tiquette) est d√©j√† connue.
-   **Donn√©es requises** : un volume cons√©quent de textes **d√©j√†
    √©tiquet√©s** (positif, n√©gatif, etc.). C'est le fameux **Gold
    Standard**.
-   **Exemples** :
    -   Naive Bayes
    -   R√©gression Logistique
    -   Support Vector Machine (SVM)

::: {.callout-tip title="üí° Cas d'usage marketing"}
C'est l'approche la plus courante pour la classification. Id√©al quand on
dispose de donn√©es historiques, comme des tickets de support client d√©j√†
class√©s par niveau de satisfaction.
:::
::::

:::: {.column width="33%"}
### **Apprentissage Non Supervis√©**

-   **Principe** : trouver des **structures cach√©es** dans les donn√©es,
    sans aucun corrig√©. Le mod√®le regroupe les textes qui se
    ressemblent.
-   **Donn√©es requises** : un grand volume de textes **bruts,
    non-√©tiquet√©s**.
-   **Exemple** :
    -   **Clustering** : regrouper des clients ou des commentaires
        similaires.

\
\

::: {.callout-tip title="üí° Cas d'usage marketing"}
Parfait pour l'**exploration**. Quand on ne sait pas ce qu'on cherche,
le non-supervis√© peut r√©v√©ler des segments de clients ou des sujets de
plainte √©mergents qu'on n'avait pas anticip√©s.
:::
::::

:::: {.column width="33%"}
### **Apprentissage Semi-Supervis√©**

-   **Principe** : le meilleur des deux mondes. On utilise un **petit
    peu de donn√©es √©tiquet√©es** pour "guider" l'apprentissage sur une
    **immense quantit√© de donn√©es non-√©tiquet√©es**.
-   **Donn√©es requises** : quelques centaines d'exemples annot√©s + des
    milliers (ou millions) de textes bruts.
-   **Exemples** :
    -   Algorithmes qui propagent les √©tiquettes des exemples connus aux
        exemples inconnus qui leur ressemblent.

::: {.callout-tip title="üí° Cas d'usage marketing"}
C'est souvent le sc√©nario le plus **r√©aliste et rentable**. L'annotation
manuelle co√ªte cher. Le semi-supervis√© permet de construire un mod√®le
performant avec un effort d'annotation minimal.
:::
::::
:::::::::

------------------------------------------------------------------------

## Le Machine Learning : apprendre √† partir des donn√©es {style="font-size:0.7em"}

L'id√©e du ML est simple : au lieu de donner des r√®gles √† la machine, on
lui donne des **exemples** et on la laisse **d√©couvrir les r√®gles
elle-m√™me**. C'est une approche *bottom-up*
[@hartmannComparingAutomatedText2019a].

### Le workflow en 3 √©tapes

:::::: columns
::: {.column width="33%"}
**1. Pr√©parer les donn√©es**

On a besoin d'un corpus d'avis **d√©j√† √©tiquet√©s** (positif/n√©gatif).

\
\

Plus on a d'exemples de qualit√©, mieux le mod√®le apprendra.
:::

::: {.column width="33%"}
**2. Transformer le texte en chiffres**

Un ordinateur ne "lit" pas. Il calcule. Il faut transformer les mots en
**vecteurs num√©riques** (features).

\
\

-   **Approche simple (BoW)** : on compte la fr√©quence de chaque mot.
-   **Approche avanc√©e (Embeddings)** : on repr√©sente le sens des mots
    dans un espace vectoriel. *(√† voir en s√©ance 6)*.
:::

::: {.column width="33%"}
**3. Entra√Æner un mod√®le**

On choisit un algorithme qui va apprendre √† associer les "patterns"
num√©riques des textes aux √©tiquettes.

\
\

-   **Mod√®les classiques** : Naive Bayes, R√©gression Logistique, SVM.
-   **Mod√®les modernes** : R√©seaux de neurones (Deep Learning).
:::
::::::

::: {.callout-tip title="L'adaptation au domaine" style="font-size:1.1em"}
Avec le ML, on peut **ajuster finement ("finetuner")** un mod√®le sur un
domaine sp√©cifique (ex: luxe, automobile, cosm√©tique). Le mod√®le apprend
ainsi le jargon et les nuances propres √† ce domaine, l√† o√π un
dictionnaire g√©n√©rique √©chouerait.
:::

------------------------------------------------------------------------

## Un panorama des mod√®les de Machine Learning {style="font-size:0.7em"}

Tous les mod√®les n'ont pas la m√™me complexit√© ni la m√™me performance.
Voici une vue d'ensemble, du plus simple au plus avanc√©.

:::::::::: columns
::: {.column width="50%" style="font-size: 0.75em"}
### 1. ML "Classique" (Supervised Learning)

On entra√Æne un mod√®le de A √† Z sur nos propres donn√©es √©tiquet√©es.

-   **Naive Bayes** : un mod√®le probabiliste simple et rapide. Il
    calcule la probabilit√© qu'un avis soit positif sachant les mots
    qu'il contient [@ahmadMachineLearningTechniques2017]. Tr√®s bon comme
    baseline.

-   **Support Vector Machine (SVM)** : un classificateur tr√®s robuste
    qui cherche la "fronti√®re" optimale pour s√©parer les classes. Il a
    longtemps √©t√© l'√©tat de l'art pour la classification de texte
    [@pangOpinionMiningSentiment].

**Le d√©fi** : n√©cessite beaucoup de donn√©es √©tiquet√©es pour chaque
nouveau domaine.

\
\
\

### 2. Le Deep Learning et le Transfer Learning

\

On ne part plus de z√©ro. On utilise un mod√®le **pr√©-entra√Æn√©** sur des
milliards de textes (comme Wikip√©dia) qui a d√©j√† une compr√©hension
g√©n√©rale du langage.

\
\

-   **Principe** : on prend ce "cerveau" pr√©-entra√Æn√© et on l'affine
    (*fine-tuning*) sur notre t√¢che sp√©cifique avec beaucoup moins de
    donn√©es [@dangSentimentAnalysisBased2020].
-   **Avantage majeur** : le mod√®le peut g√©n√©raliser et comprendre des
    nuances qu'il n'aurait jamais pu apprendre sur un petit jeu de
    donn√©es.
-   C'est l'approche qui donne aujourd'hui les **meilleures
    performances** [@hartmannMoreFeelingAccuracy2023].
:::

:::::::: {.column width="50%"}
### L'√©chelle de la performance

::::: columns
:::: {.column width="50%"}

::::
:::::

::: {.callout-note title="Accuracy moyenne [@hartmannMoreFeelingAccuracy2023]"}
Une m√©ta-analyse sur 272 jeux de donn√©es montre une hi√©rarchie claire
des performances :

1.  **Transfer Learning (BERT, RoBERTa...)** : **\~90-96%**
2.  **ML Classique (SVM, etc.)** : **\~80-88%**
3.  **Lexiques (VADER, LIWC...)** : **\~65-75%**

Le Transfer Learning est en moyenne **+20 points** plus pr√©cis que les
lexiques.
:::

::: {.callout-warning title="Le compromis g√©n√©ral (interpr√©tabilit√©)"}
-   **Lexiques** : **transparence maximale**, mais pr√©cision limit√©e.
    Id√©al pour comprendre le "pourquoi" et pour des analyses
    exploratoires.
-   **ML / Transfer Learning** : **pr√©cision maximale**, mais plus
    "bo√Æte noire". Id√©al pour des syst√®mes de d√©tection automatique (ex:
    alertes de crise) o√π la performance prime.
:::
::::::::
::::::::::

# Annotation & √©valuation {.transition-slide-ubdyellow}

## L'annotation manuelle : cr√©er notre "v√©rit√© terrain" {style="font-size: 0.85em"}

Avant de pouvoir √©valuer un outil, il nous faut une r√©f√©rence fiable :
le **gold standard**. C'est un ensemble de textes que des humains ont
lus et √©tiquet√©s selon des r√®gles pr√©cises.

### Principes d'une bonne annotation

-   **Sch√©ma clair** : d√©finir pr√©cis√©ment ce qu'on cherche.
    -   **Unit√©s** : annote-t-on la phrase enti√®re, un segment
        (**span**), ou une paire (**aspect**, **opinion**) ?
    -   **Labels** : est-ce une simple polarit√© (`{-, 0, +}`) ou une
        √©chelle d'**intensit√©** (ex: notes de 1 √† 5) ?
-   **Guide d'annotation** : un document essentiel avec des r√®gles et
    des exemples de cas limites (ironie, conditionnels) pour assurer la
    coh√©rence.
-   **Double annotation** : au moins deux personnes annotent le m√™me
    texte de mani√®re ind√©pendante.
-   **Adjudication** : en cas de d√©saccord, un troisi√®me annotateur (ou
    un consensus) tranche pour finaliser le gold standard.

::: {.callout-tip title="üí° Conseil pratique" style="font-size: 0.9em"}
Un bon guide d'annotation est la cl√© de vo√ªte de toute analyse de
sentiment rigoureuse. C'est 80% du travail pour obtenir des donn√©es
fiables.
:::

------------------------------------------------------------------------

## La fiabilit√© des donn√©es : l'accord inter-annotateurs (IAA) {style="font-size: 0.8em"}

**La question cl√© :** nos annotateurs sont-ils d'accord entre eux, ou
est-ce que leurs √©tiquettes sont le fruit du hasard ? L'IAA mesure la
coh√©rence de leur travail.

::::: columns
::: {.column width="50%"}
### Kappa de Cohen ($\kappa$)

Mesure l'accord entre **deux** annotateurs, en corrigeant l'accord qui
pourrait survenir par chance[^1]. $$
\kappa = \frac{p_o - p_e}{1 - p_e}
$$ O√π $p_o$ est l'accord observ√© et $p_e$ l'accord attendu par hasard.
:::

::: {.column width="50%"}
### Alpha de Krippendorff ($\alpha$)

Plus g√©n√©ral et robuste : fonctionne avec **plus de deux** annotateurs
et diff√©rents types de labels (nominal, ordinal...). $$
\alpha = 1 - \frac{D_o}{D_e}
$$ O√π $D_o$ est le d√©saccord observ√© et $D_e$ le d√©saccord attendu par
hasard.
:::
:::::

[^1]: D‚Äôautres mesures existent, comme le Kappa de Fleiss (extension √†
    plusieurs annotateurs) ou l‚ÄôICC (Intraclass Correlation Coefficient)
    pour des variables continues.

::: {.callout-note title="üéØ Objectif"}
On vise un score **Kappa/Alpha ‚â• 0.70**. En dessous, cela signifie que
le guide d'annotation n'est pas assez clair et doit √™tre am√©lior√©. Un
IAA √©lev√© garantit que notre "v√©rit√© terrain" est solide.
:::

------------------------------------------------------------------------

## Exemple & interpr√©tation des scores {style="font-size: 0.8em"}

::::::: columns
::::: {.column width="50%"}
### Exemple de calcul (Kappa de Cohen)

Deux annotateurs classent 50 tweets (*positif/n√©gatif*).

-   Accord observ√© : 40/50 ‚Üí $p_o = 0.8$\
-   Accord attendu par hasard : $p_e = 0.5$

$$
\kappa = \frac{0.8 - 0.5}{1 - 0.5} = 0.6
$$

:::: {.callout-example title="Interpr√©tation"}
$\kappa = 0.6$ ‚Üí **accord mod√©r√© √† substantiel**, mais am√©liorable.

::: {.callout-note title="Remarque sur l'interpr√©tation" style="font-size: 0.8em"}
Les seuils propos√©s par Landis et Koch
[@landisMeasurementObserverAgreement1977] sont devenus une r√©f√©rence,
mais ils sont **arbitraires** et parfois jug√©s trop tol√©rants.\
McHugh [@mchugh2012interrater] recommande des crit√®res plus stricts,
consid√©rant qu‚Äôun accord ¬´ acceptable ¬ª ne devrait pas √™tre en dessous
de **0.80** en contexte scientifique ou m√©dical.
:::
::::
:::::

::: {.column width="50%" style="font-size: 0.8em"}
### Interpr√©tation des scores

| Valeur de Œ∫ / Œ± | Interpr√©tation selon Landis & Koch (1977) |
|-----------------|-------------------------------------------|
| \< 0.00         | Poor                                      |
| 0.00 ‚Äì 0.20     | Slight                                    |
| 0.21 ‚Äì 0.40     | Fair                                      |
| 0.41 ‚Äì 0.60     | Moderate                                  |
| 0.61 ‚Äì 0.80     | Substantial                               |
| 0.81 ‚Äì 1.00     | Almost perfect                            |

```{r}
library(irr)
# Exemple : 2 annotateurs classent 50 tweets (positif/n√©gatif)
# On cr√©e une matrice items √ó annotateurs
# Ici : 40 accords, 10 d√©saccords
annotateur1 <- c(rep("positif", 20), rep("n√©gatif", 20), rep("positif", 5), rep("n√©gatif", 5))
annotateur2 <- c(rep("positif", 20), rep("n√©gatif", 20), rep("n√©gatif", 5), rep("positif", 5))
annotations <- data.frame(annotateur1, annotateur2)
kappa2(annotations, "unweighted")
```
:::
:::::::

## Exemple & interpr√©tation de l‚ÄôAlpha de Krippendorff {style="font-size: 0.8em"}

::::::: columns
:::: {.column width="50%"}
### Exemple de calcul

Trois annotateurs √©valuent 5 items (*positif/n√©gatif*).

-   D√©saccord observ√© : $(D_o \approx 0.27)$
-   D√©saccord attendu : $(D_e \approx 0.48)$

$$
\alpha = 1 - \frac{0.27}{0.48} \approx 0.463
$$

::: {.callout-example title="Interpr√©tation"}
(\alpha = 0.463) ‚Üí Accord **insuffisant** (\< 0.67) ‚Üí guide/formation √†
am√©liorer.
:::
::::

:::: {.column width="50%"}
### Interpr√©tation des scores

::: {.callout-note title="Comment lire Œ±" style="font-size: 0.8em"}
-   (D_o) = d√©saccord observ√© (proportion de d√©saccords r√©els entre
    juges).\
-   (D_e) = d√©saccord attendu **par hasard**, calcul√© √† partir de la
    distribution globale des cat√©gories.

Selon [@krippendorff2018content] :\
- **Œ± ‚â• 0.80** ‚Üí Accord **fiable** (analyses solides)\
- **0.67 ‚â§ Œ± \< 0.80** ‚Üí Accord **acceptable** (exploratoire)\
- **Œ± \< 0.67** ‚Üí Accord **insuffisant**, guide d‚Äôannotation √† am√©liorer

```{r}
library(irr)
annotations <- data.frame(
  annotateur1 = c(1, 1, 0, 1, 0),
  annotateur2 = c(1, 0, 0, 1, 0),
  annotateur3 = c(1, 1, 0, 1, 1)
)
# La fonction kripp.alpha attend une matrice items √ó juges
result <- kripp.alpha(t(as.matrix(annotations)), method = "nominal")
result
```
:::
::::
:::::::

## La base de l'√©valuation : la matrice de confusion {style="font-size: 0.85em"}

Maintenant que nous avons un gold standard fiable, nous pouvons juger
notre outil. La matrice de confusion est le point de d√©part : elle
montre o√π le mod√®le a eu raison et o√π il s'est tromp√©.

Imaginons qu'on veuille d√©tecter les commentaires **n√©gatifs** (la
classe "positive" de notre analyse) :

|                    | Pr√©dit : **n√©gatif**  | Pr√©dit : **OK**       |
|--------------------|-----------------------|-----------------------|
| **R√©el : n√©gatif** | **TP** (vrai positif) | **FN** (faux n√©gatif) |
| **R√©el : OK**      | **FP** (faux positif) | **TN** (vrai n√©gatif) |

\

-   **TP (true positive)** : l'alerte √©tait justifi√©e. C'est un
    commentaire n√©gatif, et on l'a bien d√©tect√©. **Bravo**
-   **FN (false negative)** : **l'alerte manqu√©e !** C'√©tait un
    commentaire n√©gatif, mais on l'a rat√©. **Danger !**
-   **FP (false positive)** : **la fausse alerte.** On a cru que c'√©tait
    n√©gatif, mais √ßa ne l'√©tait pas. **Bruit.**
-   **TN (true negative)** : on a bien ignor√© un commentaire
    non-n√©gatif. **Correct.**

------------------------------------------------------------------------

## Matrice de confusion multiclasse (analyse de sentiment) {style="font-size: 0.4em"}

![](images/clipboard-1562987940.png){fig-align="center" width="50%"}

### Interpr√©tation de la matrice de confusion (10 000 avis)

::::: columns
::: column
#### Performance g√©n√©rale

Sur 10 000 avis, le mod√®le a correctement class√© **7 692** d'entre eux,
soit une **pr√©cision globale de 76,9%**.

-   **Avis N√©gatifs** : **2 107** correctement identifi√©s sur 3 053.
-   **Avis Neutres** : **1 636** correctement identifi√©s sur 2 023.
-   **Avis Positifs** : **3 949** correctement identifi√©s sur 4 924. Le
    mod√®le est particuli√®rement performant pour cette classe.
:::

::: column
#### Analyse des erreurs principales

Les erreurs les plus fr√©quentes se situent dans la confusion avec la
classe **Neutre**.

-   **Erreur majeure n¬∞1** : **739** avis **positifs** ont √©t√© class√©s √†
    tort comme **neutres**. Le mod√®le peine √† identifier un sentiment
    positif peu prononc√©.
-   **Erreur majeure n¬∞2** : **620** avis **n√©gatifs** ont √©t√© class√©s √†
    tort comme **neutres**. De m√™me, le sentiment n√©gatif l√©ger semble
    difficile √† capter.

##### Pistes d'am√©lioration

-   **Affiner la distinction** : Le mod√®le pourrait √™tre am√©lior√© en lui
    fournissant plus d'exemples d'avis √† la fronti√®re entre "Neutre" et
    "Positif/N√©gatif".
-   **Analyse des faux n√©gatifs/positifs** : Examiner les 739 avis
    positifs et 620 avis n√©gatifs mal class√©s pour comprendre les mots
    ou tournures de phrases qui trompent le mod√®le.
:::
:::::

## Le dilemme du marketeur : pr√©cision vs. rappel {style="font-size: 0.65em"}

L'accuracy (taux de bonnes pr√©dictions) est souvent trompeuse. La
pr√©cision et le rappel r√©pondent √† des besoins m√©tier tr√®s diff√©rents.

:::::: columns
::: {.column width="50%"}
### Pr√©cision (precision)

$$
\mathrm{P} = \frac{TP}{TP + FP}
$$

**La question m√©tier :** quand mon syst√®me sonne une alerte, est-ce que
je peux lui faire confiance ?

-   Une **haute pr√©cision** signifie que l'on a peu de fausses alertes
    (peu de FP).
-   **Priorit√© :** ne pas d√©ranger les √©quipes pour rien, ne pas
    contacter √† tort des clients suppos√©s m√©contents. C'est la m√©trique
    de la **fiabilit√©**.

### Rappel (recall)

$$
\mathrm{R} = \frac{TP}{TP + FN}
$$ **La question m√©tier :** suis-je s√ªr d'avoir identifi√© TOUS les vrais
commentaires n√©gatifs ?

-   Un **haut rappel** signifie que l'on a rat√© tr√®s peu de vrais
    probl√®mes (peu de FN).
-   **Priorit√© :** d√©tecter une crise √† tout prix, m√™me si cela g√©n√®re
    quelques fausses alertes. C'est la m√©trique de l'**exhaustivit√©**.
:::

:::: {.column width="50%"}
### F1-score

$$
\mathrm{F1} = \frac{2 \times P \times R}{P + R}
$$ **La question m√©tier :** comment trouver le meilleur √©quilibre entre
fiabilit√© et exhaustivit√© ?

Le **F1-score** est une moyenne qui p√©nalise les mod√®les qui sacrifient
trop l'une des deux m√©triques. **C'est la m√©trique par d√©faut pour une
√©valuation √©quilibr√©e.**

\
\
\
\

::: {.callout-tip title="Analogie marketing" style="font-size: 1.2em"}
-   **Haute pr√©cision** : votre campagne de retargeting est tr√®s
    efficace (haut taux de conversion), mais n'a touch√© qu'un petit
    segment.
-   **Haut rappel** : votre campagne TV a touch√© tout le monde
    (couverture maximale), mais avec un faible impact.
-   **Haut F1-score** : vous avez touch√© une large part de votre cible
    avec un impact significatif.
:::
::::
::::::

------------------------------------------------------------------------

## Le d√©fi des donn√©es r√©elles : des distributions asym√©triques {style="font-size: 0.70em"}

Contrairement √† une id√©e re√ßue, les avis en ligne sont rarement
"√©quilibr√©s". En r√©alit√©, leur distribution est presque toujours
**fortement asym√©trique** (*skewed*), suivant souvent une forme visuelle
de **courbe en "J"** [@pangOpinionMiningSentiment, p. 50].

L'asym√©trie d√©pend fortement de la plateforme (biais d'auto-s√©lection) :

-   **Majoritairement positifs** : sur les plateformes o√π l'avis est un
    acte de recommandation ou de construction de r√©putation (ex:
    **Airbnb**, la plupart des produits sur **Amazon**), on observe une
    avalanche d'avis tr√®s positifs (4-5 √©toiles).
-   **Majoritairement n√©gatifs** : sur les plateformes per√ßues comme un
    lieu de r√©clamation ou de vigilance (ex: **Trustpilot** pour
    certains services, forums de support technique), les avis n√©gatifs
    peuvent dominer.

::: {.callout-warning title="Le pi√®ge de l'accuracy reste le m√™me"}
Que vous ayez 90% d'avis positifs ou 90% de n√©gatifs, le probl√®me de
fond demeure : l'**accuracy est une m√©trique dangereuse**. Un mod√®le qui
pr√©dit toujours la classe majoritaire aura un score √©lev√© mais sera
inutile pour d√©tecter les signaux faibles (la crise qui d√©marre ou les
clients ambassadeurs).
:::

### Les bonnes m√©triques pour les donn√©es d√©s√©quilibr√©es

-   **F1-macro** : on calcule le F1-score pour chaque classe (+, 0, -),
    puis on fait la **moyenne simple**. Chaque classe a le m√™me poids,
    qu'elle soit rare ou fr√©quente. C'est le **standard** pour rapporter
    la performance en analyse de sentiment.

-   **Balanced accuracy** : c'est la moyenne des rappels de chaque
    classe. Simple et juste.

$$
\mathrm{BAcc}=\tfrac{1}{2}\big(\text{Rappel}_{Pos} + \text{Rappel}_{Neg}\big)
$$

------------------------------------------------------------------------

## Au-del√† des labels : √©valuer les scores {style="font-size: 0.60em"}

La plupart des outils (VADER, LIWC) donnent un **score continu** (ex: -0.87), pas un label. Voici comment on √©value cette sortie.

:::: {.columns}

::: {.column width="50%"}
### 1. Le seuil de d√©cision ($\tau$)

C'est √† nous de transformer ce score en label. On d√©finit une **"zone neutre"**.

-   **Exemple** : si score > `0.1` ‚Üí positif ; si score < `-0.1` ‚Üí n√©gatif ; sinon ‚Üí neutre.
-   Un seuil plus exigeant augmentera la pr√©cision mais baissera le rappel.

### 2. √âvaluer le score directement

-   **Corr√©lation de Spearman** : compare le **classement** des avis selon le score de l'outil avec le classement des notes humaines (√©toiles).
    -   *La question : "est-ce que l'outil classe bien les avis du pire au meilleur ?"*
-   **MAE (mean absolute error)** : calcule l'erreur moyenne entre le score de l'outil (normalis√©) et la note en √©toile.
:::

::: {.column width="50%"}
### Courbes P-R et ROC

En faisant varier le seuil $\tau$ de 0 √† 1, on peut tracer des courbes qui visualisent le compromis entre les erreurs :

-   **Courbe ROC** : montre le taux de vrais positifs (sensibilit√©) contre le taux de faux positifs (1-sp√©cificit√©). C'est la vision la plus compl√®te du compromis.

-   **Courbe P-R (precision-recall)** : montre l'√©volution de la pr√©cision en fonction du rappel. Elle est surtout pertinente quand la classe n√©gative est immense et peu int√©ressante (ex: trouver l'aiguille dans la botte de foin).

::: {.callout-warning title="Mise en garde sur le d√©s√©quilibre"}
Contrairement √† une id√©e re√ßue, l'AUPRC (l'aire sous la courbe P-R) n'est pas *toujours* la meilleure m√©trique en cas de d√©s√©quilibre. Des recherches r√©centes montrent qu'elle peut m√™me **aggraver les biais** et que le choix doit avant tout d√©pendre de l'objectif m√©tier [@mcdermottCloserLookAUROC2025].
:::
:::

::::

::: {.callout-note title="Quel seuil choisir ?"}
Le choix du seuil est une **d√©cision strat√©gique**. Pour la **d√©tection de crise** (ne rien rater), on choisira un seuil bas pour maximiser le **rappel**. Pour une **campagne de fid√©lisation** ciblant les clients "tr√®s heureux" (ne pas se tromper), on choisira un seuil √©lev√© pour maximiser la **pr√©cision**.
:::


------------------------------------------------------------------------

## Synth√®se pratique : quelle m√©trique pour quel outil ? {style="font-size: 0.75em"}

Un guide pour √©valuer les outils que vous utiliserez en TP et pour vos
projets.

:::::: columns
::: {.column width="50%"}
### 1. Comprendre la sortie de l'outil

-   **VADER, NRC, syuzhet, LIWC** produisent principalement des
    **scores**.
-   Votre premi√®re √©tape sera toujours de **d√©finir des seuils** pour
    les convertir en labels `(+, 0, -)`.

### 2. Le rapport de performance id√©al

Pour un projet d'analyse de sentiment, votre rapport d'√©valuation
devrait contenir :

1.  La **matrice de confusion** pour visualiser les erreurs.
2.  Le **F1-score macro** comme indicateur principal de la performance.
3.  La **corr√©lation de Spearman** pour √©valuer la qualit√© du classement
    par score.
4.  La **couverture du lexique** : quel % de mots l'outil a-t-il reconnu
    ? Un score bas√© sur 10% du texte est peu fiable.
:::

:::: {.column width="50%"}
### 3. Checklist d'analyse d'erreurs

Une bonne m√©trique ne suffit pas. Il faut comprendre **pourquoi**
l'outil se trompe.

-   L'outil g√®re-t-il bien la **n√©gation** ? (*"pas mauvais"*)
-   Comprend-il les **adversatifs** ? (*"beau mais lent"*)
-   Est-il sensible √† l'**intensit√©** ? *"un peu d√©√ßu" vs "totalement
    d√©go√ªt√©"*)
-   Est-il adapt√© √† votre **domaine** ? (ex: le mot "froid" est n√©gatif
    pour un plat, mais positif pour une bi√®re).

::: {.callout-note title="Le conseil final"}
Aucune m√©trique n'est parfaite. La meilleure approche est de **combiner
une m√©trique quantitative robuste (F1-macro) avec une analyse
qualitative des erreurs** pour vraiment comprendre les forces et les
faiblesses de votre syst√®me.
:::
::::
::::::

## Pi√®ges √† √©viter en analyse de sentiment {style="font-size:0.80em"}

M√™me les meilleurs outils peuvent se tromper. Voici les pi√®ges les plus courants √† anticiper :

:::: {.columns}
::: {.column width="50%"}
### Pi√®ges Linguistiques

-   **Ambigu√Øt√©s** : l'implicite, l'ironie et le sarcasme peuvent totalement inverser la polarit√© et sont tr√®s difficiles √† d√©tecter automatiquement.
-   **Port√©e des "shifters"** : une n√©gation ou un adversatif ("mais") mal interpr√©t√© peut fausser l'analyse d'une phrase enti√®re.

### Pi√®ges M√©thodologiques

-   **D√©pendance au domaine** : un lexique entra√Æn√© sur des avis de restaurants sera m√©diocre pour analyser des tweets financiers. Le vocabulaire et le contexte changent tout.
-   **Biais des lexiques** : un dictionnaire g√©n√©rique peut contenir des biais culturels ou √™tre inadapt√© au langage sp√©cifique de certaines communaut√©s en ligne (argot, m√®mes).
:::
::: {.column width="50%"}
### Pi√®ges li√©s aux Donn√©es et √† l'√âthique

-   **Spam d'opinion (Fake Reviews)** : la pr√©sence d'avis frauduleux (positifs ou n√©gatifs) peut compl√®tement fausser vos KPIs. La d√©tection de spam est un enjeu majeur.
-   **Qualit√© des donn√©es** : des textes tr√®s courts, mal √©crits ou remplis d'emojis peuvent d√©grader la performance de n'importe quel mod√®le.
:::
::::

## De la question marketing au rapport final : la checklist d'un projet r√©ussi  {style="font-size:0.50em"}

Un projet d'analyse de sentiment r√©ussi n'est pas qu'une question d'outils, c'est avant tout une question de m√©thode. Voici les √©tapes cl√©s.

### 1. Partir de la question de recherche (cadrage strat√©gique)
Tout commence par la traduction d'un objectif m√©tier en une question analytique pr√©cise. Cette question va dicter vos choix techniques [@krugmannSentimentAnalysisAge2024a].

- **Question m√©tier** : *"Le lancement de notre nouveau produit g√©n√®re-t-il un buzz positif ?"*
- **Traduction analytique** :
    - Quel est le volume de mentions ?* ‚Üí **Monitoring de base**
    - La polarit√© globale est-elle positive ou n√©gative ?* ‚Üí **Classification binaire**
    - Quels sont les points forts et faibles per√ßus ?* ‚Üí **ABSA (analyse par aspect)**
    - Comment nous situons-nous face au concurrent X ?* ‚Üí **Analyse comparative**

### 2. Choisir l'approche m√©thodologique
Votre question et vos ressources (temps, donn√©es) d√©terminent la meilleure approche.

- **Approche Lexique + R√®gles** : id√©ale pour la **transparence** (comprendre le "pourquoi"), la rapidit√© et l'exploration, au d√©triment de la performance brute.
- **Approche Machine Learning** : √† privil√©gier pour la **performance** et l'**adaptation** au domaine. C'est en moyenne +20 points de pr√©cision par rapport aux lexiques [@hartmannMoreFeelingAccuracy2023].

### 3. Pr√©parer donn√©es et outils (rigueur op√©rationnelle)
- **Si approche ML** : la priorit√© est de constituer un **Gold Standard** de qualit√© via une **annotation** rigoureuse (guide clair, double annotation, calcul de l'**IAA**). La qualit√© du mod√®le d√©pend directement de la qualit√© de ces donn√©es.
- **Si approche Lexique** : la priorit√© est d'**adapter le lexique** au domaine (via les techniques corpus-based comme PMI ou l'analyse des conjonctions) et de v√©rifier manuellement un √©chantillon pour √©viter les contresens.

### 4. Analyser et evaluer les r√©sultats
- **√âvaluation quantitative** : ne jamais se fier √† l'accuracy seule. Utiliser la **matrice de confusion** et le **F1-macro** pour une mesure juste, surtout si les classes sont d√©s√©quilibr√©es.
- **Analyse qualitative des erreurs** : examiner les cas o√π le mod√®le se trompe (n√©gation, ironie, implicite...). C'est la meilleure source d'inspiration pour l'am√©liorer.
- **Test de robustesse** : v√©rifier si le mod√®le fonctionne encore sur des donn√©es d'une autre plateforme ou d'une autre p√©riode (**cross-domaine**, **cross-temporel**).

------------------------------------------------------------------------


## Conclusion : de l'artisanat √† l'automatisation intelligente {style="font-size:0.65em"}

L'analyse de sentiment a connu une r√©volution. Nous sommes pass√©s d'approches manuelles √† des outils capables de comprendre le langage avec une finesse sans pr√©c√©dent.

:::: {.columns}
::: {.column width="50%"}

### L‚Äô√©volution des m√©thodes

- **Hier : lexiques & r√®gles (artisanat)** :
M√©thodes transparentes et contr√¥lables, excellentes pour l'exploration et pour tester des hypoth√®ses th√©oriques [@hartmannMoreFeelingAccuracy2023, p. 84].

- **Aujourd‚Äôhui : Machine Learning & Deep Learning (industrialisation)** :
Apprentissage sur donn√©es pour une meilleure adaptation au contexte et des performances nettement sup√©rieures [@hartmannMoreFeelingAccuracy2023, p. 76].

- **Demain (et d√©j√† maintenant) :  LLMs / IA g√©n√©rative** :
Compr√©hension contextuelle "sur √©tag√®re" (*zero-shot*) qui rivalise avec les mod√®les sp√©cialis√©s, posant de nouveaux enjeux de reproductibilit√© et d'√©thique [@krugmannSentimentAnalysisAge2024a, p. 2, 16].
:::

::: {.column width="50%"}

### Les implications pour le marketing

- **De la description √† la pr√©diction** :
Au-del√† du comptage pos/neg : anticipation de tendances (ex: cours de la bourse) et d√©tection de signaux faibles de crise (*firestorms*) [@hartmannMoreFeelingAccuracy2023, p. 76].

- **Connaissance client hyper-granulaire** :
Les nuances dans des milliers de verbatims permettent d'affiner les personas, de personnaliser les messages et d'identifier des besoins non satisfaits pour l‚Äôinnovation [@agarwalProminentFeatureExtraction2016, p. 3].

- **Vigilance strat√©gique en continu** :
L'e-r√©putation devient un **flux** d'information en temps r√©el qui peut alimenter des tableaux de bord et la prise de d√©cision au quotidien [@ahmadMachineLearningTechniques2017, p. 3].
:::
::::

::: {.callout-note title="Le message final"}
La technologie devient de plus en plus puissante et accessible. Le r√¥le de l‚Äôexpert marketing n‚Äôest plus de conna√Ætre chaque d√©tail technique, mais de **poser les bonnes questions**, d'**interpr√©ter avec esprit critique** et de **d√©cider** √† partir d‚Äôinsights fiables [@hartmannMoreFeelingAccuracy2023].
:::

-----

## R√©f√©rences
