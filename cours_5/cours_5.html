<!DOCTYPE html>
<html lang="en"><head>
<script src="cours_5_files/libs/clipboard/clipboard.min.js"></script>
<script src="cours_5_files/libs/quarto-html/tabby.min.js"></script>
<script src="cours_5_files/libs/quarto-html/popper.min.js"></script>
<script src="cours_5_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="cours_5_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="cours_5_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="cours_5_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Olivier Caron">
  <title>Ã‰tudes qualitatives sur le web (netnographie)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="cours_5_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="cours_5_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="cours_5_files/libs/revealjs/dist/theme/quarto-7305b09eb733fa85903ef661c69bedac.css">
  <link href="cours_5_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="cours_5_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="cours_5_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="cours_5_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="cours_5_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="cours_5_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="ubd_bg1.png" data-background-position="center" data-background-size="cover" class="quarto-title-block center">
  <h1 class="title">Ã‰tudes qualitatives sur le web (netnographie)</h1>
  <p class="subtitle">Analyse de sentiment et opinions</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Olivier Caron 
</div>
        <p class="quarto-title-affiliation">
            Paris Dauphine - PSL
          </p>
    </div>
</div>

</section>
<section id="objectifs-du-cours" class="slide level2" style="font-size:0.75em">
<h2>Objectifs du cours</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>1. Comprendre et modÃ©liser les opinions</strong></p>
<ul>
<li>DÃ©finir et distinguer <strong>opinion</strong>, <strong>subjectivitÃ©</strong> et <strong>polaritÃ©</strong>.</li>
<li>MaÃ®triser les <strong>niveaux dâ€™analyse</strong> (document, phrase, aspect) et leur pertinence marketing.</li>
<li>Identifier les <strong>phÃ©nomÃ¨nes linguistiques</strong> qui influencent le sentiment (nÃ©gation, intensitÃ©, â€œmaisâ€â€¦).</li>
</ul>
<p><br>
<br>
</p>
<p><strong>2. MaÃ®triser les approches classiques</strong></p>
<p><br>
<br>
</p>
<ul>
<li>Appliquer des mÃ©thodes basÃ©es sur des <strong>lexiques</strong> et des <strong>rÃ¨gles</strong>.</li>
<li>Comprendre comment <strong>adapter un lexique</strong> Ã  un domaine spÃ©cifique (induction <em>corpus-based</em>).</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>3. Comprendre le Machine Learning pour lâ€™analyse de sentiment</strong></p>
<ul>
<li>Comprendre les principes des apprentissages <strong>supervisÃ©</strong> et <strong>non supervisÃ©</strong>.</li>
<li>Distinguer le <strong>ML â€œclassiqueâ€</strong> (Naive Bayes, SVM) du <strong>Deep Learning / Transfer Learning</strong>.</li>
<li>ConnaÃ®tre les avantages et les limites de chaque grande famille de modÃ¨les.</li>
</ul>
<p><strong>4. Comprendre et mettre en oeuvre une dÃ©marche rigoureuse</strong></p>
<p><br>
</p>
<ul>
<li>Concevoir un <strong>schÃ©ma dâ€™annotation</strong> clair et fiable.</li>
<li>Mesurer la qualitÃ© des donnÃ©es avec lâ€™<strong>accord inter-annotateurs (IAA)</strong>.</li>
<li><strong>Ã‰valuer</strong> un systÃ¨me avec les bonnes mÃ©triques (<strong>F1-macro</strong>) en Ã©vitant les piÃ¨ges (dÃ©sÃ©quilibre des classes).</li>
</ul>
</div></div>
</section>
<section id="quest-ce-quune-opinion-le-modÃ¨le-structurÃ©-de-liu" class="slide level2" style="font-size:0.80em">
<h2>Quâ€™est-ce quâ€™une opinion ? Le modÃ¨le structurÃ© de Liu</h2>
<p>En analyse de sentiment, une opinion nâ€™est pas quâ€™un simple â€œjâ€™aimeâ€ ou â€œje nâ€™aime pasâ€. Pour Ãªtre analysable, Bing Liu, lâ€™un des pionniers du domaine, la modÃ©lise comme un objet structurÃ©, le <strong>quintuple</strong> <span class="citation" data-cites="liuSentimentAnalysisOpinion">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Liu 2022, 19</a>)</span>.</p>
<p><br>
</p>
<p><span class="math display">\[(e_i, a_{ij}, s_{ijkl}, h_k, t_l)\]</span><br>
</p>
<ul>
<li><strong>EntitÃ© (</strong><span class="math inline">\(e_i\)</span>) : le produit, la marque, le service. <em>Ex: â€œiPhone 15â€</em>.</li>
<li><strong>Aspect (</strong><span class="math inline">\(a_{ij}\)</span>) : une caractÃ©ristique spÃ©cifique de lâ€™entitÃ©. <em>Ex: â€œbatterieâ€, â€œqualitÃ© photoâ€</em>. Si lâ€™opinion vise lâ€™entitÃ© entiÃ¨re, on utilise lâ€™aspect <strong>GENERAL</strong>.</li>
<li><strong>Sentiment (</strong><span class="math inline">\(s_{ijkl}\)</span>) : la polaritÃ© (+, 0, -) et/ou son intensitÃ©. <em>Ex: â€œtrÃ¨s positifâ€</em>.</li>
<li><strong>Holder (</strong><span class="math inline">\(h_k\)</span>) : la source de lâ€™opinion. <em>Ex: â€œlâ€™auteur du tweetâ€, â€œle journalisteâ€</em>.</li>
<li><strong>Temps (</strong><span class="math inline">\(t_l\)</span>) : la date de publication. Essentiel pour suivre les tendances.</li>
</ul>
</section>
<section id="explicite-vs.-implicite-lire-entre-les-lignes" class="slide level2" style="font-size:0.85em">
<h2>Explicite vs.&nbsp;Implicite : lire entre les lignes</h2>
<p>Toutes les opinions ne sont pas exprimÃ©es de la mÃªme maniÃ¨re. La distinction entre opinion explicite et implicite est cruciale car elle dÃ©termine la difficultÃ© de lâ€™analyse <span class="citation" data-cites="liuSentimentAnalysisOpinion">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Liu 2022, 26</a>)</span>.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="opinion-explicite"><strong>Opinion explicite</strong></h3>
<p>Câ€™est une <strong>dÃ©claration subjective</strong> qui utilise des mots de sentiment clairs.</p>
<ul>
<li><em>â€œLa batterie de ce tÃ©lÃ©phone est <strong>excellente</strong>.â€</em></li>
<li><em>â€œJe <strong>dÃ©teste</strong> le nouveau design.â€</em></li>
<li><em>â€œLe service client Ã©tait <strong>dÃ©cevant</strong>.â€</em></li>
</ul>
<p><strong>FacilitÃ©</strong> : relativement simple Ã  dÃ©tecter avec des lexiques de mots positifs/nÃ©gatifs.</p>
</div><div class="column" style="width:50%;">
<h3 id="opinion-implicite"><strong>Opinion implicite</strong></h3>
<p>Câ€™est un <strong>Ã©noncÃ© factuel</strong> qui, dans un contexte donnÃ©, implique une opinion forte.</p>
<ul>
<li><em>â€œLa batterie de ce tÃ©lÃ©phone <strong>tient Ã  peine la journÃ©e</strong>.â€</em> (fait indÃ©sirable â†’ opinion nÃ©gative)</li>
<li><em>â€œJâ€™ai dÃ» <strong>redÃ©marrer lâ€™ordinateur trois fois</strong> ce matin.â€</em> (fait indÃ©sirable â†’ opinion nÃ©gative)</li>
<li><em>â€œLe colis est <strong>arrivÃ© en 24h</strong>.â€</em> (fait dÃ©sirable â†’ opinion positive)</li>
</ul>
<p><strong>DifficultÃ©</strong> : beaucoup plus complexe Ã  dÃ©tecter. NÃ©cessite une connaissance du domaine et des attentes des consommateurs.</p>
</div></div>
</section>
<section id="subjectivitÃ©-polaritÃ©-et-valence" class="slide level2" style="font-size:0.75em">
<h2>SubjectivitÃ©, polaritÃ© et valence</h2>
<p>Le langage des opinions a plusieurs facettes. Il est essentiel de distinguer si un texte exprime un point de vue (<em>subjectivitÃ©</em>) et si ce point de vue est positif ou nÃ©gatif (<em>polaritÃ©</em> ou <em>valence</em>) <span class="citation" data-cites="pangOpinionMiningSentiment">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Pang, Lee, et al. 2008, 5</a>)</span>.</p>
<ul>
<li><strong>SubjectivitÃ©</strong> : câ€™est la prÃ©sence dâ€™un <strong>Ã©tat privÃ©</strong> de lâ€™auteur (croyance, jugement, spÃ©culation) par opposition Ã  un <strong>fait objectif</strong> vÃ©rifiable.
<ul>
<li><strong>Subjectif</strong> : <em>â€œJe pense que ce film va plaire.â€</em></li>
<li><strong>Objectif</strong> : <em>â€œLe film est sorti hier.â€</em></li>
</ul></li>
<li><strong>PolaritÃ© (ou valence)</strong> : câ€™est lâ€™<strong>orientation</strong> de lâ€™opinion (+, -, 0). Le terme <strong>valence</strong>, issu de la psychologie, est souvent utilisÃ© pour dÃ©crire cette qualitÃ© intrinsÃ¨quement positive ou nÃ©gative dâ€™un mot ou dâ€™une expression.
<ul>
<li><strong>Subjectif SANS polaritÃ© claire</strong> : <em>â€œJe me demande si ce produit est fiable.â€</em></li>
<li><strong>Subjectif AVEC polaritÃ©</strong> : <em>â€œCe produit est incroyablement fiable.â€</em> (valence positive)</li>
</ul></li>
<li><strong>PolaritÃ© (ou valence) contextuelle</strong> : la polaritÃ© dâ€™un mot nâ€™est pas fixe ; elle dÃ©pend crucialement de son contexte. Les <strong>nÃ©gations</strong>, <strong>intensificateurs</strong> ou mÃªme lâ€™<strong>aspect</strong> concernÃ© peuvent tout changer.
<ul>
<li><em>â€œlongâ€</em> â†’ valence positive pour une batterie, valence nÃ©gative pour un temps dâ€™attente.</li>
</ul></li>
</ul>
<div title="Pourquoi cette distinction est-elle importante ?">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Pourquoi cette distinction est-elle importante ?</strong></p>
</div>
<div class="callout-content">
<p>La plupart des systÃ¨mes dâ€™analyse de sentiment fonctionnent en deux Ã©tapes : dâ€™abord, ils filtrent les phrases pour ne garder que les <strong>subjectives</strong>, puis ils dÃ©terminent la <strong>polaritÃ©/valence</strong> de ces derniÃ¨res.</p>
</div>
</div>
</div>
</div>
</section>
<section id="les-niveaux-danalyse-quelle-question-se-pose-t-on" class="slide level2" style="font-size:0.72em">
<h2>Les niveaux dâ€™analyse : quelle question se pose-t-on ?</h2>
<p>Lâ€™analyse de sentiment peut Ãªtre menÃ©e Ã  diffÃ©rentes Ã©chelles. Chaque â€œgranularitÃ©â€ rÃ©pond Ã  un besoin marketing diffÃ©rent <span class="citation" data-cites="liuSentimentAnalysisOpinion">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Liu 2022, 10â€“11</a>)</span>.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="document-level"><strong>Document-level</strong></h3>
<p>On analyse un texte entier (un avis, un article) pour en extraire un sentiment global.</p>
<ul>
<li><strong>Question mÃ©tier</strong> : <em>â€œQuel est le score de satisfaction moyen de notre produit sur Amazon ?â€</em></li>
<li><strong>Limite</strong> : trÃ¨s rÃ©ducteur. Un avis 3 Ã©toiles peut contenir des critiques trÃ¨s prÃ©cises et des compliments sur dâ€™autres aspects.</li>
</ul>
<h3 id="sentence-level"><strong>Sentence-level</strong></h3>
<p><br>
</p>
<p>On analyse chaque phrase indÃ©pendamment pour dÃ©terminer si elle est subjective et quelle est sa polaritÃ©.</p>
<p><br>
</p>
<ul>
<li><strong>Question mÃ©tier</strong> : <em>â€œQuels sont les verbatims clients les plus percutants (positifs ou nÃ©gatifs) Ã  faire remonter en rÃ©union ?â€</em></li>
<li><strong>Limite</strong> : une mÃªme phrase peut contenir plusieurs opinions. <em>â€œLe design est super mais la batterie est nulle.â€</em></li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="aspect-level-absa"><strong>Aspect-level (ABSA)</strong></h3>
<p>Câ€™est le niveau le plus fin et le plus utile. On identifie les <strong>aspects</strong> spÃ©cifiques et on leur attribue une polaritÃ©.</p>
<ul>
<li><strong>Question mÃ©tier</strong> : <em>â€œQuels sont les <strong>points forts et les points faibles</strong> de notre produit ? Sur quoi devons-nous concentrer nos efforts R&amp;D et marketing ?â€</em></li>
<li><strong>Avantage</strong> : fournit des insights trÃ¨s <strong>actionnables</strong>.</li>
</ul>
<p><br>
<br>
</p>
<h3 id="opinions-comparatives"><strong>Opinions Comparatives</strong></h3>
<p><br>
</p>
<p>On analyse les phrases qui comparent plusieurs entitÃ©s sur un mÃªme aspect.</p>
<p><br>
</p>
<ul>
<li><strong>Question mÃ©tier</strong> : <em>â€œComment notre produit se positionne-t-il face Ã  notre principal concurrent sur lâ€™aspect â€˜prixâ€™ ou â€˜qualitÃ©â€™ aux yeux des consommateurs ?â€</em></li>
<li><strong>Avantage</strong> : le cÅ“ur de lâ€™<strong>intelligence concurrentielle</strong>.</li>
</ul>
</div></div>
</section>
<section id="les-phÃ©nomÃ¨nes-linguistiques-et-leurs-effets" class="slide level2">
<h2>Les phÃ©nomÃ¨nes linguistiques et leurs effets</h2>
<div class="columns">
<div class="column" style="font-size:0.75em">
<h3 id="valence-shifters-nÃ©gation-intensitÃ©"><strong>â€œValence Shiftersâ€</strong> : nÃ©gation &amp; intensitÃ©</h3>
<ul>
<li><strong>NÃ©gation</strong> : inverse la polaritÃ© dâ€™un mot (<em>pas bon</em>). La <strong>portÃ©e</strong> (scope) est cruciale : â€œCe nâ€™est pas bon, câ€™est excellentâ€ â†’ la nÃ©gation ne sâ€™applique quâ€™Ã  â€œbonâ€.</li>
<li><strong>Intensificateurs</strong> : augmentent la force (<em>trÃ¨s, vraiment, extrÃªmement</em>).</li>
<li><strong>AttÃ©nuateurs</strong> : diminuent la force (<em>un peu, lÃ©gÃ¨rement</em>).</li>
</ul>
<h3 id="connecteurs-mais-et-et"><strong>Connecteurs</strong> : â€œMaisâ€ et â€œEtâ€</h3>
<ul>
<li><strong>Adversatifs (â€œmaisâ€, â€œcependantâ€)</strong> : signalent un retournement. La rÃ¨gle dâ€™or est que lâ€™opinion <strong>aprÃ¨s le â€œmaisâ€</strong> est la plus importante.
<ul>
<li><em>â€œLe design est super, <strong>mais la batterie est nulle</strong>.â€</em> â†’ avis globalement nÃ©gatif.</li>
</ul></li>
<li><strong>Additifs (â€œetâ€)</strong> : tendent Ã  aligner des opinions de mÃªme polaritÃ©.
<ul>
<li><em>â€œLÃ©ger <strong>et</strong> pratique.â€</em> â†’ deux aspects positifs.</li>
</ul></li>
</ul>
</div><div class="column" style="font-size:0.8em">
<h3 id="conditionnels-modaux"><strong>Conditionnels &amp; Modaux</strong></h3>
<ul>
<li><strong>Expriment une possibilitÃ©, pas une rÃ©alitÃ©</strong> (<em>â€œLe service <strong>pourrait</strong> Ãªtre meilleur.â€</em>).</li>
<li>Ils <strong>affaiblissent</strong> lâ€™opinion. Ce nâ€™est pas une critique aussi ferme que <em>â€œLe service est mauvais.â€</em></li>
</ul>
<p><br>
<br>
</p>
<h3 id="implicites-ironie"><strong>Implicites &amp; Ironie</strong></h3>
<ul>
<li><strong>Implicite</strong> : opinion cachÃ©e dans un fait.
<ul>
<li><em>â€œLe tÃ©lÃ©phone chauffe aprÃ¨s 10 min.â€</em> â†’ fait objectif, mais opinion nÃ©gative implicite sur lâ€™aspect <em>performance</em>.</li>
</ul></li>
<li><strong>Ironie/Sarcasme</strong> : dire le contraire de ce que lâ€™on pense.
<ul>
<li><em>â€œSuper, ma commande est encore arrivÃ©e en retard.â€</em> â†’ mots positifs, mais sentiment trÃ¨s nÃ©gatif. Câ€™est le dÃ©fi le plus complexe de lâ€™analyse.</li>
</ul></li>
</ul>
</div></div>
</section>
<section id="mÃ©thodes-danalyse-classiques" class="slide level2">
<h2>MÃ©thodes dâ€™analyse classiques</h2>
<div class="columns">
<div class="column" style="font-size:0.7em">
<h3 id="approche-par-lexiques-dictionnaires"><strong>Approche par lexiques (dictionnaires)</strong></h3>
<ul>
<li><strong>Principe</strong> : on attribue un score Ã  chaque mot (+1 pour â€œbonâ€, -1 pour â€œmauvaisâ€) et on fait la somme, ajustÃ©e par des <strong>rÃ¨gles de composition</strong> (nÃ©gation, â€œmaisâ€â€¦).</li>
<li><strong>Construction de lexique</strong> :
<ul>
<li><strong>Dictionary-based</strong> : on part de quelques mots et on Ã©tend avec des synonymes/antonymes.</li>
<li><strong>Corpus-based</strong> : on â€œdÃ©couvreâ€ la polaritÃ© des mots en regardant avec quels autres mots ils apparaissent dans un grand corpus de textes (ex: PMI).</li>
</ul></li>
</ul>
<h3 id="absa-aspect-based-sentiment-analysis"><strong>ABSA (Aspect-Based Sentiment Analysis)</strong></h3>
<p>Câ€™est lâ€™approche la plus <strong>actionnable</strong> pour le marketing.</p>
<ul>
<li><strong>Pipeline</strong> :
<ol type="1">
<li><strong>Extraire les aspects</strong> dont les gens parlent (ex: â€œbatterieâ€, â€œÃ©cranâ€, â€œprixâ€).</li>
<li><strong>Lier lâ€™opinion Ã  lâ€™aspect</strong> (ex: â€œexcellentâ€ â†’ â€œÃ©cranâ€).</li>
<li><strong>Calculer la polaritÃ© pour chaque aspect</strong>.</li>
</ol></li>
<li><strong>RÃ©sultat</strong> : une carte des points forts et faibles du produit.</li>
</ul>
</div><div class="column" style="font-size:0.8em">
<h3 id="opinions-comparatives-1"><strong>Opinions comparatives</strong></h3>
<ul>
<li><strong>Objectif</strong> : analyser les phrases qui comparent des entitÃ©s.
<ul>
<li><em>â€œLa batterie de lâ€™iPhone <strong>dure plus longtemps que</strong> celle du Samsung.â€</em></li>
</ul></li>
<li><strong>Extraction</strong> : on identifie les deux entitÃ©s comparÃ©es (E1, E2), lâ€™aspect de comparaison (A) et surtout, lâ€™<strong>entitÃ© prÃ©fÃ©rÃ©e</strong> (PE).</li>
</ul>
</div></div>
</section>
<section>
<section id="machine-learning" class="title-slide slide level1 center">
<h1>Machine learning</h1>

</section>
<section id="deux-approches-pour-automatiser-lanalyse-ml-vs-deep-learning" class="slide level2">
<h2>Deux approches pour automatiser lâ€™analyse : ML vs Deep Learning</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-2246092486.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></p>
</figure>
</div>
<div class="columns">
<div class="column" style="font-size:0.478em">
<h3 id="machine-learning-classique"><strong>Machine Learning â€œClassiqueâ€</strong></h3>
<ul>
<li><strong>Principe</strong> : lâ€™humain choisit et prÃ©pare les <em>features</em> (caractÃ©ristiques) pertinentes du texte (ex: la prÃ©sence de certains mots, des bigrammesâ€¦). Câ€™est une Ã©tape de <strong>feature extraction</strong> manuelle.</li>
<li><strong>Le modÃ¨le apprend</strong> Ã  associer ces <em>features</em> prÃ©parÃ©es Ã  un sentiment (positif/nÃ©gatif).</li>
<li><strong>Analogie</strong> : on prÃ©pare les ingrÃ©dients (features) pour le chef (modÃ¨le) qui nâ€™a plus quâ€™Ã  cuisiner.</li>
</ul>
</div><div class="column" style="font-size:0.5em">
<h3 id="deep-learning"><strong>Deep Learning</strong></h3>
<ul>
<li><strong>Principe</strong> : le modÃ¨le apprend <strong>directement Ã  partir des mots bruts</strong>. Il dÃ©couvre lui-mÃªme les <em>features</em> importantes dans ses couches cachÃ©es (<em>hidden layers</em>). Lâ€™Ã©tape de <strong>feature extraction</strong> est automatique.</li>
<li><strong>Le modÃ¨le apprend</strong> des reprÃ©sentations complexes du langage (embeddings).</li>
<li><strong>Analogie</strong> : on donne les produits bruts au chef (modÃ¨le) et il se charge de tout, de la dÃ©coupe Ã  la cuisson.</li>
</ul>
</div></div>
<div title="A retenir">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>A retenir</strong></p>
</div>
<div class="callout-content">
<p>Le <strong>Deep Learning</strong> automatise plus de tÃ¢ches et peut capturer des relations plus complexes, ce qui conduit souvent Ã  de meilleures performances <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023</a>)</span>. Câ€™est la base des modÃ¨les les plus rÃ©cents.</p>
</div>
</div>
</div>
</div>
</section>
<section id="transition-les-limites-des-approches-par-lexiques" class="slide level2" style="font-size:0.7em">
<h2>Transition : les limites des approches par lexiques</h2>
<p>Les mÃ©thodes par lexiques et rÃ¨gles sont transparentes et rapides, mais elles ont des faiblesses majeures :</p>
<ul>
<li><strong>Aveugles au contexte</strong> : elles peinent Ã  comprendre que <strong>â€œpas mauvaisâ€</strong> est positif ou que <strong>â€œlongâ€</strong> peut Ãªtre positif (batterie) ou nÃ©gatif (mise au point) <span class="citation" data-cites="liuSentimentAnalysisOpinion">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Liu 2022</a>)</span>.</li>
<li><strong>Statiques et rigides</strong> : un lexique ne sâ€™adapte pas Ã  lâ€™argot, aux nouveaux usages ou Ã  un domaine trÃ¨s spÃ©cifique. Il faut le mettre Ã  jour manuellement.</li>
<li><strong>Couverture limitÃ©e</strong> : elles ne gÃ¨rent que les mots quâ€™elles connaissent et ratent toutes les opinions implicites (<em>â€œle tÃ©lÃ©phone a cessÃ© de fonctionner au bout de deux joursâ€</em>).</li>
</ul>
<p><br>
</p>
<div title="Quelle transition ?">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Quelle transition ?</strong></p>
</div>
<div class="callout-content">
<p>Comment passer dâ€™un systÃ¨me qui suit des rÃ¨gles fixes Ã  un systÃ¨me qui <strong>apprend Ã  partir dâ€™exemples</strong> et sâ€™adapte au contexte ?</p>
<p><strong>RÃ©ponse : le Machine Learning (ML)</strong></p>
</div>
</div>
</div>
</div>
</section>
<section id="les-3-grandes-approches-du-machine-learning" class="slide level2" style="font-size:0.65em">
<h2>Les 3 grandes approches du Machine Learning</h2>
<p>On peut classer les algorithmes de ML selon la maniÃ¨re dont ils â€œapprennentâ€ Ã  partir des donnÃ©es <span class="citation" data-cites="ahmadMachineLearningTechniques2017">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Ahmad et al. 2017</a>)</span>.</p>
<div class="columns">
<div class="column" style="width:33%;">
<h3 id="apprentissage-supervisÃ©"><strong>Apprentissage SupervisÃ©</strong></h3>
<ul>
<li><strong>Principe</strong> : apprendre avec un <strong>corrigÃ©</strong>. Le modÃ¨le est entraÃ®nÃ© sur des donnÃ©es oÃ¹ la â€œbonne rÃ©ponseâ€ (lâ€™Ã©tiquette) est dÃ©jÃ  connue.</li>
<li><strong>DonnÃ©es requises</strong> : un volume consÃ©quent de textes <strong>dÃ©jÃ  Ã©tiquetÃ©s</strong> (positif, nÃ©gatif, etc.). Câ€™est le fameux <strong>Gold Standard</strong>.</li>
<li><strong>Exemples</strong> :
<ul>
<li>Naive Bayes</li>
<li>RÃ©gression Logistique</li>
<li>Support Vector Machine (SVM)</li>
</ul></li>
</ul>
<div title="ğŸ’¡ Cas d'usage marketing">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ’¡ Cas dâ€™usage marketing</strong></p>
</div>
<div class="callout-content">
<p>Câ€™est lâ€™approche la plus courante pour la classification. IdÃ©al quand on dispose de donnÃ©es historiques, comme des tickets de support client dÃ©jÃ  classÃ©s par niveau de satisfaction.</p>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:33%;">
<h3 id="apprentissage-non-supervisÃ©"><strong>Apprentissage Non SupervisÃ©</strong></h3>
<ul>
<li><strong>Principe</strong> : trouver des <strong>structures cachÃ©es</strong> dans les donnÃ©es, sans aucun corrigÃ©. Le modÃ¨le regroupe les textes qui se ressemblent.</li>
<li><strong>DonnÃ©es requises</strong> : un grand volume de textes <strong>bruts, non-Ã©tiquetÃ©s</strong>.</li>
<li><strong>Exemple</strong> :
<ul>
<li><strong>Clustering</strong> : regrouper des clients ou des commentaires similaires.</li>
</ul></li>
</ul>
<p><br>
<br>
</p>
<div title="ğŸ’¡ Cas d'usage marketing">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ’¡ Cas dâ€™usage marketing</strong></p>
</div>
<div class="callout-content">
<p>Parfait pour lâ€™<strong>exploration</strong>. Quand on ne sait pas ce quâ€™on cherche, le non-supervisÃ© peut rÃ©vÃ©ler des segments de clients ou des sujets de plainte Ã©mergents quâ€™on nâ€™avait pas anticipÃ©s.</p>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:33%;">
<h3 id="apprentissage-semi-supervisÃ©"><strong>Apprentissage Semi-SupervisÃ©</strong></h3>
<ul>
<li><strong>Principe</strong> : le meilleur des deux mondes. On utilise un <strong>petit peu de donnÃ©es Ã©tiquetÃ©es</strong> pour â€œguiderâ€ lâ€™apprentissage sur une <strong>immense quantitÃ© de donnÃ©es non-Ã©tiquetÃ©es</strong>.</li>
<li><strong>DonnÃ©es requises</strong> : quelques centaines dâ€™exemples annotÃ©s + des milliers (ou millions) de textes bruts.</li>
<li><strong>Exemples</strong> :
<ul>
<li>Algorithmes qui propagent les Ã©tiquettes des exemples connus aux exemples inconnus qui leur ressemblent.</li>
</ul></li>
</ul>
<div title="ğŸ’¡ Cas d'usage marketing">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ’¡ Cas dâ€™usage marketing</strong></p>
</div>
<div class="callout-content">
<p>Câ€™est souvent le scÃ©nario le plus <strong>rÃ©aliste et rentable</strong>. Lâ€™annotation manuelle coÃ»te cher. Le semi-supervisÃ© permet de construire un modÃ¨le performant avec un effort dâ€™annotation minimal.</p>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="le-machine-learning-apprendre-Ã -partir-des-donnÃ©es" class="slide level2" style="font-size:0.7em">
<h2>Le Machine Learning : apprendre Ã  partir des donnÃ©es</h2>
<p>Lâ€™idÃ©e du ML est simple : au lieu de donner des rÃ¨gles Ã  la machine, on lui donne des <strong>exemples</strong> et on la laisse <strong>dÃ©couvrir les rÃ¨gles elle-mÃªme</strong>. Câ€™est une approche <em>bottom-up</em> <span class="citation" data-cites="hartmannComparingAutomatedText2019a">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2019</a>)</span>.</p>
<h3 id="le-workflow-en-3-Ã©tapes">Le workflow en 3 Ã©tapes</h3>
<div class="columns">
<div class="column" style="width:33%;">
<p><strong>1. PrÃ©parer les donnÃ©es</strong></p>
<p>On a besoin dâ€™un corpus dâ€™avis <strong>dÃ©jÃ  Ã©tiquetÃ©s</strong> (positif/nÃ©gatif).</p>
<p><br>
<br>
</p>
<p>Plus on a dâ€™exemples de qualitÃ©, mieux le modÃ¨le apprendra.</p>
</div><div class="column" style="width:33%;">
<p><strong>2. Transformer le texte en chiffres</strong></p>
<p>Un ordinateur ne â€œlitâ€ pas. Il calcule. Il faut transformer les mots en <strong>vecteurs numÃ©riques</strong> (features).</p>
<p><br>
<br>
</p>
<ul>
<li><strong>Approche simple (BoW)</strong> : on compte la frÃ©quence de chaque mot.</li>
<li><strong>Approche avancÃ©e (Embeddings)</strong> : on reprÃ©sente le sens des mots dans un espace vectoriel. <em>(Ã  voir en sÃ©ance 6)</em>.</li>
</ul>
</div><div class="column" style="width:33%;">
<p><strong>3. EntraÃ®ner un modÃ¨le</strong></p>
<p>On choisit un algorithme qui va apprendre Ã  associer les â€œpatternsâ€ numÃ©riques des textes aux Ã©tiquettes.</p>
<p><br>
<br>
</p>
<ul>
<li><strong>ModÃ¨les classiques</strong> : Naive Bayes, RÃ©gression Logistique, SVM.</li>
<li><strong>ModÃ¨les modernes</strong> : RÃ©seaux de neurones (Deep Learning).</li>
</ul>
</div></div>
<div title="L'adaptation au domaine" style="font-size:1em">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Lâ€™adaptation au domaine</strong></p>
</div>
<div class="callout-content">
<p>Avec le Machine Learning, chaque nouveau domaine (ex : luxe, automobile, cosmÃ©tique) nÃ©cessite de <strong>rÃ©entraÃ®ner un modÃ¨le</strong> avec des donnÃ©es propres Ã  ce domaine.<br>
Le modÃ¨le apprend ainsi le vocabulaire et les nuances spÃ©cifiques, lÃ  oÃ¹ un dictionnaire gÃ©nÃ©rique Ã©chouerait.</p>
</div>
</div>
</div>
</div>
</section>
<section id="la-bonne-pratique-du-ml-sÃ©parer-les-donnÃ©es-trainvalidationtest" class="slide level2" style="font-size:0.65em">
<h2>La bonne pratique du ML : sÃ©parer les donnÃ©es (Train/Validation/Test)</h2>
<p>Pour Ã©valuer un modÃ¨le, on doit mesurer sa capacitÃ© Ã  <strong>gÃ©nÃ©raliser</strong>, pas Ã  <strong>mÃ©moriser</strong>. La mÃ©thode standard est de diviser les donnÃ©es en trois ensembles distincts pour simuler un processus dâ€™apprentissage et dâ€™Ã©valuation rÃ©aliste.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="la-division-en-trois-ensembles">La division en trois ensembles</h3>
<p>Notre â€œGold Standardâ€ est scindÃ© pour assigner un rÃ´le unique Ã  chaque partie :</p>
<p><br>
<br>
</p>
<ul>
<li><strong>Jeu dâ€™entraÃ®nement (Train Set) : ~70%</strong> Le <strong>manuel de cours</strong>. Le modÃ¨le utilise ces donnÃ©es pour <strong>apprendre</strong> les rÃ¨gles et les associations. Câ€™est sa seule source de connaissance.</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>Jeu de validation (Validation Set) : ~15%</strong> Lâ€™<strong>examen blanc</strong>. On utilise cet ensemble pour <strong>rÃ©gler</strong> les paramÃ¨tres du modÃ¨le et pour <strong>comparer</strong> diffÃ©rentes versions entre elles. Cela Ã©vite la <strong>fuite dâ€™information</strong> (<em>data leak</em>) vers le jeu de test.</li>
</ul>
<p><br>
</p>
<ul>
<li><strong>Jeu de test (Test Set) : ~15%</strong> Lâ€™<strong>examen final</strong>, sous scellÃ©. On nâ€™utilise cet ensemble quâ€™<strong>une seule et unique fois</strong> Ã  la toute fin, pour obtenir la mesure de <strong>performance finale</strong> et objective du modÃ¨le choisi.</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="le-workflow-classique">Le workflow classique</h3>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-1060488567.png" class="quarto-figure quarto-figure-center" style="width:75.0%"></p>
</figure>
</div>
<div title="Analogie de la prÃ©paration d'un concours">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Analogie de la prÃ©paration dâ€™un concours</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>Le <strong>Train Set</strong>, ce sont les chapitres que lâ€™Ã©tudiant Ã©tudie pour <strong>apprendre</strong>.</p></li>
<li><p>Le <strong>Validation Set</strong>, ce sont les annales et les examens blancs. Lâ€™Ã©tudiant les utilise pour <strong>ajuster sa mÃ©thode de travail</strong> et voir ce qui fonctionne le mieux.</p></li>
<li><p>Le <strong>Test Set</strong>, câ€™est le <strong>sujet officiel du concours</strong>, dÃ©couvert le jour J. La note obtenue est la seule qui compte vraiment pour mesurer son niveau rÃ©el.</p></li>
</ul>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="un-panorama-des-modÃ¨les-de-machine-learning" class="slide level2" style="font-size:0.7em">
<h2>Un panorama des modÃ¨les de Machine Learning</h2>
<p>Tous les modÃ¨les nâ€™ont pas la mÃªme complexitÃ© ni la mÃªme performance. Voici une vue dâ€™ensemble, du plus simple au plus avancÃ©.</p>
<div class="columns">
<div class="column" style="font-size: 0.75em">
<h3 id="ml-classique-supervised-learning">1. ML â€œClassiqueâ€ (Supervised Learning)</h3>
<p>On entraÃ®ne un modÃ¨le de A Ã  Z sur nos propres donnÃ©es Ã©tiquetÃ©es.</p>
<ul>
<li><p><strong>Naive Bayes</strong> : un modÃ¨le probabiliste simple et rapide. Il calcule la probabilitÃ© quâ€™un avis soit positif sachant les mots quâ€™il contient <span class="citation" data-cites="ahmadMachineLearningTechniques2017">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Ahmad et al. 2017</a>)</span>. TrÃ¨s bon comme baseline.</p></li>
<li><p><strong>Support Vector Machine (SVM)</strong> : un classificateur trÃ¨s robuste qui cherche la â€œfrontiÃ¨reâ€ optimale pour sÃ©parer les classes. Il a longtemps Ã©tÃ© lâ€™Ã©tat de lâ€™art pour la classification de texte <span class="citation" data-cites="pangOpinionMiningSentiment">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Pang, Lee, et al. 2008</a>)</span>.</p></li>
</ul>
<p><strong>Le dÃ©fi</strong> : nÃ©cessite beaucoup de donnÃ©es Ã©tiquetÃ©es pour chaque nouveau domaine.</p>
<p><br>
<br>
<br>
</p>
<h3 id="le-deep-learning-et-le-transfer-learning">2. Le Deep Learning et le Transfer Learning</h3>
<p><br>
</p>
<p>On ne part plus de zÃ©ro. On utilise un modÃ¨le <strong>prÃ©-entraÃ®nÃ©</strong> sur des milliards de textes (comme WikipÃ©dia) qui a dÃ©jÃ  une comprÃ©hension gÃ©nÃ©rale du langage.</p>
<p><br>
<br>
</p>
<ul>
<li><strong>Principe</strong> : on prend ce â€œcerveauâ€ prÃ©-entraÃ®nÃ© et on lâ€™affine (<em>fine-tuning</em>) sur notre tÃ¢che spÃ©cifique avec beaucoup moins de donnÃ©es <span class="citation" data-cites="dangSentimentAnalysisBased2020">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Dang, Moreno-GarcÃ­a, and De La Prieta 2020</a>)</span>.</li>
<li><strong>Avantage majeur</strong> : le modÃ¨le peut gÃ©nÃ©raliser et comprendre des nuances quâ€™il nâ€™aurait jamais pu apprendre sur un petit jeu de donnÃ©es.</li>
<li>Câ€™est lâ€™approche qui donne aujourdâ€™hui les <strong>meilleures performances</strong> <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023</a>)</span>.</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="lÃ©chelle-de-la-performance">Lâ€™Ã©chelle de la performance</h3>
<div class="columns">
<div class="column" style="width:50%;">

</div></div>
<div title="Accuracy moyenne [@hartmannMoreFeelingAccuracy2023]">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Accuracy moyenne <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023</a>)</span></strong></p>
</div>
<div class="callout-content">
<p>Une mÃ©ta-analyse sur 272 jeux de donnÃ©es montre une hiÃ©rarchie claire des performances :</p>
<ol type="1">
<li><strong>Transfer Learning (BERT, RoBERTaâ€¦)</strong> : <strong>~90-96%</strong></li>
<li><strong>ML Classique (SVM, etc.)</strong> : <strong>~80-88%</strong></li>
<li><strong>Lexiques (VADER, LIWCâ€¦)</strong> : <strong>~65-75%</strong></li>
</ol>
<p>Le Transfer Learning est en moyenne <strong>+20 points</strong> plus prÃ©cis que les lexiques.</p>
</div>
</div>
</div>
</div>
<div title="Le compromis gÃ©nÃ©ral (interprÃ©tabilitÃ©)">
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Le compromis gÃ©nÃ©ral (interprÃ©tabilitÃ©)</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Lexiques</strong> : <strong>transparence maximale</strong>, mais prÃ©cision limitÃ©e. IdÃ©al pour comprendre le â€œpourquoiâ€ et pour des analyses exploratoires.</li>
<li><strong>ML / Transfer Learning</strong> : <strong>prÃ©cision maximale</strong>, mais plus â€œboÃ®te noireâ€. IdÃ©al pour des systÃ¨mes oÃ¹ la performance prime.</li>
</ul>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="zoom-sur-les-modÃ¨les-classiques-12-naive-bayes" class="slide level2" style="font-size:0.57em">
<h2>Zoom sur les modÃ¨les classiques (1/2) : Naive Bayes</h2>
<p>Le Naive Bayes est un modÃ¨le qui fonctionne comme un <strong>dÃ©tective probabiliste</strong>.<br>
Pour classer un avis, il ne cherche pas de rÃ¨gles complexes, mais se pose une question simple :<br>
<strong>â€œQuelle est la probabilitÃ© que cet avis soit positif, sachant les mots quâ€™il contient ?â€</strong></p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="le-principe-le-thÃ©orÃ¨me-de-bayes">Le principe : le thÃ©orÃ¨me de Bayes</h3>
<p>Tout repose sur le thÃ©orÃ¨me de Bayes, qui permet dâ€™inverser une probabilitÃ©.<br>
On cherche <span class="math inline">\(P(\text{Classe | Mots})\)</span>, mais il est plus simple de calculer lâ€™inverse : <span class="math inline">\(P(\text{Mots | Classe})\)</span>.</p>
<p>Formule gÃ©nÃ©rale :<br>
<span class="math display">\[
P(\text{Classe | Mots}) = \frac{P(\text{Mots | Classe}) \times P(\text{Classe})}{P(\text{Mots})}
\]</span></p>
<p>Comme <span class="math inline">\(P(\text{Mots})\)</span> est identique pour toutes les classes, on lâ€™ignore et on compare seulement les numÃ©rateurs :<br>
<span class="math display">\[
\text{Score}(\text{Classe}) \propto P(\text{Classe}) \times \prod_{i=1}^{n} P(\text{mot}_i | \text{Classe})
\]</span></p>
<ul>
<li><span class="math inline">\(P(\text{Classe})\)</span> : <strong>probabilitÃ© a priori</strong> = frÃ©quence de base dâ€™une classe.<br>
(ex. : si 80% des avis sont positifs, alors <span class="math inline">\(P(\text{positif}) = 0.8\)</span>).<br>
</li>
<li><span class="math inline">\(P(\text{mot}_i | \text{Classe})\)</span> : <strong>vraisemblance</strong> (<em>likelihood</em>) = frÃ©quence dâ€™un mot dans une classe donnÃ©e.<br>
</li>
<li><span class="math inline">\(\prod\)</span> : multiplication des probabilitÃ©s de chaque mot, selon lâ€™hypothÃ¨se <strong>â€œnaÃ¯veâ€</strong> que les mots sont indÃ©pendants.</li>
</ul>
<p><em>(MÃªme si cette hypothÃ¨se est fausse dans la rÃ©alitÃ©, le modÃ¨le reste Ã©tonnamment efficace en pratique.)</em></p>
</div><div class="column" style="width:50%;">
<h3 id="exemple-concret">Exemple concret</h3>
<p>Avis : <em>â€œservice dÃ©cevantâ€</em></p>
<ol type="1">
<li><p><strong>Score positif :</strong><br>
<span class="math display">\[
\text{Score}(\text{positif}) = P(\text{positif}) \times P(\text{"service"|positif}) \times P(\text{"dÃ©cevant"|positif})
\]</span></p></li>
<li><p><strong>Score nÃ©gatif :</strong><br>
<span class="math display">\[
\text{Score}(\text{nÃ©gatif}) = P(\text{nÃ©gatif}) \times P(\text{"service"|nÃ©gatif}) \times P(\text{"dÃ©cevant"|nÃ©gatif})
\]</span></p></li>
</ol>
<p>Le mot <strong>â€œdÃ©cevantâ€</strong> apparaÃ®t trÃ¨s souvent dans les avis nÃ©gatifs et rarement dans les positifs.<br>
MÃªme si <strong>â€œserviceâ€</strong> est neutre, le poids de <strong>â€œdÃ©cevantâ€</strong> fait basculer le score.</p>
<p><br>
<br>
</p>
<p>ğŸ‘‰ Lâ€™avis est classÃ© dans la catÃ©gorie dont le score est le plus Ã©levÃ©.</p>
<div title="ğŸ’¡ Analogie du dÃ©tective">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ’¡ Analogie du dÃ©tective</strong></p>
</div>
<div class="callout-content">
<p>Le Naive Bayes est un dÃ©tective qui a Ã©tudiÃ© des milliers de cas :<br>
- Le <strong>prior</strong> (<span class="math inline">\(P(\text{Classe})\)</span>) = son intuition de base (<em>â€œla plupart des crimes ici sont des volsâ€</em>).<br>
- La <strong>vraisemblance</strong> (<span class="math inline">\(P(\text{mot|Classe})\)</span>) = la valeur de chaque indice (<em>â€œune empreinte digitale de ce type est trÃ¨s souvent liÃ©e au suspect Xâ€</em>).</p>
<p>Il combine les indices pour identifier le coupable le plus probable.</p>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="zoom-sur-les-modÃ¨les-classiques-22-la-rÃ©gression-logistique" class="slide level2" style="font-size:0.60em">
<h2>Zoom sur les modÃ¨les classiques (2/2) : La RÃ©gression Logistique</h2>
<p>La RÃ©gression Logistique est un pilier de la classification. MalgrÃ© son nom, son but nâ€™est pas de prÃ©dire un chiffre continu, mais de calculer la <strong>probabilitÃ© conditionnelle</strong> quâ€™un avis appartienne Ã  une classe (ex : 75% de chance dâ€™Ãªtre â€œpositifâ€), sachant les mots quâ€™il contient.<br>
Elle le fait en transformant un score linÃ©aire grÃ¢ce Ã  une courbe en â€œSâ€.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="le-principe-du-score-Ã -la-probabilitÃ©">Le principe : du score Ã  la probabilitÃ©</h3>
<ol type="1">
<li><p><strong>Calculer un score (Logit)</strong> : Le modÃ¨le calcule un score en additionnant les â€œpoidsâ€ de chaque mot.<br>
Pendant lâ€™entraÃ®nement, il apprend que â€œexcellentâ€ a un poids positif Ã©levÃ©, tandis que â€œdÃ©cevantâ€ a un poids nÃ©gatif fort.</p>
<p><span class="math display">\[
z = b_0 + b_1 x_1 + b_2 x_2 + ... + b_n x_n
\]</span></p>
<ul>
<li><span class="math inline">\(x_i\)</span> : la prÃ©sence ou la frÃ©quence dâ€™un mot dans lâ€™avis.<br>
</li>
<li><span class="math inline">\(b_i\)</span> : le poids appris pour ce mot.<br>
</li>
<li><span class="math inline">\(z\)</span> : le score total, qui peut aller de <span class="math inline">\(-\infty\)</span> Ã  <span class="math inline">\(+\infty\)</span>.</li>
</ul></li>
<li><p><strong>Transformer le score en probabilitÃ©</strong> : Ce score <span class="math inline">\(z\)</span> est ensuite â€œÃ©crasÃ©â€ dans un intervalle [0, 1] grÃ¢ce Ã  la <strong>fonction sigmoÃ¯de (ou logistique)</strong>.<br>
Câ€™est elle qui produit la fameuse courbe en â€œSâ€.</p>
<p><span class="math display">\[
P(y=1|x) = \frac{1}{1 + e^{-z}}
\]</span></p>
<ul>
<li>Si le score <span class="math inline">\(z\)</span> est trÃ¨s grand â†’ la probabilitÃ© est proche de 1.<br>
</li>
<li>Si le score <span class="math inline">\(z\)</span> est trÃ¨s nÃ©gatif â†’ la probabilitÃ© est proche de 0.<br>
</li>
<li>Si le score <span class="math inline">\(z\)</span> est 0 â†’ la probabilitÃ© est de 0.5.<br>
</li>
</ul></li>
</ol>
</div><div class="column" style="width:50%;">
<h3 id="le-processus-de-dÃ©cision">Le processus de dÃ©cision</h3>
<p>Pour un avis donnÃ© :</p>
<ol type="1">
<li>Le modÃ¨le calcule le score <span class="math inline">\(z\)</span> en additionnant les poids des mots prÃ©sents.<br>
</li>
<li>Il applique la fonction sigmoÃ¯de pour obtenir une probabilitÃ©, par exemple <span class="math inline">\(P(\text{positif}) = 0.82\)</span>.<br>
</li>
<li>Il compare cette probabilitÃ© Ã  un seuil de dÃ©cision (par dÃ©faut 0.5).
<ul>
<li>Si <span class="math inline">\(0.82 &gt; 0.5 \rightarrow\)</span> lâ€™avis est classÃ© <strong>Positif</strong>.<br>
</li>
<li>Si <span class="math inline">\(0.21 &lt; 0.5 \rightarrow\)</span> lâ€™avis est classÃ© <strong>NÃ©gatif</strong>.</li>
</ul></li>
</ol>
<div title="ğŸ’¡ Analogie du score de confiance">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ’¡ Analogie du score de confiance</strong></p>
</div>
<div class="callout-content">
<p>La RÃ©gression Logistique calcule un <strong>score de confiance</strong> :</p>
<ul>
<li>Chaque mot ajoute ou retire des points de confiance.<br>
</li>
<li>Un avis plein de mots positifs (â€œrapideâ€, â€œparfaitâ€, â€œexcellentâ€) obtiendra un score trÃ¨s Ã©levÃ©.<br>
</li>
<li>Un avis avec des mots nÃ©gatifs (â€œlentâ€, â€œcassÃ©â€, â€œhorribleâ€) aura un score trÃ¨s bas.</li>
</ul>
<p>La fonction sigmoÃ¯de transforme ce score de confiance en une <strong>probabilitÃ© claire et interprÃ©table</strong> â€” dâ€™oÃ¹ son intÃ©rÃªt en marketing pour comprendre les <em>drivers</em> de la satisfaction.</p>
</div>
</div>
</div>
</div>
</div></div>
</section></section>
<section>
<section id="annotation-Ã©valuation" class="title-slide slide level1 transition-slide-ubdyellow center">
<h1>Annotation &amp; Ã©valuation</h1>

</section>
<section id="lannotation-manuelle-crÃ©er-notre-vÃ©ritÃ©-terrain" class="slide level2" style="font-size: 0.85em">
<h2>Lâ€™annotation manuelle : crÃ©er notre â€œvÃ©ritÃ© terrainâ€</h2>
<p>Avant de pouvoir Ã©valuer un outil, il nous faut une rÃ©fÃ©rence fiable : le <strong>gold standard</strong>. Câ€™est un ensemble de textes que des humains ont lus et Ã©tiquetÃ©s selon des rÃ¨gles prÃ©cises.</p>
<h3 id="principes-dune-bonne-annotation">Principes dâ€™une bonne annotation</h3>
<ul>
<li><strong>SchÃ©ma clair</strong> : dÃ©finir ce quâ€™on annote
<ul>
<li><strong>UnitÃ©</strong> : texte entier, phrase ou extrait spÃ©cifique<br>
</li>
<li><strong>Labels</strong> : polaritÃ© simple (positif / nÃ©gatif / neutre) ou niveau dâ€™intensitÃ© (ex : 1 Ã  5)</li>
</ul></li>
<li><strong>Guide dâ€™annotation</strong> : un document essentiel avec des rÃ¨gles et des exemples de cas limites (ironie, conditionnels) pour assurer la cohÃ©rence.</li>
<li><strong>Double annotation</strong> : au moins deux personnes annotent le mÃªme texte de maniÃ¨re indÃ©pendante.</li>
<li><strong>Adjudication</strong> : en cas de dÃ©saccord, un troisiÃ¨me annotateur (ou un consensus) tranche pour finaliser le gold standard.</li>
</ul>
<div title="ğŸ’¡ Conseil pratique" style="font-size: 0.9em">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ’¡ Conseil pratique</strong></p>
</div>
<div class="callout-content">
<p>Un bon guide dâ€™annotation est la clÃ© de voÃ»te de toute analyse de sentiment rigoureuse. Câ€™est 80% du travail pour obtenir des donnÃ©es fiables.</p>
</div>
</div>
</div>
</div>
</section>
<section id="la-fiabilitÃ©-des-donnÃ©es-laccord-inter-annotateurs-iaa" class="slide level2" style="font-size: 0.8em">
<h2>La fiabilitÃ© des donnÃ©es : lâ€™accord inter-annotateurs (IAA)</h2>
<p><strong>La question clÃ© :</strong> nos annotateurs sont-ils dâ€™accord entre eux, ou est-ce que leurs Ã©tiquettes sont le fruit du hasard ? Lâ€™IAA mesure la cohÃ©rence de leur travail.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="kappa-de-cohen-kappa">Kappa de Cohen (<span class="math inline">\(\kappa\)</span>)</h3>
<p>Mesure lâ€™accord entre <strong>deux</strong> annotateurs, en corrigeant lâ€™accord qui pourrait survenir par chance<sup>1</sup>. <span class="math display">\[
\kappa = \frac{p_o - p_e}{1 - p_e}
\]</span> OÃ¹ <span class="math inline">\(p_o\)</span> est lâ€™accord observÃ© et <span class="math inline">\(p_e\)</span> lâ€™accord attendu par hasard.</p>
</div><div class="column" style="width:50%;">
<h3 id="alpha-de-krippendorff-alpha">Alpha de Krippendorff (<span class="math inline">\(\alpha\)</span>)</h3>
<p>Plus gÃ©nÃ©ral et robuste : fonctionne avec <strong>plus de deux</strong> annotateurs et diffÃ©rents types de labels (nominal, ordinalâ€¦). <span class="math display">\[
\alpha = 1 - \frac{D_o}{D_e}
\]</span> OÃ¹ <span class="math inline">\(D_o\)</span> est le dÃ©saccord observÃ© et <span class="math inline">\(D_e\)</span> le dÃ©saccord attendu par hasard.</p>
</div></div>
<div title="ğŸ¯ Objectif">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>ğŸ¯ Objectif</strong></p>
</div>
<div class="callout-content">
<p>On vise un score <strong>Kappa/Alpha â‰¥ 0.70</strong>. En dessous, cela signifie que le guide dâ€™annotation nâ€™est pas assez clair et doit Ãªtre amÃ©liorÃ©. Un IAA Ã©levÃ© garantit que notre â€œvÃ©ritÃ© terrainâ€ est solide.</p>
</div>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn1"><p>Dâ€™autres mesures existent, comme le Kappa de Fleiss (extension Ã  plusieurs annotateurs) ou lâ€™ICC (Intraclass Correlation Coefficient) pour des variables continues.</p></li></ol></aside></section>
<section id="exemple-interprÃ©tation-des-scores" class="slide level2" style="font-size: 0.8em">
<h2>Exemple &amp; interprÃ©tation des scores</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="exemple-de-calcul-kappa-de-cohen">Exemple de calcul (Kappa de Cohen)</h3>
<p>Deux annotateurs classent 50 tweets (<em>positif/nÃ©gatif</em>).</p>
<ul>
<li>Accord observÃ© : 40/50 â†’ <span class="math inline">\(p_o = 0.8\)</span><br>
</li>
<li>Accord attendu par hasard : <span class="math inline">\(p_e = 0.5\)</span></li>
</ul>
<p><span class="math display">\[
\kappa = \frac{0.8 - 0.5}{1 - 0.5} = 0.6
\]</span></p>
<div class="callout-example" title="InterprÃ©tation">
<p><span class="math inline">\(\kappa = 0.6\)</span> â†’ <strong>accord modÃ©rÃ© Ã  substantiel</strong>, mais amÃ©liorable.</p>
<div title="Remarque sur l'interprÃ©tation" style="font-size: 0.8em">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Remarque sur lâ€™interprÃ©tation</strong></p>
</div>
<div class="callout-content">
<p>Les seuils proposÃ©s par Landis et Koch <span class="citation" data-cites="landisMeasurementObserverAgreement1977">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Landis and Koch 1977</a>)</span> sont devenus une rÃ©fÃ©rence, mais ils sont <strong>arbitraires</strong> et parfois jugÃ©s trop tolÃ©rants.<br>
McHugh <span class="citation" data-cites="mchugh2012interrater">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">McHugh 2012</a>)</span> recommande des critÃ¨res plus stricts, considÃ©rant quâ€™un accord Â« acceptable Â» ne devrait pas Ãªtre en dessous de <strong>0.80</strong> en contexte scientifique ou mÃ©dical.</p>
</div>
</div>
</div>
</div>
</div>
</div><div class="column" style="font-size: 0.8em">
<h3 id="interprÃ©tation-des-scores">InterprÃ©tation des scores</h3>
<table class="caption-top">
<thead>
<tr class="header">
<th>Valeur de Îº / Î±</th>
<th>InterprÃ©tation selon Landis &amp; Koch (1977)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt; 0.00</td>
<td>Poor</td>
</tr>
<tr class="even">
<td>0.00 â€“ 0.20</td>
<td>Slight</td>
</tr>
<tr class="odd">
<td>0.21 â€“ 0.40</td>
<td>Fair</td>
</tr>
<tr class="even">
<td>0.41 â€“ 0.60</td>
<td>Moderate</td>
</tr>
<tr class="odd">
<td>0.61 â€“ 0.80</td>
<td>Substantial</td>
</tr>
<tr class="even">
<td>0.81 â€“ 1.00</td>
<td>Almost perfect</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href=""></a><span class="fu">library</span>(irr)</span>
<span id="cb1-2"><a href=""></a><span class="co"># Exemple : 2 annotateurs classent 50 tweets (positif/nÃ©gatif)</span></span>
<span id="cb1-3"><a href=""></a><span class="co"># On crÃ©e une matrice items Ã— annotateurs</span></span>
<span id="cb1-4"><a href=""></a><span class="co"># Ici : 40 accords, 10 dÃ©saccords</span></span>
<span id="cb1-5"><a href=""></a>annotateur1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"positif"</span>, <span class="dv">20</span>), <span class="fu">rep</span>(<span class="st">"nÃ©gatif"</span>, <span class="dv">20</span>), <span class="fu">rep</span>(<span class="st">"positif"</span>, <span class="dv">5</span>), <span class="fu">rep</span>(<span class="st">"nÃ©gatif"</span>, <span class="dv">5</span>))</span>
<span id="cb1-6"><a href=""></a>annotateur2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"positif"</span>, <span class="dv">20</span>), <span class="fu">rep</span>(<span class="st">"nÃ©gatif"</span>, <span class="dv">20</span>), <span class="fu">rep</span>(<span class="st">"nÃ©gatif"</span>, <span class="dv">5</span>), <span class="fu">rep</span>(<span class="st">"positif"</span>, <span class="dv">5</span>))</span>
<span id="cb1-7"><a href=""></a>annotations <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(annotateur1, annotateur2)</span>
<span id="cb1-8"><a href=""></a><span class="fu">kappa2</span>(annotations, <span class="st">"unweighted"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Cohen's Kappa for 2 Raters (Weights: unweighted)

 Subjects = 50 
   Raters = 2 
    Kappa = 0.6 

        z = 4.24 
  p-value = 2.21e-05 </code></pre>
</div>
</div>
</div></div>
</section>
<section id="exemple-interprÃ©tation-de-lalpha-de-krippendorff" class="slide level2" style="font-size: 0.8em">
<h2>Exemple &amp; interprÃ©tation de lâ€™Alpha de Krippendorff</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="exemple-de-calcul">Exemple de calcul</h3>
<p>Trois annotateurs Ã©valuent 5 items (<em>positif/nÃ©gatif</em>).</p>
<ul>
<li>DÃ©saccord observÃ© : <span class="math inline">\((D_o \approx 0.27)\)</span></li>
<li>DÃ©saccord attendu : <span class="math inline">\((D_e \approx 0.48)\)</span></li>
</ul>
<p><span class="math display">\[
\alpha = 1 - \frac{0.27}{0.48} \approx 0.463
\]</span></p>
<div class="callout-example" title="InterprÃ©tation">
<p>(= 0.463) â†’ Accord <strong>insuffisant</strong> (&lt; 0.67) â†’ guide/formation Ã  amÃ©liorer.</p>
</div>
</div><div class="column" style="width:50%;">
<h3 id="interprÃ©tation-des-scores-1">InterprÃ©tation des scores</h3>
<div title="Comment lire Î±" style="font-size: 0.8em">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Comment lire Î±</strong></p>
</div>
<div class="callout-content">
<ul>
<li>(D_o) = dÃ©saccord observÃ© (proportion de dÃ©saccords rÃ©els entre juges).<br>
</li>
<li>(D_e) = dÃ©saccord attendu <strong>par hasard</strong>, calculÃ© Ã  partir de la distribution globale des catÃ©gories.</li>
</ul>
<p>Selon <span class="citation" data-cites="krippendorff2018content">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Krippendorff 2018</a>)</span> :<br>
- <strong>Î± â‰¥ 0.80</strong> â†’ Accord <strong>fiable</strong> (analyses solides)<br>
- <strong>0.67 â‰¤ Î± &lt; 0.80</strong> â†’ Accord <strong>acceptable</strong> (exploratoire)<br>
- <strong>Î± &lt; 0.67</strong> â†’ Accord <strong>insuffisant</strong>, guide dâ€™annotation Ã  amÃ©liorer</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href=""></a><span class="fu">library</span>(irr)</span>
<span id="cb3-2"><a href=""></a>annotations <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb3-3"><a href=""></a>  <span class="at">annotateur1 =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb3-4"><a href=""></a>  <span class="at">annotateur2 =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb3-5"><a href=""></a>  <span class="at">annotateur3 =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb3-6"><a href=""></a>)</span>
<span id="cb3-7"><a href=""></a><span class="co"># La fonction kripp.alpha attend une matrice items Ã— juges</span></span>
<span id="cb3-8"><a href=""></a>result <span class="ot">&lt;-</span> <span class="fu">kripp.alpha</span>(<span class="fu">t</span>(<span class="fu">as.matrix</span>(annotations)), <span class="at">method =</span> <span class="st">"nominal"</span>)</span>
<span id="cb3-9"><a href=""></a>result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> Krippendorff's alpha

 Subjects = 5 
   Raters = 3 
    alpha = 0.463 </code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="la-base-de-lÃ©valuation-la-matrice-de-confusion" class="slide level2" style="font-size: 0.85em">
<h2>La base de lâ€™Ã©valuation : la matrice de confusion</h2>
<p>Maintenant que nous avons un gold standard fiable, nous pouvons juger notre outil. La matrice de confusion est le point de dÃ©part : elle montre oÃ¹ le modÃ¨le a eu raison et oÃ¹ il sâ€™est trompÃ©.</p>
<p>Imaginons quâ€™on veuille dÃ©tecter les commentaires <strong>nÃ©gatifs</strong> (la classe â€œpositiveâ€ de notre analyse) :</p>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th>PrÃ©dit : <strong>nÃ©gatif</strong></th>
<th>PrÃ©dit : <strong>OK</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>RÃ©el : nÃ©gatif</strong></td>
<td><strong>TP</strong> (vrai positif)</td>
<td><strong>FN</strong> (faux nÃ©gatif)</td>
</tr>
<tr class="even">
<td><strong>RÃ©el : OK</strong></td>
<td><strong>FP</strong> (faux positif)</td>
<td><strong>TN</strong> (vrai nÃ©gatif)</td>
</tr>
</tbody>
</table>
<p><br>
</p>
<ul>
<li><strong>TP (true positive)</strong> : lâ€™alerte Ã©tait justifiÃ©e. Câ€™est un commentaire nÃ©gatif, et on lâ€™a bien dÃ©tectÃ©. <strong>Bravo</strong></li>
<li><strong>FN (false negative)</strong> : <strong>lâ€™alerte manquÃ©e !</strong> Câ€™Ã©tait un commentaire nÃ©gatif, mais on lâ€™a ratÃ©. <strong>Danger !</strong></li>
<li><strong>FP (false positive)</strong> : <strong>la fausse alerte.</strong> On a cru que câ€™Ã©tait nÃ©gatif, mais Ã§a ne lâ€™Ã©tait pas. <strong>Bruit.</strong></li>
<li><strong>TN (true negative)</strong> : on a bien ignorÃ© un commentaire non-nÃ©gatif. <strong>Correct.</strong></li>
</ul>
</section>
<section id="matrice-de-confusion-multiclasse-analyse-de-sentiment" class="slide level2" style="font-size: 0.4em">
<h2>Matrice de confusion multiclasse (analyse de sentiment)</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-1562987940.png" class="quarto-figure quarto-figure-center" style="width:50.0%"></p>
</figure>
</div>
<h3 id="interprÃ©tation-de-la-matrice-de-confusion-10-000-avis">InterprÃ©tation de la matrice de confusion (10 000 avis)</h3>
<div class="columns">
<div class="column">
<h4 id="performance-gÃ©nÃ©rale">Performance gÃ©nÃ©rale</h4>
<p>Sur 10 000 avis, le modÃ¨le a correctement classÃ© <strong>7 692</strong> dâ€™entre eux, soit une <strong>prÃ©cision globale de 76,9%</strong>.</p>
<ul>
<li><strong>Avis NÃ©gatifs</strong> : <strong>2 107</strong> correctement identifiÃ©s sur 3 053.</li>
<li><strong>Avis Neutres</strong> : <strong>1 636</strong> correctement identifiÃ©s sur 2 023.</li>
<li><strong>Avis Positifs</strong> : <strong>3 949</strong> correctement identifiÃ©s sur 4 924. Le modÃ¨le est particuliÃ¨rement performant pour cette classe.</li>
</ul>
</div><div class="column">
<h4 id="analyse-des-erreurs-principales">Analyse des erreurs principales</h4>
<p>Les erreurs les plus frÃ©quentes se situent dans la confusion avec la classe <strong>Neutre</strong>.</p>
<ul>
<li><strong>Erreur majeure nÂ°1</strong> : <strong>739</strong> avis <strong>positifs</strong> ont Ã©tÃ© classÃ©s Ã  tort comme <strong>neutres</strong>. Le modÃ¨le peine Ã  identifier un sentiment positif peu prononcÃ©.</li>
<li><strong>Erreur majeure nÂ°2</strong> : <strong>620</strong> avis <strong>nÃ©gatifs</strong> ont Ã©tÃ© classÃ©s Ã  tort comme <strong>neutres</strong>. De mÃªme, le sentiment nÃ©gatif lÃ©ger semble difficile Ã  capter.</li>
</ul>
<h5 id="pistes-damÃ©lioration">Pistes dâ€™amÃ©lioration</h5>
<ul>
<li><strong>Affiner la distinction</strong> : Le modÃ¨le pourrait Ãªtre amÃ©liorÃ© en lui fournissant plus dâ€™exemples dâ€™avis Ã  la frontiÃ¨re entre â€œNeutreâ€ et â€œPositif/NÃ©gatifâ€.</li>
<li><strong>Analyse des faux nÃ©gatifs/positifs</strong> : Examiner les 739 avis positifs et 620 avis nÃ©gatifs mal classÃ©s pour comprendre les mots ou tournures de phrases qui trompent le modÃ¨le.</li>
</ul>
</div></div>
</section>
<section id="le-dilemme-du-marketeur-prÃ©cision-vs.-rappel" class="slide level2" style="font-size: 0.65em">
<h2>Le dilemme du marketeur : prÃ©cision vs.&nbsp;rappel</h2>
<p>Lâ€™accuracy (taux de bonnes prÃ©dictions) est souvent trompeuse. La prÃ©cision et le rappel rÃ©pondent Ã  des besoins mÃ©tier trÃ¨s diffÃ©rents.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="prÃ©cision-precision">PrÃ©cision (precision)</h3>
<p><span class="math display">\[
\mathrm{P} = \frac{TP}{TP + FP}
\]</span></p>
<p><strong>La question mÃ©tier :</strong> quand mon systÃ¨me sonne une alerte, est-ce que je peux lui faire confiance ?</p>
<ul>
<li>Une <strong>haute prÃ©cision</strong> signifie que lâ€™on a peu de fausses alertes (peu de FP).</li>
<li><strong>PrioritÃ© :</strong> ne pas dÃ©ranger les Ã©quipes pour rien, ne pas contacter Ã  tort des clients supposÃ©s mÃ©contents. Câ€™est la mÃ©trique de la <strong>fiabilitÃ©</strong>.</li>
</ul>
<h3 id="rappel-recall">Rappel (recall)</h3>
<p><span class="math display">\[
\mathrm{R} = \frac{TP}{TP + FN}
\]</span> <strong>La question mÃ©tier :</strong> suis-je sÃ»r dâ€™avoir identifiÃ© TOUS les vrais commentaires nÃ©gatifs ?</p>
<ul>
<li>Un <strong>haut rappel</strong> signifie que lâ€™on a ratÃ© trÃ¨s peu de vrais problÃ¨mes (peu de FN).</li>
<li><strong>PrioritÃ© :</strong> dÃ©tecter une crise Ã  tout prix, mÃªme si cela gÃ©nÃ¨re quelques fausses alertes. Câ€™est la mÃ©trique de lâ€™<strong>exhaustivitÃ©</strong>.</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="f1-score">F1-score</h3>
<p><span class="math display">\[
\mathrm{F1} = \frac{2 \times P \times R}{P + R}
\]</span> <strong>La question mÃ©tier :</strong> comment trouver le meilleur Ã©quilibre entre fiabilitÃ© et exhaustivitÃ© ?</p>
<p>Le <strong>F1-score</strong> est une moyenne qui pÃ©nalise les modÃ¨les qui sacrifient trop lâ€™une des deux mÃ©triques. <strong>Câ€™est la mÃ©trique par dÃ©faut pour une Ã©valuation Ã©quilibrÃ©e.</strong></p>
<p><br>
<br>
<br>
<br>
</p>
<div title="Analogie marketing" style="font-size: 1.2em">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Analogie marketing</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Haute prÃ©cision</strong> : votre campagne de retargeting est trÃ¨s efficace (haut taux de conversion), mais nâ€™a touchÃ© quâ€™un petit segment.</li>
<li><strong>Haut rappel</strong> : votre campagne TV a touchÃ© tout le monde (couverture maximale), mais avec un faible impact.</li>
<li><strong>Haut F1-score</strong> : vous avez touchÃ© une large part de votre cible avec un impact significatif.</li>
</ul>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="le-dÃ©fi-des-donnÃ©es-rÃ©elles-des-distributions-asymÃ©triques" class="slide level2" style="font-size: 0.70em">
<h2>Le dÃ©fi des donnÃ©es rÃ©elles : des distributions asymÃ©triques</h2>
<p>Contrairement Ã  une idÃ©e reÃ§ue, les avis en ligne sont rarement â€œÃ©quilibrÃ©sâ€. En rÃ©alitÃ©, leur distribution est presque toujours <strong>fortement asymÃ©trique</strong> (<em>skewed</em>), suivant souvent une forme visuelle de <strong>courbe en â€œJâ€</strong> <span class="citation" data-cites="pangOpinionMiningSentiment">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Pang, Lee, et al. 2008, 50</a>)</span>.</p>
<p>Lâ€™asymÃ©trie dÃ©pend fortement de la plateforme (biais dâ€™auto-sÃ©lection) :</p>
<ul>
<li><strong>Majoritairement positifs</strong> : sur les plateformes oÃ¹ lâ€™avis est un acte de recommandation ou de construction de rÃ©putation (ex: <strong>Airbnb</strong>, la plupart des produits sur <strong>Amazon</strong>), on observe une avalanche dâ€™avis trÃ¨s positifs (4-5 Ã©toiles).</li>
<li><strong>Majoritairement nÃ©gatifs</strong> : sur les plateformes perÃ§ues comme un lieu de rÃ©clamation ou de vigilance (ex: <strong>Trustpilot</strong> pour certains services, forums de support technique), les avis nÃ©gatifs peuvent dominer.</li>
</ul>
<div title="Le piÃ¨ge de l'accuracy reste le mÃªme">
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Le piÃ¨ge de lâ€™accuracy reste le mÃªme</strong></p>
</div>
<div class="callout-content">
<p>Que vous ayez 90% dâ€™avis positifs ou 90% de nÃ©gatifs, le problÃ¨me de fond demeure : lâ€™<strong>accuracy est une mÃ©trique dangereuse</strong>. Un modÃ¨le qui prÃ©dit toujours la classe majoritaire aura un score Ã©levÃ© mais sera inutile pour dÃ©tecter les signaux faibles (la crise qui dÃ©marre ou les clients ambassadeurs).</p>
</div>
</div>
</div>
</div>
<h3 id="les-bonnes-mÃ©triques-pour-les-donnÃ©es-dÃ©sÃ©quilibrÃ©es">Les bonnes mÃ©triques pour les donnÃ©es dÃ©sÃ©quilibrÃ©es</h3>
<ul>
<li><p><strong>F1-macro</strong> : on calcule le F1-score pour chaque classe (+, 0, -), puis on fait la <strong>moyenne simple</strong>. Chaque classe a le mÃªme poids, quâ€™elle soit rare ou frÃ©quente. Câ€™est le <strong>standard</strong> pour rapporter la performance en analyse de sentiment.</p></li>
<li><p><strong>Balanced accuracy</strong> : câ€™est la moyenne des rappels de chaque classe. Simple et juste.</p></li>
</ul>
<p><span class="math display">\[
\mathrm{BAcc}=\tfrac{1}{2}\big(\text{Rappel}_{Pos} + \text{Rappel}_{Neg}\big)
\]</span></p>
</section>
<section id="au-delÃ -des-labels-Ã©valuer-les-scores" class="slide level2" style="font-size: 0.75em">
<h2>Au-delÃ  des labels : Ã©valuer les scores</h2>
<p>Beaucoup dâ€™outils (VADER, LIWC) produisent un <strong>score continu</strong> (ex : -0.87) plutÃ´t quâ€™un label. On peut lâ€™Ã©valuer de deux faÃ§ons.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="seuil-de-dÃ©cision-tau">1. Seuil de dÃ©cision (<span class="math inline">\(\tau\)</span>)</h3>
<p>On transforme le score en label via un seuil (souvent avec une <strong>zone neutre</strong>).<br>
- Ex. : score &gt; 0.1 â†’ positif ; score &lt; -0.1 â†’ nÃ©gatif ; sinon neutre.<br>
- Seuil bas â†’ rappel â†‘ mais prÃ©cision â†“.<br>
- Seuil haut â†’ prÃ©cision â†‘ mais rappel â†“.</p>
<h3 id="Ã©valuer-le-score-brut">2. Ã‰valuer le score brut</h3>
<ul>
<li><strong>CorrÃ©lation (Spearman)</strong> : est-ce que lâ€™outil classe bien les avis du pire au meilleur ?<br>
</li>
<li><strong>MAE</strong> : compare le score normalisÃ© Ã  la note en Ã©toile.<br>
</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="courbes-p-r-et-roc">Courbes P-R et ROC</h3>
<p>En faisant varier le seuil :<br>
- <strong>ROC</strong> : compromis sensibilitÃ© vs spÃ©cificitÃ©.<br>
- <strong>P-R</strong> : utile quand la classe positive est rare.</p>
<div title="âš ï¸ Attention au dÃ©sÃ©quilibre">
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>âš ï¸ Attention au dÃ©sÃ©quilibre</strong></p>
</div>
<div class="callout-content">
<p>Lâ€™AUPRC nâ€™est pas toujours â€œmeilleureâ€ : le choix de la mÃ©trique dÃ©pend de lâ€™<strong>objectif mÃ©tier</strong> <span class="citation" data-cites="mcdermottCloserLookAUROC2025">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">McDermott et al. 2025</a>)</span>.</p>
</div>
</div>
</div>
</div>
</div></div>
<div title="Quel seuil choisir ?">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Quel seuil choisir ?</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Crise (ne rien rater)</strong> â†’ seuil bas â†’ rappel â†‘.<br>
</li>
<li><strong>FidÃ©lisation (Ã©viter les erreurs)</strong> â†’ seuil haut â†’ prÃ©cision â†‘.<br>
</li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="synthÃ¨se-pratique-quelle-mÃ©trique-pour-quel-outil" class="slide level2" style="font-size: 0.75em">
<h2>SynthÃ¨se pratique : quelle mÃ©trique pour quel outil ?</h2>
<p>Un guide pour Ã©valuer les outils que vous utiliserez en TP et pour vos projets.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="comprendre-la-sortie-de-loutil">1. Comprendre la sortie de lâ€™outil</h3>
<ul>
<li><strong>VADER, NRC, syuzhet, LIWC</strong> produisent principalement des <strong>scores</strong>.</li>
<li>Votre premiÃ¨re Ã©tape sera toujours de <strong>dÃ©finir des seuils</strong> pour les convertir en labels <code>(+, 0, -)</code>.</li>
</ul>
<h3 id="le-rapport-de-performance-idÃ©al">2. Le rapport de performance idÃ©al</h3>
<p>Pour un projet dâ€™analyse de sentiment, votre rapport dâ€™Ã©valuation devrait contenir :</p>
<ol type="1">
<li>La <strong>matrice de confusion</strong> pour visualiser les erreurs.</li>
<li>Le <strong>F1-score macro</strong> comme indicateur principal de la performance.</li>
<li>La <strong>corrÃ©lation de Spearman</strong> pour Ã©valuer la qualitÃ© du classement par score.</li>
<li>La <strong>couverture du lexique</strong> : quel % de mots lâ€™outil a-t-il reconnu ? Un score basÃ© sur 10% du texte est peu fiable.</li>
</ol>
</div><div class="column" style="width:50%;">
<h3 id="checklist-danalyse-derreurs">3. Checklist dâ€™analyse dâ€™erreurs</h3>
<p>Une bonne mÃ©trique ne suffit pas. Il faut comprendre <strong>pourquoi</strong> lâ€™outil se trompe.</p>
<ul>
<li>Lâ€™outil gÃ¨re-t-il bien la <strong>nÃ©gation</strong> ? (<em>â€œpas mauvaisâ€</em>)</li>
<li>Comprend-il les <strong>adversatifs</strong> ? (<em>â€œbeau mais lentâ€</em>)</li>
<li>Est-il sensible Ã  lâ€™<strong>intensitÃ©</strong> ? <em>â€œun peu dÃ©Ã§uâ€ vs â€œtotalement dÃ©goÃ»tÃ©â€</em>)</li>
<li>Est-il adaptÃ© Ã  votre <strong>domaine</strong> ? (ex: le mot â€œfroidâ€ est nÃ©gatif pour un plat, mais positif pour une biÃ¨re).</li>
</ul>
<div title="Le conseil final">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Le conseil final</strong></p>
</div>
<div class="callout-content">
<p>Aucune mÃ©trique nâ€™est parfaite. La meilleure approche est de <strong>combiner une mÃ©trique quantitative robuste (F1-macro) avec une analyse qualitative des erreurs</strong> pour vraiment comprendre les forces et les faiblesses de votre systÃ¨me.</p>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="piÃ¨ges-Ã -Ã©viter-en-analyse-de-sentiment" class="slide level2" style="font-size:0.80em">
<h2>PiÃ¨ges Ã  Ã©viter en analyse de sentiment</h2>
<p>MÃªme les meilleurs outils peuvent se tromper. Voici les piÃ¨ges les plus courants Ã  anticiper :</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="piÃ¨ges-linguistiques">PiÃ¨ges Linguistiques</h3>
<ul>
<li><strong>AmbiguÃ¯tÃ©s</strong> : lâ€™implicite, lâ€™ironie et le sarcasme peuvent totalement inverser la polaritÃ© et sont trÃ¨s difficiles Ã  dÃ©tecter automatiquement.</li>
<li><strong>PortÃ©e des â€œshiftersâ€</strong> : une nÃ©gation ou un adversatif (â€œmaisâ€) mal interprÃ©tÃ© peut fausser lâ€™analyse dâ€™une phrase entiÃ¨re.</li>
</ul>
<h3 id="piÃ¨ges-mÃ©thodologiques">PiÃ¨ges MÃ©thodologiques</h3>
<ul>
<li><strong>DÃ©pendance au domaine</strong> : un lexique entraÃ®nÃ© sur des avis de restaurants sera mÃ©diocre pour analyser des tweets financiers. Le vocabulaire et le contexte changent tout.</li>
<li><strong>Biais des lexiques</strong> : un dictionnaire gÃ©nÃ©rique peut contenir des biais culturels ou Ãªtre inadaptÃ© au langage spÃ©cifique de certaines communautÃ©s en ligne (argot, mÃ¨mes).</li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="piÃ¨ges-liÃ©s-aux-donnÃ©es-et-Ã -lÃ©thique">PiÃ¨ges liÃ©s aux DonnÃ©es et Ã  lâ€™Ã‰thique</h3>
<ul>
<li><strong>Spam dâ€™opinion (Fake Reviews)</strong> : la prÃ©sence dâ€™avis frauduleux (positifs ou nÃ©gatifs) peut complÃ¨tement fausser vos KPIs. La dÃ©tection de spam est un enjeu majeur.</li>
<li><strong>QualitÃ© des donnÃ©es</strong> : des textes trÃ¨s courts, mal Ã©crits ou remplis dâ€™emojis peuvent dÃ©grader la performance de nâ€™importe quel modÃ¨le.</li>
</ul>
</div></div>
</section>
<section id="de-la-question-marketing-au-rapport-final-la-checklist-dun-projet-rÃ©ussi" class="slide level2" style="font-size:0.70em">
<h2>De la question marketing au rapport final : la checklist dâ€™un projet rÃ©ussi</h2>
<p>Un projet dâ€™analyse de sentiment rÃ©ussi repose sur la <strong>mÃ©thode</strong> autant que sur les outils. Voici les Ã©tapes clÃ©s.</p>
<h3 id="cadrer-la-question">1. Cadrer la question</h3>
<p>Tout part dâ€™un objectif mÃ©tier traduit en question analytique claire <span class="citation" data-cites="krugmannSentimentAnalysisAge2024a">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Krugmann and Hartmann 2024</a>)</span>.</p>
<ul>
<li><em>Buzz positif autour du lancement ?</em> â†’ <strong>Classification binaire</strong><br>
</li>
<li><em>Points forts et faibles perÃ§us ?</em> â†’ <strong>Analyse par aspect (ABSA)</strong><br>
</li>
<li><em>Comparaison avec un concurrent ?</em> â†’ <strong>Analyse comparative</strong></li>
</ul>
<h3 id="choisir-lapproche">2. Choisir lâ€™approche</h3>
<ul>
<li><strong>Lexiques + rÃ¨gles</strong> : transparence, rapiditÃ©, exploration.<br>
</li>
<li><strong>Machine Learning</strong> : performance et adaptation (+20 points en moyenne <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023</a>)</span>).</li>
</ul>
<h3 id="prÃ©parer-les-donnÃ©es">3. PrÃ©parer les donnÃ©es</h3>
<ul>
<li><strong>ML</strong> : constituer un <strong>Gold Standard</strong> de qualitÃ© (annotation claire, double codage, accord inter-annotateurs).<br>
</li>
<li><strong>Lexiques</strong> : adapter le vocabulaire au domaine et contrÃ´ler les contresens.</li>
</ul>
<h3 id="Ã©valuer-et-analyser">4. Ã‰valuer et analyser</h3>
<ul>
<li><strong>Quantitatif</strong> : prÃ©fÃ©rer matrice de confusion &amp; F1-macro Ã  lâ€™accuracy seule.<br>
</li>
<li><strong>Qualitatif</strong> : analyser les erreurs (nÃ©gation, ironie, implicite).<br>
</li>
<li><strong>Robustesse</strong> : tester sur dâ€™autres plateformes ou pÃ©riodes.</li>
</ul>
</section>
<section id="conclusion-de-lartisanat-Ã -lautomatisation-intelligente" class="slide level2" style="font-size:0.62em">
<h2>Conclusion : de lâ€™artisanat Ã  lâ€™automatisation intelligente</h2>
<p>Lâ€™analyse de sentiment a connu une rÃ©volution. Nous sommes passÃ©s dâ€™approches manuelles Ã  des outils capables de comprendre le langage avec une finesse sans prÃ©cÃ©dent.</p>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="lÃ©volution-des-mÃ©thodes">Lâ€™Ã©volution des mÃ©thodes</h3>
<ul>
<li><p><strong>Hier : lexiques &amp; rÃ¨gles (artisanat)</strong> : MÃ©thodes transparentes et contrÃ´lables, excellentes pour lâ€™exploration et pour tester des hypothÃ¨ses thÃ©oriques <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023, 84</a>)</span>.</p></li>
<li><p><strong>Aujourdâ€™hui : Machine Learning &amp; Deep Learning (industrialisation)</strong> : Apprentissage sur donnÃ©es pour une meilleure adaptation au contexte et des performances nettement supÃ©rieures <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023, 76</a>)</span>.</p></li>
<li><p><strong>Demain (et dÃ©jÃ  maintenant) : LLMs / IA gÃ©nÃ©rative</strong> : ComprÃ©hension contextuelle â€œsur Ã©tagÃ¨reâ€ (<em>zero-shot</em>) qui rivalise avec les modÃ¨les spÃ©cialisÃ©s, posant de nouveaux enjeux de reproductibilitÃ© et dâ€™Ã©thique <span class="citation" data-cites="krugmannSentimentAnalysisAge2024a">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Krugmann and Hartmann 2024, 2, 16</a>)</span>.</p></li>
</ul>
</div><div class="column" style="width:50%;">
<h3 id="les-implications-pour-le-marketing">Les implications pour le marketing</h3>
<ul>
<li><p><strong>De la description Ã  la prÃ©diction</strong> : Au-delÃ  du comptage pos/neg : anticipation de tendances (ex: cours de la bourse) et dÃ©tection de signaux faibles de crise <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023, 76</a>)</span>.</p></li>
<li><p><strong>Connaissance client hyper-granulaire</strong> : Les nuances dans des milliers de verbatims permettent dâ€™affiner les personas, de personnaliser les messages et dâ€™identifier des besoins non satisfaits pour lâ€™innovation <span class="citation" data-cites="agarwalProminentFeatureExtraction2016">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Agarwal and Mittal 2016, 3</a>)</span>.</p></li>
<li><p><strong>Vigilance stratÃ©gique en continu</strong> : Lâ€™e-rÃ©putation devient un <strong>flux</strong> dâ€™information en temps rÃ©el qui peut alimenter des tableaux de bord et la prise de dÃ©cision au quotidien <span class="citation" data-cites="ahmadMachineLearningTechniques2017">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Ahmad et al. 2017, 3</a>)</span>.</p></li>
</ul>
</div></div>
<div title="Le message final">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Le message final</strong></p>
</div>
<div class="callout-content">
<p>La technologie devient de plus en plus puissante et accessible. Le rÃ´le de lâ€™expert marketing nâ€™est plus de connaÃ®tre chaque dÃ©tail technique, mais de <strong>poser les bonnes questions</strong>, dâ€™<strong>interprÃ©ter avec esprit critique</strong> et de <strong>dÃ©cider</strong> Ã  partir dâ€™insights fiables <span class="citation" data-cites="hartmannMoreFeelingAccuracy2023">(<a href="#/rÃ©fÃ©rences" role="doc-biblioref" onclick="">Hartmann et al. 2023</a>)</span>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="rÃ©fÃ©rences" class="slide level2 smaller scrollable">
<h2>RÃ©fÃ©rences</h2>

<script> window._input_file = "---\n" + "title: \"Ã‰tudes qualitatives sur le web (netnographie)\"\n" + "subtitle: \"Analyse de sentiment et opinions\"\n" + "author:\n" + "  - name: \"Olivier Caron\"\n" + "    affiliations: \"Paris Dauphine - PSL\"\n" + "format:\n" + "  ubd-revealjs:\n" + "    self-contained: false\n" + "    chalkboard: true\n" + "    transition: fade\n" + "    auto-stretch: false\n" + "    width: 1250\n" + "    height: 760\n" + "    toc: false\n" + "    toc-depth: 1\n" + "    code-block-height: 700px\n" + "execute:\n" + "  echo: true\n" + "bibliography: refs.bib\n" + "revealjs-plugins:\n" + "  - editable\n" + "filters:\n" + "  - editable\n" + "editor: \n" + "  markdown: \n" + "    wrap: 72\n" + "---\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Objectifs du cours {style=\"font-size:0.75em\"}\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "**1. Comprendre et modÃ©liser les opinions**\n" + "\n" + "-   DÃ©finir et distinguer **opinion**, **subjectivitÃ©** et **polaritÃ©**.\n" + "-   MaÃ®triser les **niveaux d'analyse** (document, phrase, aspect) et\n" + "    leur pertinence marketing.\n" + "-   Identifier les **phÃ©nomÃ¨nes linguistiques** qui influencent le\n" + "    sentiment (nÃ©gation, intensitÃ©, \"mais\"...).\n" + "\n" + "\\n" + "\\n" + "\n" + "**2. MaÃ®triser les approches classiques**\n" + "\n" + "\\n" + "\\n" + "\n" + "-   Appliquer des mÃ©thodes basÃ©es sur des **lexiques** et des\n" + "    **rÃ¨gles**.\n" + "-   Comprendre comment **adapter un lexique** Ã  un domaine spÃ©cifique\n" + "    (induction *corpus-based*).\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "**3. Comprendre le Machine Learning pour l'analyse de sentiment**\n" + "\n" + "-   Comprendre les principes des apprentissages **supervisÃ©** et **non\n" + "    supervisÃ©**.\n" + "-   Distinguer le **ML \"classique\"** (Naive Bayes, SVM) du **Deep\n" + "    Learning / Transfer Learning**.\n" + "-   ConnaÃ®tre les avantages et les limites de chaque grande famille de\n" + "    modÃ¨les.\n" + "\n" + "**4. Comprendre et mettre en oeuvre une dÃ©marche rigoureuse**\n" + "\n" + "\\n" + "\n" + "-   Concevoir un **schÃ©ma d'annotation** clair et fiable.\n" + "-   Mesurer la qualitÃ© des donnÃ©es avec l'**accord inter-annotateurs\n" + "    (IAA)**.\n" + "-   **Ã‰valuer** un systÃ¨me avec les bonnes mÃ©triques (**F1-macro**) en\n" + "    Ã©vitant les piÃ¨ges (dÃ©sÃ©quilibre des classes).\n" + ":::\n" + ":::::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Quâ€™est-ce quâ€™une opinion ? Le modÃ¨le structurÃ© de Liu {style=\"font-size:0.80em\"}\n" + "\n" + "En analyse de sentiment, une opinion n'est pas qu'un simple \"j'aime\" ou\n" + "\"je n'aime pas\". Pour Ãªtre analysable, Bing Liu, l'un des pionniers du\n" + "domaine, la modÃ©lise comme un objet structurÃ©, le **quintuple**\n" + "[@liuSentimentAnalysisOpinion, p. 19].\n" + "\n" + "\\n" + "\n" + "$$(e_i, a_{ij}, s_{ijkl}, h_k, t_l)$$\\n" + "\n" + "-   **EntitÃ© (**$e_i$) : le produit, la marque, le service. *Ex: \"iPhone\n" + "    15\"*.\n" + "-   **Aspect (**$a_{ij}$) : une caractÃ©ristique spÃ©cifique de l'entitÃ©.\n" + "    *Ex: \"batterie\", \"qualitÃ© photo\"*. Si l'opinion vise l'entitÃ©\n" + "    entiÃ¨re, on utilise l'aspect **GENERAL**.\n" + "-   **Sentiment (**$s_{ijkl}$) : la polaritÃ© (+, 0, -) et/ou son\n" + "    intensitÃ©. *Ex: \"trÃ¨s positif\"*.\n" + "-   **Holder (**$h_k$) : la source de l'opinion. *Ex: \"l'auteur du\n" + "    tweet\", \"le journaliste\"*.\n" + "-   **Temps (**$t_l$) : la date de publication. Essentiel pour suivre\n" + "    les tendances.\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Explicite vs. Implicite : lire entre les lignes {style=\"font-size:0.85em\"}\n" + "\n" + "Toutes les opinions ne sont pas exprimÃ©es de la mÃªme maniÃ¨re. La\n" + "distinction entre opinion explicite et implicite est cruciale car elle\n" + "dÃ©termine la difficultÃ© de l'analyse [@liuSentimentAnalysisOpinion, p.\n" + "26].\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### **Opinion explicite**\n" + "\n" + "C'est une **dÃ©claration subjective** qui utilise des mots de sentiment\n" + "clairs.\n" + "\n" + "-   *\"La batterie de ce tÃ©lÃ©phone est **excellente**.\"*\n" + "-   *\"Je **dÃ©teste** le nouveau design.\"*\n" + "-   *\"Le service client Ã©tait **dÃ©cevant**.\"*\n" + "\n" + "**FacilitÃ©** : relativement simple Ã  dÃ©tecter avec des lexiques de mots\n" + "positifs/nÃ©gatifs.\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### **Opinion implicite**\n" + "\n" + "C'est un **Ã©noncÃ© factuel** qui, dans un contexte donnÃ©, implique une\n" + "opinion forte.\n" + "\n" + "-   *\"La batterie de ce tÃ©lÃ©phone **tient Ã  peine la journÃ©e**.\"* (fait\n" + "    indÃ©sirable â†’ opinion nÃ©gative)\n" + "-   *\"J'ai dÃ» **redÃ©marrer l'ordinateur trois fois** ce matin.\"* (fait\n" + "    indÃ©sirable â†’ opinion nÃ©gative)\n" + "-   *\"Le colis est **arrivÃ© en 24h**.\"* (fait dÃ©sirable â†’ opinion\n" + "    positive)\n" + "\n" + "**DifficultÃ©** : beaucoup plus complexe Ã  dÃ©tecter. NÃ©cessite une\n" + "connaissance du domaine et des attentes des consommateurs.\n" + ":::\n" + ":::::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## SubjectivitÃ©, polaritÃ© et valence {style=\"font-size:0.75em\"}\n" + "\n" + "Le langage des opinions a plusieurs facettes. Il est essentiel de\n" + "distinguer si un texte exprime un point de vue (*subjectivitÃ©*) et si ce\n" + "point de vue est positif ou nÃ©gatif (*polaritÃ©* ou *valence*)\n" + "[@pangOpinionMiningSentiment, p. 5].\n" + "\n" + "-   **SubjectivitÃ©** : c'est la prÃ©sence d'un **Ã©tat privÃ©** de l'auteur\n" + "    (croyance, jugement, spÃ©culation) par opposition Ã  un **fait\n" + "    objectif** vÃ©rifiable.\n" + "    -   **Subjectif** : *\"Je pense que ce film va plaire.\"*\n" + "    -   **Objectif** : *\"Le film est sorti hier.\"*\n" + "-   **PolaritÃ© (ou valence)** : c'est l'**orientation** de l'opinion (+,\n" + "    -, 0). Le terme **valence**, issu de la psychologie, est souvent\n" + "    utilisÃ© pour dÃ©crire cette qualitÃ© intrinsÃ¨quement positive ou\n" + "    nÃ©gative d'un mot ou d'une expression.\n" + "    -   **Subjectif SANS polaritÃ© claire** : *\"Je me demande si ce\n" + "        produit est fiable.\"*\n" + "    -   **Subjectif AVEC polaritÃ©** : *\"Ce produit est incroyablement\n" + "        fiable.\"* (valence positive)\n" + "-   **PolaritÃ© (ou valence) contextuelle** : la polaritÃ© d'un mot n'est\n" + "    pas fixe ; elle dÃ©pend crucialement de son contexte. Les\n" + "    **nÃ©gations**, **intensificateurs** ou mÃªme l'**aspect** concernÃ©\n" + "    peuvent tout changer.\n" + "    -   *\"long\"* â†’ valence positive pour une batterie, valence nÃ©gative\n" + "        pour un temps d'attente.\n" + "\n" + "::: {.callout-note title=\"Pourquoi cette distinction est-elle importante ?\"}\n" + "La plupart des systÃ¨mes d'analyse de sentiment fonctionnent en deux\n" + "Ã©tapes : d'abord, ils filtrent les phrases pour ne garder que les\n" + "**subjectives**, puis ils dÃ©terminent la **polaritÃ©/valence** de ces\n" + "derniÃ¨res.\n" + ":::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Les niveaux d'analyse : quelle question se pose-t-on ? {style=\"font-size:0.72em\"}\n" + "\n" + "L'analyse de sentiment peut Ãªtre menÃ©e Ã  diffÃ©rentes Ã©chelles. Chaque\n" + "\"granularitÃ©\" rÃ©pond Ã  un besoin marketing diffÃ©rent\n" + "[@liuSentimentAnalysisOpinion, p. 10-11].\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### **Document-level**\n" + "\n" + "On analyse un texte entier (un avis, un article) pour en extraire un\n" + "sentiment global.\n" + "\n" + "-   **Question mÃ©tier** : *\"Quel est le score de satisfaction moyen de\n" + "    notre produit sur Amazon ?\"*\n" + "-   **Limite** : trÃ¨s rÃ©ducteur. Un avis 3 Ã©toiles peut contenir des\n" + "    critiques trÃ¨s prÃ©cises et des compliments sur d'autres aspects.\n" + "\n" + "### **Sentence-level**\n" + "\n" + "\\n" + "\n" + "On analyse chaque phrase indÃ©pendamment pour dÃ©terminer si elle est\n" + "subjective et quelle est sa polaritÃ©.\n" + "\n" + "\\n" + "\n" + "-   **Question mÃ©tier** : *\"Quels sont les verbatims clients les plus\n" + "    percutants (positifs ou nÃ©gatifs) Ã  faire remonter en rÃ©union ?\"*\n" + "-   **Limite** : une mÃªme phrase peut contenir plusieurs opinions. *\"Le\n" + "    design est super mais la batterie est nulle.\"*\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### **Aspect-level (ABSA)**\n" + "\n" + "C'est le niveau le plus fin et le plus utile. On identifie les\n" + "**aspects** spÃ©cifiques et on leur attribue une polaritÃ©.\n" + "\n" + "-   **Question mÃ©tier** : *\"Quels sont les **points forts et les points\n" + "    faibles** de notre produit ? Sur quoi devons-nous concentrer nos\n" + "    efforts R&D et marketing ?\"*\n" + "-   **Avantage** : fournit des insights trÃ¨s **actionnables**.\n" + "\n" + "\\n" + "\\n" + "\n" + "### **Opinions Comparatives**\n" + "\n" + "\\n" + "\n" + "On analyse les phrases qui comparent plusieurs entitÃ©s sur un mÃªme\n" + "aspect.\n" + "\n" + "\\n" + "\n" + "-   **Question mÃ©tier** : *\"Comment notre produit se positionne-t-il\n" + "    face Ã  notre principal concurrent sur l'aspect 'prix' ou 'qualitÃ©'\n" + "    aux yeux des consommateurs ?\"*\n" + "-   **Avantage** : le cÅ“ur de l'**intelligence concurrentielle**.\n" + ":::\n" + ":::::\n" + "\n" + "## Les phÃ©nomÃ¨nes linguistiques et leurs effets\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\" style=\"font-size:0.75em\"}\n" + "### **\"Valence Shifters\"** : nÃ©gation & intensitÃ©\n" + "\n" + "-   **NÃ©gation** : inverse la polaritÃ© d'un mot (*pas bon*). La\n" + "    **portÃ©e** (scope) est cruciale : \"Ce n'est pas bon, c'est\n" + "    excellent\" â†’ la nÃ©gation ne s'applique qu'Ã  \"bon\".\n" + "-   **Intensificateurs** : augmentent la force (*trÃ¨s, vraiment,\n" + "    extrÃªmement*).\n" + "-   **AttÃ©nuateurs** : diminuent la force (*un peu, lÃ©gÃ¨rement*).\n" + "\n" + "### **Connecteurs** : \"Mais\" et \"Et\"\n" + "\n" + "-   **Adversatifs (\"mais\", \"cependant\")** : signalent un retournement.\n" + "    La rÃ¨gle d'or est que l'opinion **aprÃ¨s le \"mais\"** est la plus\n" + "    importante.\n" + "    -   *\"Le design est super, **mais la batterie est nulle**.\"* â†’ avis\n" + "        globalement nÃ©gatif.\n" + "-   **Additifs (\"et\")** : tendent Ã  aligner des opinions de mÃªme\n" + "    polaritÃ©.\n" + "    -   *\"LÃ©ger **et** pratique.\"* â†’ deux aspects positifs.\n" + ":::\n" + "\n" + "::: {.column width=\"50%\" style=\"font-size:0.8em\"}\n" + "### **Conditionnels & Modaux**\n" + "\n" + "-   **Expriment une possibilitÃ©, pas une rÃ©alitÃ©** (*\"Le service\n" + "    **pourrait** Ãªtre meilleur.\"*).\n" + "-   Ils **affaiblissent** l'opinion. Ce n'est pas une critique aussi\n" + "    ferme que *\"Le service est mauvais.\"*\n" + "\n" + "\\n" + "\\n" + "\n" + "### **Implicites & Ironie**\n" + "\n" + "-   **Implicite** : opinion cachÃ©e dans un fait.\n" + "    -   *\"Le tÃ©lÃ©phone chauffe aprÃ¨s 10 min.\"* â†’ fait objectif, mais\n" + "        opinion nÃ©gative implicite sur l'aspect *performance*.\n" + "-   **Ironie/Sarcasme** : dire le contraire de ce que l'on pense.\n" + "    -   *\"Super, ma commande est encore arrivÃ©e en retard.\"* â†’ mots\n" + "        positifs, mais sentiment trÃ¨s nÃ©gatif. C'est le dÃ©fi le plus\n" + "        complexe de l'analyse.\n" + ":::\n" + ":::::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## MÃ©thodes d'analyse classiques\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\" style=\"font-size:0.7em\"}\n" + "### **Approche par lexiques (dictionnaires)**\n" + "\n" + "-   **Principe** : on attribue un score Ã  chaque mot (+1 pour \"bon\", -1\n" + "    pour \"mauvais\") et on fait la somme, ajustÃ©e par des **rÃ¨gles de\n" + "    composition** (nÃ©gation, \"mais\"...).\n" + "-   **Construction de lexique** :\n" + "    -   **Dictionary-based** : on part de quelques mots et on Ã©tend avec\n" + "        des synonymes/antonymes.\n" + "    -   **Corpus-based** : on \"dÃ©couvre\" la polaritÃ© des mots en\n" + "        regardant avec quels autres mots ils apparaissent dans un grand\n" + "        corpus de textes (ex: PMI).\n" + "\n" + "### **ABSA (Aspect-Based Sentiment Analysis)**\n" + "\n" + "C'est l'approche la plus **actionnable** pour le marketing.\n" + "\n" + "-   **Pipeline** :\n" + "    1.  **Extraire les aspects** dont les gens parlent (ex: \"batterie\",\n" + "        \"Ã©cran\", \"prix\").\n" + "    2.  **Lier l'opinion Ã  l'aspect** (ex: \"excellent\" â†’ \"Ã©cran\").\n" + "    3.  **Calculer la polaritÃ© pour chaque aspect**.\n" + "-   **RÃ©sultat** : une carte des points forts et faibles du produit.\n" + ":::\n" + "\n" + "::: {.column width=\"50%\" style=\"font-size:0.8em\"}\n" + "### **Opinions comparatives**\n" + "\n" + "-   **Objectif** : analyser les phrases qui comparent des entitÃ©s.\n" + "    -   *\"La batterie de l'iPhone **dure plus longtemps que** celle du\n" + "        Samsung.\"*\n" + "-   **Extraction** : on identifie les deux entitÃ©s comparÃ©es (E1, E2),\n" + "    l'aspect de comparaison (A) et surtout, l'**entitÃ© prÃ©fÃ©rÃ©e** (PE).\n" + ":::\n" + ":::::\n" + "\n" + "# Machine learning\n" + "\n" + "## Deux approches pour automatiser l'analyse : ML vs Deep Learning\n" + "\n" + "![](images/clipboard-2246092486.png){fig-align=\"center\" width=\"60%\"}\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\" style=\"font-size:0.478em\"}\n" + "### **Machine Learning \"Classique\"**\n" + "\n" + "-   **Principe** : l'humain choisit et prÃ©pare les *features*\n" + "    (caractÃ©ristiques) pertinentes du texte (ex: la prÃ©sence de certains\n" + "    mots, des bigrammes...). C'est une Ã©tape de **feature extraction**\n" + "    manuelle.\n" + "-   **Le modÃ¨le apprend** Ã  associer ces *features* prÃ©parÃ©es Ã  un\n" + "    sentiment (positif/nÃ©gatif).\n" + "-   **Analogie** : on prÃ©pare les ingrÃ©dients (features) pour le chef\n" + "    (modÃ¨le) qui n'a plus qu'Ã  cuisiner.\n" + ":::\n" + "\n" + "::: {.column width=\"50%\" style=\"font-size:0.5em\"}\n" + "### **Deep Learning**\n" + "\n" + "-   **Principe** : le modÃ¨le apprend **directement Ã  partir des mots\n" + "    bruts**. Il dÃ©couvre lui-mÃªme les *features* importantes dans ses\n" + "    couches cachÃ©es (*hidden layers*). L'Ã©tape de **feature extraction**\n" + "    est automatique.\n" + "-   **Le modÃ¨le apprend** des reprÃ©sentations complexes du langage\n" + "    (embeddings).\n" + "-   **Analogie** : on donne les produits bruts au chef (modÃ¨le) et il se\n" + "    charge de tout, de la dÃ©coupe Ã  la cuisson.\n" + ":::\n" + ":::::\n" + "\n" + "::: {.callout-tip title=\"A retenir\"}\n" + "Le **Deep Learning** automatise plus de tÃ¢ches et peut capturer des\n" + "relations plus complexes, ce qui conduit souvent Ã  de meilleures\n" + "performances [@hartmannMoreFeelingAccuracy2023]. C'est la base des\n" + "modÃ¨les les plus rÃ©cents.\n" + ":::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Transition : les limites des approches par lexiques {style=\"font-size:0.7em\"}\n" + "\n" + "Les mÃ©thodes par lexiques et rÃ¨gles sont transparentes et rapides, mais\n" + "elles ont des faiblesses majeures :\n" + "\n" + "-   **Aveugles au contexte** : elles peinent Ã  comprendre que **\"pas\n" + "    mauvais\"** est positif ou que **\"long\"** peut Ãªtre positif\n" + "    (batterie) ou nÃ©gatif (mise au point)\n" + "    [@liuSentimentAnalysisOpinion].\n" + "-   **Statiques et rigides** : un lexique ne s'adapte pas Ã  l'argot, aux\n" + "    nouveaux usages ou Ã  un domaine trÃ¨s spÃ©cifique. Il faut le mettre Ã \n" + "    jour manuellement.\n" + "-   **Couverture limitÃ©e** : elles ne gÃ¨rent que les mots qu'elles\n" + "    connaissent et ratent toutes les opinions implicites (*\"le tÃ©lÃ©phone\n" + "    a cessÃ© de fonctionner au bout de deux jours\"*).\n" + "\n" + "\\n" + "\n" + "::: {.callout-note title=\"Quelle transition ?\"}\n" + "Comment passer d'un systÃ¨me qui suit des rÃ¨gles fixes Ã  un systÃ¨me qui\n" + "**apprend Ã  partir d'exemples** et s'adapte au contexte ?\n" + "\n" + "**RÃ©ponse : le Machine Learning (ML)**\n" + ":::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Les 3 grandes approches du Machine Learning {style=\"font-size:0.65em\"}\n" + "\n" + "On peut classer les algorithmes de ML selon la maniÃ¨re dont ils\n" + "\"apprennent\" Ã  partir des donnÃ©es [@ahmadMachineLearningTechniques2017].\n" + "\n" + "::::::::: columns\n" + ":::: {.column width=\"33%\"}\n" + "### **Apprentissage SupervisÃ©**\n" + "\n" + "-   **Principe** : apprendre avec un **corrigÃ©**. Le modÃ¨le est entraÃ®nÃ©\n" + "    sur des donnÃ©es oÃ¹ la \"bonne rÃ©ponse\" (l'Ã©tiquette) est dÃ©jÃ  connue.\n" + "-   **DonnÃ©es requises** : un volume consÃ©quent de textes **dÃ©jÃ \n" + "    Ã©tiquetÃ©s** (positif, nÃ©gatif, etc.). C'est le fameux **Gold\n" + "    Standard**.\n" + "-   **Exemples** :\n" + "    -   Naive Bayes\n" + "    -   RÃ©gression Logistique\n" + "    -   Support Vector Machine (SVM)\n" + "\n" + "::: {.callout-tip title=\"ğŸ’¡ Cas d'usage marketing\"}\n" + "C'est l'approche la plus courante pour la classification. IdÃ©al quand on\n" + "dispose de donnÃ©es historiques, comme des tickets de support client dÃ©jÃ \n" + "classÃ©s par niveau de satisfaction.\n" + ":::\n" + "::::\n" + "\n" + ":::: {.column width=\"33%\"}\n" + "### **Apprentissage Non SupervisÃ©**\n" + "\n" + "-   **Principe** : trouver des **structures cachÃ©es** dans les donnÃ©es,\n" + "    sans aucun corrigÃ©. Le modÃ¨le regroupe les textes qui se\n" + "    ressemblent.\n" + "-   **DonnÃ©es requises** : un grand volume de textes **bruts,\n" + "    non-Ã©tiquetÃ©s**.\n" + "-   **Exemple** :\n" + "    -   **Clustering** : regrouper des clients ou des commentaires\n" + "        similaires.\n" + "\n" + "\\n" + "\\n" + "\n" + "::: {.callout-tip title=\"ğŸ’¡ Cas d'usage marketing\"}\n" + "Parfait pour l'**exploration**. Quand on ne sait pas ce qu'on cherche,\n" + "le non-supervisÃ© peut rÃ©vÃ©ler des segments de clients ou des sujets de\n" + "plainte Ã©mergents qu'on n'avait pas anticipÃ©s.\n" + ":::\n" + "::::\n" + "\n" + ":::: {.column width=\"33%\"}\n" + "### **Apprentissage Semi-SupervisÃ©**\n" + "\n" + "-   **Principe** : le meilleur des deux mondes. On utilise un **petit\n" + "    peu de donnÃ©es Ã©tiquetÃ©es** pour \"guider\" l'apprentissage sur une\n" + "    **immense quantitÃ© de donnÃ©es non-Ã©tiquetÃ©es**.\n" + "-   **DonnÃ©es requises** : quelques centaines d'exemples annotÃ©s + des\n" + "    milliers (ou millions) de textes bruts.\n" + "-   **Exemples** :\n" + "    -   Algorithmes qui propagent les Ã©tiquettes des exemples connus aux\n" + "        exemples inconnus qui leur ressemblent.\n" + "\n" + "::: {.callout-tip title=\"ğŸ’¡ Cas d'usage marketing\"}\n" + "C'est souvent le scÃ©nario le plus **rÃ©aliste et rentable**. L'annotation\n" + "manuelle coÃ»te cher. Le semi-supervisÃ© permet de construire un modÃ¨le\n" + "performant avec un effort d'annotation minimal.\n" + ":::\n" + "::::\n" + ":::::::::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Le Machine Learning : apprendre Ã  partir des donnÃ©es {style=\"font-size:0.7em\"}\n" + "\n" + "L'idÃ©e du ML est simple : au lieu de donner des rÃ¨gles Ã  la machine, on\n" + "lui donne des **exemples** et on la laisse **dÃ©couvrir les rÃ¨gles\n" + "elle-mÃªme**. C'est une approche *bottom-up*\n" + "[@hartmannComparingAutomatedText2019a].\n" + "\n" + "### Le workflow en 3 Ã©tapes\n" + "\n" + ":::::: columns\n" + "::: {.column width=\"33%\"}\n" + "**1. PrÃ©parer les donnÃ©es**\n" + "\n" + "On a besoin d'un corpus d'avis **dÃ©jÃ  Ã©tiquetÃ©s** (positif/nÃ©gatif).\n" + "\n" + "\\n" + "\\n" + "\n" + "Plus on a d'exemples de qualitÃ©, mieux le modÃ¨le apprendra.\n" + ":::\n" + "\n" + "::: {.column width=\"33%\"}\n" + "**2. Transformer le texte en chiffres**\n" + "\n" + "Un ordinateur ne \"lit\" pas. Il calcule. Il faut transformer les mots en\n" + "**vecteurs numÃ©riques** (features).\n" + "\n" + "\\n" + "\\n" + "\n" + "-   **Approche simple (BoW)** : on compte la frÃ©quence de chaque mot.\n" + "-   **Approche avancÃ©e (Embeddings)** : on reprÃ©sente le sens des mots\n" + "    dans un espace vectoriel. *(Ã  voir en sÃ©ance 6)*.\n" + ":::\n" + "\n" + "::: {.column width=\"33%\"}\n" + "**3. EntraÃ®ner un modÃ¨le**\n" + "\n" + "On choisit un algorithme qui va apprendre Ã  associer les \"patterns\"\n" + "numÃ©riques des textes aux Ã©tiquettes.\n" + "\n" + "\\n" + "\\n" + "\n" + "-   **ModÃ¨les classiques** : Naive Bayes, RÃ©gression Logistique, SVM.\n" + "-   **ModÃ¨les modernes** : RÃ©seaux de neurones (Deep Learning).\n" + ":::\n" + "::::::\n" + "\n" + "::: {.callout-tip title=\"L'adaptation au domaine\" style=\"font-size:1em\"}\n" + "Avec le Machine Learning, chaque nouveau domaine (ex : luxe, automobile, cosmÃ©tique) nÃ©cessite de **rÃ©entraÃ®ner un modÃ¨le** avec des donnÃ©es propres Ã  ce domaine.  \n" + "Le modÃ¨le apprend ainsi le vocabulaire et les nuances spÃ©cifiques, lÃ  oÃ¹ un dictionnaire gÃ©nÃ©rique Ã©chouerait.\n" + ":::\n" + "\n" + "\n" + "\n" + "## La bonne pratique du ML : sÃ©parer les donnÃ©es (Train/Validation/Test) {style=\"font-size:0.65em\"}\n" + "\n" + "Pour Ã©valuer un modÃ¨le, on doit mesurer sa capacitÃ© Ã  **gÃ©nÃ©raliser**,\n" + "pas Ã  **mÃ©moriser**. La mÃ©thode standard est de diviser les donnÃ©es en\n" + "trois ensembles distincts pour simuler un processus d'apprentissage et\n" + "d'Ã©valuation rÃ©aliste.\n" + "\n" + ":::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### La division en trois ensembles\n" + "\n" + "Notre \"Gold Standard\" est scindÃ© pour assigner un rÃ´le unique Ã  chaque\n" + "partie :\n" + "\n" + "\n" + "\\n" + "\\n" + "\n" + "-   **Jeu d'entraÃ®nement (Train Set) : \~70%** Le **manuel de cours**.\n" + "    Le modÃ¨le utilise ces donnÃ©es pour **apprendre** les rÃ¨gles et les\n" + "    associations. C'est sa seule source de connaissance.\n" + "\n" + "\\n" + "\n" + "-   **Jeu de validation (Validation Set) : \~15%** L'**examen blanc**.\n" + "    On utilise cet ensemble pour **rÃ©gler** les paramÃ¨tres du modÃ¨le et\n" + "    pour **comparer** diffÃ©rentes versions entre elles. Cela Ã©vite la\n" + "    **fuite d'information** (*data leak*) vers le jeu de test.\n" + "    \n" + "\\n" + "\n" + "-   **Jeu de test (Test Set) : \~15%** L'**examen final**, sous scellÃ©.\n" + "    On n'utilise cet ensemble qu'**une seule et unique fois** Ã  la toute\n" + "    fin, pour obtenir la mesure de **performance finale** et objective\n" + "    du modÃ¨le choisi.\n" + ":::\n" + "\n" + ":::: {.column width=\"50%\"}\n" + "### Le workflow classique\n" + "\n" + "![](images/clipboard-1060488567.png){fig-align=\"center\" width=\"75%\"}\n" + "\n" + "::: {.callout-tip title=\"Analogie de la prÃ©paration d'un concours\"}\n" + "-   Le **Train Set**, ce sont les chapitres que l'Ã©tudiant Ã©tudie pour\n" + "    **apprendre**.\n" + "\n" + "-   Le **Validation Set**, ce sont les annales et les examens blancs.\n" + "    L'Ã©tudiant les utilise pour **ajuster sa mÃ©thode de travail** et\n" + "    voir ce qui fonctionne le mieux.\n" + "\n" + "-   Le **Test Set**, c'est le **sujet officiel du concours**, dÃ©couvert\n" + "    le jour J. La note obtenue est la seule qui compte vraiment pour\n" + "    mesurer son niveau rÃ©el.\n" + ":::\n" + "::::\n" + "::::::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Un panorama des modÃ¨les de Machine Learning {style=\"font-size:0.7em\"}\n" + "\n" + "Tous les modÃ¨les n'ont pas la mÃªme complexitÃ© ni la mÃªme performance.\n" + "Voici une vue d'ensemble, du plus simple au plus avancÃ©.\n" + "\n" + "::::::::: columns\n" + "::: {.column width=\"50%\" style=\"font-size: 0.75em\"}\n" + "### 1. ML \"Classique\" (Supervised Learning)\n" + "\n" + "On entraÃ®ne un modÃ¨le de A Ã  Z sur nos propres donnÃ©es Ã©tiquetÃ©es.\n" + "\n" + "-   **Naive Bayes** : un modÃ¨le probabiliste simple et rapide. Il\n" + "    calcule la probabilitÃ© qu'un avis soit positif sachant les mots\n" + "    qu'il contient [@ahmadMachineLearningTechniques2017]. TrÃ¨s bon comme\n" + "    baseline.\n" + "\n" + "-   **Support Vector Machine (SVM)** : un classificateur trÃ¨s robuste\n" + "    qui cherche la \"frontiÃ¨re\" optimale pour sÃ©parer les classes. Il a\n" + "    longtemps Ã©tÃ© l'Ã©tat de l'art pour la classification de texte\n" + "    [@pangOpinionMiningSentiment].\n" + "\n" + "**Le dÃ©fi** : nÃ©cessite beaucoup de donnÃ©es Ã©tiquetÃ©es pour chaque\n" + "nouveau domaine.\n" + "\n" + "\\n" + "\\n" + "\\n" + "\n" + "### 2. Le Deep Learning et le Transfer Learning\n" + "\n" + "\\n" + "\n" + "On ne part plus de zÃ©ro. On utilise un modÃ¨le **prÃ©-entraÃ®nÃ©** sur des\n" + "milliards de textes (comme WikipÃ©dia) qui a dÃ©jÃ  une comprÃ©hension\n" + "gÃ©nÃ©rale du langage.\n" + "\n" + "\\n" + "\\n" + "\n" + "-   **Principe** : on prend ce \"cerveau\" prÃ©-entraÃ®nÃ© et on l'affine\n" + "    (*fine-tuning*) sur notre tÃ¢che spÃ©cifique avec beaucoup moins de\n" + "    donnÃ©es [@dangSentimentAnalysisBased2020].\n" + "-   **Avantage majeur** : le modÃ¨le peut gÃ©nÃ©raliser et comprendre des\n" + "    nuances qu'il n'aurait jamais pu apprendre sur un petit jeu de\n" + "    donnÃ©es.\n" + "-   C'est l'approche qui donne aujourd'hui les **meilleures\n" + "    performances** [@hartmannMoreFeelingAccuracy2023].\n" + ":::\n" + "\n" + "::::::: {.column width=\"50%\"}\n" + "### L'Ã©chelle de la performance\n" + "\n" + ":::: columns\n" + "::: {.column width=\"50%\"}\n" + ":::\n" + "::::\n" + "\n" + "::: {.callout-note title=\"Accuracy moyenne [@hartmannMoreFeelingAccuracy2023]\"}\n" + "Une mÃ©ta-analyse sur 272 jeux de donnÃ©es montre une hiÃ©rarchie claire\n" + "des performances :\n" + "\n" + "1.  **Transfer Learning (BERT, RoBERTa...)** : **\~90-96%**\n" + "2.  **ML Classique (SVM, etc.)** : **\~80-88%**\n" + "3.  **Lexiques (VADER, LIWC...)** : **\~65-75%**\n" + "\n" + "Le Transfer Learning est en moyenne **+20 points** plus prÃ©cis que les\n" + "lexiques.\n" + ":::\n" + "\n" + "::: {.callout-warning title=\"Le compromis gÃ©nÃ©ral (interprÃ©tabilitÃ©)\"}\n" + "-   **Lexiques** : **transparence maximale**, mais prÃ©cision limitÃ©e.\n" + "    IdÃ©al pour comprendre le \"pourquoi\" et pour des analyses\n" + "    exploratoires.\n" + "-   **ML / Transfer Learning** : **prÃ©cision maximale**, mais plus\n" + "    \"boÃ®te noire\". IdÃ©al pour des systÃ¨mes oÃ¹ la performance prime.\n" + ":::\n" + ":::::::\n" + ":::::::::\n" + "\n" + "## Zoom sur les modÃ¨les classiques (1/2) : Naive Bayes {style=\"font-size:0.57em\"}\n" + "\n" + "Le Naive Bayes est un modÃ¨le qui fonctionne comme un **dÃ©tective probabiliste**.  \n" + "Pour classer un avis, il ne cherche pas de rÃ¨gles complexes, mais se pose une question simple :  \n" + "**\"Quelle est la probabilitÃ© que cet avis soit positif, sachant les mots qu'il contient ?\"**\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### Le principe : le thÃ©orÃ¨me de Bayes\n" + "\n" + "Tout repose sur le thÃ©orÃ¨me de Bayes, qui permet dâ€™inverser une probabilitÃ©.  \n" + "On cherche $P(\text{Classe | Mots})$, mais il est plus simple de calculer lâ€™inverse : $P(\text{Mots | Classe})$.\n" + "\n" + "Formule gÃ©nÃ©rale :  \n" + "$$\n" + "P(\text{Classe | Mots}) = \frac{P(\text{Mots | Classe}) \times P(\text{Classe})}{P(\text{Mots})}\n" + "$$\n" + "\n" + "Comme $P(\text{Mots})$ est identique pour toutes les classes, on lâ€™ignore et on compare seulement les numÃ©rateurs :  \n" + "$$\n" + "\text{Score}(\text{Classe}) \propto P(\text{Classe}) \times \prod_{i=1}^{n} P(\text{mot}_i | \text{Classe})\n" + "$$\n" + "\n" + "-   $P(\text{Classe})$ : **probabilitÃ© a priori** = frÃ©quence de base dâ€™une classe.  \n" + "    (ex. : si 80% des avis sont positifs, alors $P(\text{positif}) = 0.8$).  \n" + "-   $P(\text{mot}_i | \text{Classe})$ : **vraisemblance** (*likelihood*) = frÃ©quence dâ€™un mot dans une classe donnÃ©e.  \n" + "-   $\prod$ : multiplication des probabilitÃ©s de chaque mot, selon lâ€™hypothÃ¨se **â€œnaÃ¯veâ€** que les mots sont indÃ©pendants.  \n" + "\n" + "*(MÃªme si cette hypothÃ¨se est fausse dans la rÃ©alitÃ©, le modÃ¨le reste Ã©tonnamment efficace en pratique.)*\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### Exemple concret\n" + "\n" + "Avis : *\"service dÃ©cevant\"*  \n" + "\n" + "1. **Score positif :**  \n" + "$$\n" + "\text{Score}(\text{positif}) = P(\text{positif}) \times P(\text{\"service\"|positif}) \times P(\text{\"dÃ©cevant\"|positif})\n" + "$$\n" + "\n" + "2. **Score nÃ©gatif :**  \n" + "$$\n" + "\text{Score}(\text{nÃ©gatif}) = P(\text{nÃ©gatif}) \times P(\text{\"service\"|nÃ©gatif}) \times P(\text{\"dÃ©cevant\"|nÃ©gatif})\n" + "$$\n" + "\n" + "Le mot **\"dÃ©cevant\"** apparaÃ®t trÃ¨s souvent dans les avis nÃ©gatifs et rarement dans les positifs.  \n" + "MÃªme si **\"service\"** est neutre, le poids de **\"dÃ©cevant\"** fait basculer le score.\n" + "\n" + "\\n" + "\\n" + "\n" + "ğŸ‘‰ Lâ€™avis est classÃ© dans la catÃ©gorie dont le score est le plus Ã©levÃ©.  \n" + "\n" + "::: {.callout-tip title=\"ğŸ’¡ Analogie du dÃ©tective\"}\n" + "Le Naive Bayes est un dÃ©tective qui a Ã©tudiÃ© des milliers de cas :  \n" + "- Le **prior** ($P(\text{Classe})$) = son intuition de base (*\"la plupart des crimes ici sont des vols\"*).  \n" + "- La **vraisemblance** ($P(\text{mot|Classe})$) = la valeur de chaque indice (*\"une empreinte digitale de ce type est trÃ¨s souvent liÃ©e au suspect X\"*).  \n" + "\n" + "Il combine les indices pour identifier le coupable le plus probable.  \n" + ":::\n" + ":::\n" + ":::::\n" + "\n" + "\n" + "## Zoom sur les modÃ¨les classiques (2/2) : La RÃ©gression Logistique {style=\"font-size:0.60em\"}\n" + "\n" + "La RÃ©gression Logistique est un pilier de la classification. MalgrÃ© son nom, son but n'est pas de prÃ©dire un chiffre continu, mais de calculer la **probabilitÃ© conditionnelle** qu'un avis appartienne Ã  une classe (ex : 75% de chance d'Ãªtre \"positif\"), sachant les mots qu'il contient.  \n" + "Elle le fait en transformant un score linÃ©aire grÃ¢ce Ã  une courbe en \"S\".\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### Le principe : du score Ã  la probabilitÃ©\n" + "\n" + "1.  **Calculer un score (Logit)** : Le modÃ¨le calcule un score en additionnant les \"poids\" de chaque mot.  \n" + "    Pendant l'entraÃ®nement, il apprend que \"excellent\" a un poids positif Ã©levÃ©, tandis que \"dÃ©cevant\" a un poids nÃ©gatif fort.  \n" + "\n" + "    $$\n" + "    z = b_0 + b_1 x_1 + b_2 x_2 + ... + b_n x_n\n" + "    $$\n" + "\n" + "    -   $x_i$ : la prÃ©sence ou la frÃ©quence d'un mot dans l'avis.  \n" + "    -   $b_i$ : le poids appris pour ce mot.  \n" + "    -   $z$ : le score total, qui peut aller de $-\infty$ Ã  $+\infty$.  \n" + "\n" + "2.  **Transformer le score en probabilitÃ©** : Ce score $z$ est ensuite \"Ã©crasÃ©\" dans un intervalle [0, 1] grÃ¢ce Ã  la **fonction sigmoÃ¯de (ou logistique)**.  \n" + "    C'est elle qui produit la fameuse courbe en \"S\".  \n" + "\n" + "    $$\n" + "    P(y=1|x) = \frac{1}{1 + e^{-z}}\n" + "    $$\n" + "\n" + "    -   Si le score $z$ est trÃ¨s grand â†’ la probabilitÃ© est proche de 1.  \n" + "    -   Si le score $z$ est trÃ¨s nÃ©gatif â†’ la probabilitÃ© est proche de 0.  \n" + "    -   Si le score $z$ est 0 â†’ la probabilitÃ© est de 0.5.  \n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### Le processus de dÃ©cision\n" + "\n" + "Pour un avis donnÃ© :\n" + "\n" + "1.  Le modÃ¨le calcule le score $z$ en additionnant les poids des mots prÃ©sents.  \n" + "2.  Il applique la fonction sigmoÃ¯de pour obtenir une probabilitÃ©, par exemple $P(\text{positif}) = 0.82$.  \n" + "3.  Il compare cette probabilitÃ© Ã  un seuil de dÃ©cision (par dÃ©faut 0.5).  \n" + "    -   Si $0.82 > 0.5 \rightarrow$ l'avis est classÃ© **Positif**.  \n" + "    -   Si $0.21 < 0.5 \rightarrow$ l'avis est classÃ© **NÃ©gatif**.  \n" + "\n" + "::: {.callout-tip title=\"ğŸ’¡ Analogie du score de confiance\"}\n" + "La RÃ©gression Logistique calcule un **score de confiance** :  \n" + "\n" + "-   Chaque mot ajoute ou retire des points de confiance.  \n" + "-   Un avis plein de mots positifs (\"rapide\", \"parfait\", \"excellent\") obtiendra un score trÃ¨s Ã©levÃ©.  \n" + "-   Un avis avec des mots nÃ©gatifs (\"lent\", \"cassÃ©\", \"horrible\") aura un score trÃ¨s bas.  \n" + "\n" + "La fonction sigmoÃ¯de transforme ce score de confiance en une **probabilitÃ© claire et interprÃ©table** â€” d'oÃ¹ son intÃ©rÃªt en marketing pour comprendre les *drivers* de la satisfaction.  \n" + ":::\n" + ":::\n" + ":::::\n" + "\n" + "# Annotation & Ã©valuation {.transition-slide-ubdyellow}\n" + "\n" + "## L'annotation manuelle : crÃ©er notre \"vÃ©ritÃ© terrain\" {style=\"font-size: 0.85em\"}\n" + "\n" + "Avant de pouvoir Ã©valuer un outil, il nous faut une rÃ©fÃ©rence fiable :\n" + "le **gold standard**. C'est un ensemble de textes que des humains ont\n" + "lus et Ã©tiquetÃ©s selon des rÃ¨gles prÃ©cises.\n" + "\n" + "### Principes d'une bonne annotation\n" + "\n" + "- **SchÃ©ma clair** : dÃ©finir ce quâ€™on annote  \n" + "  - **UnitÃ©** : texte entier, phrase ou extrait spÃ©cifique  \n" + "  - **Labels** : polaritÃ© simple (positif / nÃ©gatif / neutre) ou niveau dâ€™intensitÃ© (ex : 1 Ã  5)\n" + "-   **Guide d'annotation** : un document essentiel avec des rÃ¨gles et\n" + "    des exemples de cas limites (ironie, conditionnels) pour assurer la\n" + "    cohÃ©rence.\n" + "-   **Double annotation** : au moins deux personnes annotent le mÃªme\n" + "    texte de maniÃ¨re indÃ©pendante.\n" + "-   **Adjudication** : en cas de dÃ©saccord, un troisiÃ¨me annotateur (ou\n" + "    un consensus) tranche pour finaliser le gold standard.\n" + "\n" + "::: {.callout-tip title=\"ğŸ’¡ Conseil pratique\" style=\"font-size: 0.9em\"}\n" + "Un bon guide d'annotation est la clÃ© de voÃ»te de toute analyse de\n" + "sentiment rigoureuse. C'est 80% du travail pour obtenir des donnÃ©es\n" + "fiables.\n" + ":::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## La fiabilitÃ© des donnÃ©es : l'accord inter-annotateurs (IAA) {style=\"font-size: 0.8em\"}\n" + "\n" + "**La question clÃ© :** nos annotateurs sont-ils d'accord entre eux, ou\n" + "est-ce que leurs Ã©tiquettes sont le fruit du hasard ? L'IAA mesure la\n" + "cohÃ©rence de leur travail.\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### Kappa de Cohen ($\kappa$)\n" + "\n" + "Mesure l'accord entre **deux** annotateurs, en corrigeant l'accord qui\n" + "pourrait survenir par chance[^1]. $$\n" + "\kappa = \frac{p_o - p_e}{1 - p_e}\n" + "$$ OÃ¹ $p_o$ est l'accord observÃ© et $p_e$ l'accord attendu par hasard.\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### Alpha de Krippendorff ($\alpha$)\n" + "\n" + "Plus gÃ©nÃ©ral et robuste : fonctionne avec **plus de deux** annotateurs\n" + "et diffÃ©rents types de labels (nominal, ordinal...). $$\n" + "\alpha = 1 - \frac{D_o}{D_e}\n" + "$$ OÃ¹ $D_o$ est le dÃ©saccord observÃ© et $D_e$ le dÃ©saccord attendu par\n" + "hasard.\n" + ":::\n" + ":::::\n" + "\n" + "[^1]: Dâ€™autres mesures existent, comme le Kappa de Fleiss (extension Ã \n" + "    plusieurs annotateurs) ou lâ€™ICC (Intraclass Correlation Coefficient)\n" + "    pour des variables continues.\n" + "\n" + "::: {.callout-note title=\"ğŸ¯ Objectif\"}\n" + "On vise un score **Kappa/Alpha â‰¥ 0.70**. En dessous, cela signifie que\n" + "le guide d'annotation n'est pas assez clair et doit Ãªtre amÃ©liorÃ©. Un\n" + "IAA Ã©levÃ© garantit que notre \"vÃ©ritÃ© terrain\" est solide.\n" + ":::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Exemple & interprÃ©tation des scores {style=\"font-size: 0.8em\"}\n" + "\n" + "::::::: columns\n" + "::::: {.column width=\"50%\"}\n" + "### Exemple de calcul (Kappa de Cohen)\n" + "\n" + "Deux annotateurs classent 50 tweets (*positif/nÃ©gatif*).\n" + "\n" + "-   Accord observÃ© : 40/50 â†’ $p_o = 0.8$\\n" + "-   Accord attendu par hasard : $p_e = 0.5$\n" + "\n" + "$$\n" + "\kappa = \frac{0.8 - 0.5}{1 - 0.5} = 0.6\n" + "$$\n" + "\n" + ":::: {.callout-example title=\"InterprÃ©tation\"}\n" + "$\kappa = 0.6$ â†’ **accord modÃ©rÃ© Ã  substantiel**, mais amÃ©liorable.\n" + "\n" + "::: {.callout-note title=\"Remarque sur l'interprÃ©tation\" style=\"font-size: 0.8em\"}\n" + "Les seuils proposÃ©s par Landis et Koch\n" + "[@landisMeasurementObserverAgreement1977] sont devenus une rÃ©fÃ©rence,\n" + "mais ils sont **arbitraires** et parfois jugÃ©s trop tolÃ©rants.\\n" + "McHugh [@mchugh2012interrater] recommande des critÃ¨res plus stricts,\n" + "considÃ©rant quâ€™un accord Â« acceptable Â» ne devrait pas Ãªtre en dessous\n" + "de **0.80** en contexte scientifique ou mÃ©dical.\n" + ":::\n" + "::::\n" + ":::::\n" + "\n" + "::: {.column width=\"50%\" style=\"font-size: 0.8em\"}\n" + "### InterprÃ©tation des scores\n" + "\n" + "| Valeur de Îº / Î± | InterprÃ©tation selon Landis & Koch (1977) |\n" + "|-----------------|-------------------------------------------|\n" + "| \< 0.00         | Poor                                      |\n" + "| 0.00 â€“ 0.20     | Slight                                    |\n" + "| 0.21 â€“ 0.40     | Fair                                      |\n" + "| 0.41 â€“ 0.60     | Moderate                                  |\n" + "| 0.61 â€“ 0.80     | Substantial                               |\n" + "| 0.81 â€“ 1.00     | Almost perfect                            |\n" + "\n" + "```{r}\n" + "library(irr)\n" + "# Exemple : 2 annotateurs classent 50 tweets (positif/nÃ©gatif)\n" + "# On crÃ©e une matrice items Ã— annotateurs\n" + "# Ici : 40 accords, 10 dÃ©saccords\n" + "annotateur1 <- c(rep(\"positif\", 20), rep(\"nÃ©gatif\", 20), rep(\"positif\", 5), rep(\"nÃ©gatif\", 5))\n" + "annotateur2 <- c(rep(\"positif\", 20), rep(\"nÃ©gatif\", 20), rep(\"nÃ©gatif\", 5), rep(\"positif\", 5))\n" + "annotations <- data.frame(annotateur1, annotateur2)\n" + "kappa2(annotations, \"unweighted\")\n" + "```\n" + ":::\n" + ":::::::\n" + "\n" + "## Exemple & interprÃ©tation de lâ€™Alpha de Krippendorff {style=\"font-size: 0.8em\"}\n" + "\n" + "::::::: columns\n" + ":::: {.column width=\"50%\"}\n" + "### Exemple de calcul\n" + "\n" + "Trois annotateurs Ã©valuent 5 items (*positif/nÃ©gatif*).\n" + "\n" + "-   DÃ©saccord observÃ© : $(D_o \approx 0.27)$\n" + "-   DÃ©saccord attendu : $(D_e \approx 0.48)$\n" + "\n" + "$$\n" + "\alpha = 1 - \frac{0.27}{0.48} \approx 0.463\n" + "$$\n" + "\n" + "::: {.callout-example title=\"InterprÃ©tation\"}\n" + "(\alpha = 0.463) â†’ Accord **insuffisant** (\< 0.67) â†’ guide/formation Ã \n" + "amÃ©liorer.\n" + ":::\n" + "::::\n" + "\n" + ":::: {.column width=\"50%\"}\n" + "### InterprÃ©tation des scores\n" + "\n" + "::: {.callout-note title=\"Comment lire Î±\" style=\"font-size: 0.8em\"}\n" + "-   (D_o) = dÃ©saccord observÃ© (proportion de dÃ©saccords rÃ©els entre\n" + "    juges).\\n" + "-   (D_e) = dÃ©saccord attendu **par hasard**, calculÃ© Ã  partir de la\n" + "    distribution globale des catÃ©gories.\n" + "\n" + "Selon [@krippendorff2018content] :\\n" + "- **Î± â‰¥ 0.80** â†’ Accord **fiable** (analyses solides)\\n" + "- **0.67 â‰¤ Î± \< 0.80** â†’ Accord **acceptable** (exploratoire)\\n" + "- **Î± \< 0.67** â†’ Accord **insuffisant**, guide dâ€™annotation Ã  amÃ©liorer\n" + "\n" + "```{r}\n" + "library(irr)\n" + "annotations <- data.frame(\n" + "  annotateur1 = c(1, 1, 0, 1, 0),\n" + "  annotateur2 = c(1, 0, 0, 1, 0),\n" + "  annotateur3 = c(1, 1, 0, 1, 1)\n" + ")\n" + "# La fonction kripp.alpha attend une matrice items Ã— juges\n" + "result <- kripp.alpha(t(as.matrix(annotations)), method = \"nominal\")\n" + "result\n" + "```\n" + ":::\n" + "::::\n" + ":::::::\n" + "\n" + "## La base de l'Ã©valuation : la matrice de confusion {style=\"font-size: 0.85em\"}\n" + "\n" + "Maintenant que nous avons un gold standard fiable, nous pouvons juger\n" + "notre outil. La matrice de confusion est le point de dÃ©part : elle\n" + "montre oÃ¹ le modÃ¨le a eu raison et oÃ¹ il s'est trompÃ©.\n" + "\n" + "Imaginons qu'on veuille dÃ©tecter les commentaires **nÃ©gatifs** (la\n" + "classe \"positive\" de notre analyse) :\n" + "\n" + "|                    | PrÃ©dit : **nÃ©gatif**  | PrÃ©dit : **OK**       |\n" + "|--------------------|-----------------------|-----------------------|\n" + "| **RÃ©el : nÃ©gatif** | **TP** (vrai positif) | **FN** (faux nÃ©gatif) |\n" + "| **RÃ©el : OK**      | **FP** (faux positif) | **TN** (vrai nÃ©gatif) |\n" + "\n" + "\\n" + "\n" + "-   **TP (true positive)** : l'alerte Ã©tait justifiÃ©e. C'est un\n" + "    commentaire nÃ©gatif, et on l'a bien dÃ©tectÃ©. **Bravo**\n" + "-   **FN (false negative)** : **l'alerte manquÃ©e !** C'Ã©tait un\n" + "    commentaire nÃ©gatif, mais on l'a ratÃ©. **Danger !**\n" + "-   **FP (false positive)** : **la fausse alerte.** On a cru que c'Ã©tait\n" + "    nÃ©gatif, mais Ã§a ne l'Ã©tait pas. **Bruit.**\n" + "-   **TN (true negative)** : on a bien ignorÃ© un commentaire\n" + "    non-nÃ©gatif. **Correct.**\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Matrice de confusion multiclasse (analyse de sentiment) {style=\"font-size: 0.4em\"}\n" + "\n" + "![](images/clipboard-1562987940.png){fig-align=\"center\" width=\"50%\"}\n" + "\n" + "### InterprÃ©tation de la matrice de confusion (10 000 avis)\n" + "\n" + "::::: columns\n" + "::: column\n" + "#### Performance gÃ©nÃ©rale\n" + "\n" + "Sur 10 000 avis, le modÃ¨le a correctement classÃ© **7 692** d'entre eux,\n" + "soit une **prÃ©cision globale de 76,9%**.\n" + "\n" + "-   **Avis NÃ©gatifs** : **2 107** correctement identifiÃ©s sur 3 053.\n" + "-   **Avis Neutres** : **1 636** correctement identifiÃ©s sur 2 023.\n" + "-   **Avis Positifs** : **3 949** correctement identifiÃ©s sur 4 924. Le\n" + "    modÃ¨le est particuliÃ¨rement performant pour cette classe.\n" + ":::\n" + "\n" + "::: column\n" + "#### Analyse des erreurs principales\n" + "\n" + "Les erreurs les plus frÃ©quentes se situent dans la confusion avec la\n" + "classe **Neutre**.\n" + "\n" + "-   **Erreur majeure nÂ°1** : **739** avis **positifs** ont Ã©tÃ© classÃ©s Ã \n" + "    tort comme **neutres**. Le modÃ¨le peine Ã  identifier un sentiment\n" + "    positif peu prononcÃ©.\n" + "-   **Erreur majeure nÂ°2** : **620** avis **nÃ©gatifs** ont Ã©tÃ© classÃ©s Ã \n" + "    tort comme **neutres**. De mÃªme, le sentiment nÃ©gatif lÃ©ger semble\n" + "    difficile Ã  capter.\n" + "\n" + "##### Pistes d'amÃ©lioration\n" + "\n" + "-   **Affiner la distinction** : Le modÃ¨le pourrait Ãªtre amÃ©liorÃ© en lui\n" + "    fournissant plus d'exemples d'avis Ã  la frontiÃ¨re entre \"Neutre\" et\n" + "    \"Positif/NÃ©gatif\".\n" + "-   **Analyse des faux nÃ©gatifs/positifs** : Examiner les 739 avis\n" + "    positifs et 620 avis nÃ©gatifs mal classÃ©s pour comprendre les mots\n" + "    ou tournures de phrases qui trompent le modÃ¨le.\n" + ":::\n" + ":::::\n" + "\n" + "## Le dilemme du marketeur : prÃ©cision vs. rappel {style=\"font-size: 0.65em\"}\n" + "\n" + "L'accuracy (taux de bonnes prÃ©dictions) est souvent trompeuse. La\n" + "prÃ©cision et le rappel rÃ©pondent Ã  des besoins mÃ©tier trÃ¨s diffÃ©rents.\n" + "\n" + ":::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### PrÃ©cision (precision)\n" + "\n" + "$$\n" + "\mathrm{P} = \frac{TP}{TP + FP}\n" + "$$\n" + "\n" + "**La question mÃ©tier :** quand mon systÃ¨me sonne une alerte, est-ce que\n" + "je peux lui faire confiance ?\n" + "\n" + "-   Une **haute prÃ©cision** signifie que l'on a peu de fausses alertes\n" + "    (peu de FP).\n" + "-   **PrioritÃ© :** ne pas dÃ©ranger les Ã©quipes pour rien, ne pas\n" + "    contacter Ã  tort des clients supposÃ©s mÃ©contents. C'est la mÃ©trique\n" + "    de la **fiabilitÃ©**.\n" + "\n" + "### Rappel (recall)\n" + "\n" + "$$\n" + "\mathrm{R} = \frac{TP}{TP + FN}\n" + "$$ **La question mÃ©tier :** suis-je sÃ»r d'avoir identifiÃ© TOUS les vrais\n" + "commentaires nÃ©gatifs ?\n" + "\n" + "-   Un **haut rappel** signifie que l'on a ratÃ© trÃ¨s peu de vrais\n" + "    problÃ¨mes (peu de FN).\n" + "-   **PrioritÃ© :** dÃ©tecter une crise Ã  tout prix, mÃªme si cela gÃ©nÃ¨re\n" + "    quelques fausses alertes. C'est la mÃ©trique de l'**exhaustivitÃ©**.\n" + ":::\n" + "\n" + ":::: {.column width=\"50%\"}\n" + "### F1-score\n" + "\n" + "$$\n" + "\mathrm{F1} = \frac{2 \times P \times R}{P + R}\n" + "$$ **La question mÃ©tier :** comment trouver le meilleur Ã©quilibre entre\n" + "fiabilitÃ© et exhaustivitÃ© ?\n" + "\n" + "Le **F1-score** est une moyenne qui pÃ©nalise les modÃ¨les qui sacrifient\n" + "trop l'une des deux mÃ©triques. **C'est la mÃ©trique par dÃ©faut pour une\n" + "Ã©valuation Ã©quilibrÃ©e.**\n" + "\n" + "\\n" + "\\n" + "\\n" + "\\n" + "\n" + "::: {.callout-tip title=\"Analogie marketing\" style=\"font-size: 1.2em\"}\n" + "-   **Haute prÃ©cision** : votre campagne de retargeting est trÃ¨s\n" + "    efficace (haut taux de conversion), mais n'a touchÃ© qu'un petit\n" + "    segment.\n" + "-   **Haut rappel** : votre campagne TV a touchÃ© tout le monde\n" + "    (couverture maximale), mais avec un faible impact.\n" + "-   **Haut F1-score** : vous avez touchÃ© une large part de votre cible\n" + "    avec un impact significatif.\n" + ":::\n" + "::::\n" + "::::::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Le dÃ©fi des donnÃ©es rÃ©elles : des distributions asymÃ©triques {style=\"font-size: 0.70em\"}\n" + "\n" + "Contrairement Ã  une idÃ©e reÃ§ue, les avis en ligne sont rarement\n" + "\"Ã©quilibrÃ©s\". En rÃ©alitÃ©, leur distribution est presque toujours\n" + "**fortement asymÃ©trique** (*skewed*), suivant souvent une forme visuelle\n" + "de **courbe en \"J\"** [@pangOpinionMiningSentiment, p. 50].\n" + "\n" + "L'asymÃ©trie dÃ©pend fortement de la plateforme (biais d'auto-sÃ©lection) :\n" + "\n" + "-   **Majoritairement positifs** : sur les plateformes oÃ¹ l'avis est un\n" + "    acte de recommandation ou de construction de rÃ©putation (ex:\n" + "    **Airbnb**, la plupart des produits sur **Amazon**), on observe une\n" + "    avalanche d'avis trÃ¨s positifs (4-5 Ã©toiles).\n" + "-   **Majoritairement nÃ©gatifs** : sur les plateformes perÃ§ues comme un\n" + "    lieu de rÃ©clamation ou de vigilance (ex: **Trustpilot** pour\n" + "    certains services, forums de support technique), les avis nÃ©gatifs\n" + "    peuvent dominer.\n" + "\n" + "::: {.callout-warning title=\"Le piÃ¨ge de l'accuracy reste le mÃªme\"}\n" + "Que vous ayez 90% d'avis positifs ou 90% de nÃ©gatifs, le problÃ¨me de\n" + "fond demeure : l'**accuracy est une mÃ©trique dangereuse**. Un modÃ¨le qui\n" + "prÃ©dit toujours la classe majoritaire aura un score Ã©levÃ© mais sera\n" + "inutile pour dÃ©tecter les signaux faibles (la crise qui dÃ©marre ou les\n" + "clients ambassadeurs).\n" + ":::\n" + "\n" + "### Les bonnes mÃ©triques pour les donnÃ©es dÃ©sÃ©quilibrÃ©es\n" + "\n" + "-   **F1-macro** : on calcule le F1-score pour chaque classe (+, 0, -),\n" + "    puis on fait la **moyenne simple**. Chaque classe a le mÃªme poids,\n" + "    qu'elle soit rare ou frÃ©quente. C'est le **standard** pour rapporter\n" + "    la performance en analyse de sentiment.\n" + "\n" + "-   **Balanced accuracy** : c'est la moyenne des rappels de chaque\n" + "    classe. Simple et juste.\n" + "\n" + "$$\n" + "\mathrm{BAcc}=\tfrac{1}{2}\big(\text{Rappel}_{Pos} + \text{Rappel}_{Neg}\big)\n" + "$$\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Au-delÃ  des labels : Ã©valuer les scores {style=\"font-size: 0.75em\"}\n" + "\n" + "Beaucoup dâ€™outils (VADER, LIWC) produisent un **score continu** (ex : -0.87) plutÃ´t quâ€™un label. On peut lâ€™Ã©valuer de deux faÃ§ons.\n" + "\n" + ":::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### 1. Seuil de dÃ©cision ($\tau$)\n" + "\n" + "On transforme le score en label via un seuil (souvent avec une **zone neutre**).  \n" + "- Ex. : score > 0.1 â†’ positif ; score < -0.1 â†’ nÃ©gatif ; sinon neutre.  \n" + "- Seuil bas â†’ rappel â†‘ mais prÃ©cision â†“.  \n" + "- Seuil haut â†’ prÃ©cision â†‘ mais rappel â†“.  \n" + "\n" + "### 2. Ã‰valuer le score brut\n" + "\n" + "- **CorrÃ©lation (Spearman)** : est-ce que lâ€™outil classe bien les avis du pire au meilleur ?  \n" + "- **MAE** : compare le score normalisÃ© Ã  la note en Ã©toile.  \n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### Courbes P-R et ROC\n" + "\n" + "En faisant varier le seuil :  \n" + "- **ROC** : compromis sensibilitÃ© vs spÃ©cificitÃ©.  \n" + "- **P-R** : utile quand la classe positive est rare.  \n" + "\n" + "::: {.callout-warning title=\"âš ï¸ Attention au dÃ©sÃ©quilibre\"}\n" + "Lâ€™AUPRC nâ€™est pas toujours â€œmeilleureâ€ : le choix de la mÃ©trique dÃ©pend de lâ€™**objectif mÃ©tier** [@mcdermottCloserLookAUROC2025].\n" + ":::\n" + ":::\n" + "::::::\n" + "\n" + "::: {.callout-note title=\"Quel seuil choisir ?\"}\n" + "- **Crise (ne rien rater)** â†’ seuil bas â†’ rappel â†‘.  \n" + "- **FidÃ©lisation (Ã©viter les erreurs)** â†’ seuil haut â†’ prÃ©cision â†‘.  \n" + ":::\n" + "\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## SynthÃ¨se pratique : quelle mÃ©trique pour quel outil ? {style=\"font-size: 0.75em\"}\n" + "\n" + "Un guide pour Ã©valuer les outils que vous utiliserez en TP et pour vos\n" + "projets.\n" + "\n" + ":::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### 1. Comprendre la sortie de l'outil\n" + "\n" + "-   **VADER, NRC, syuzhet, LIWC** produisent principalement des\n" + "    **scores**.\n" + "-   Votre premiÃ¨re Ã©tape sera toujours de **dÃ©finir des seuils** pour\n" + "    les convertir en labels `(+, 0, -)`.\n" + "\n" + "### 2. Le rapport de performance idÃ©al\n" + "\n" + "Pour un projet d'analyse de sentiment, votre rapport d'Ã©valuation\n" + "devrait contenir :\n" + "\n" + "1.  La **matrice de confusion** pour visualiser les erreurs.\n" + "2.  Le **F1-score macro** comme indicateur principal de la performance.\n" + "3.  La **corrÃ©lation de Spearman** pour Ã©valuer la qualitÃ© du classement\n" + "    par score.\n" + "4.  La **couverture du lexique** : quel % de mots l'outil a-t-il reconnu\n" + "    ? Un score basÃ© sur 10% du texte est peu fiable.\n" + ":::\n" + "\n" + ":::: {.column width=\"50%\"}\n" + "### 3. Checklist d'analyse d'erreurs\n" + "\n" + "Une bonne mÃ©trique ne suffit pas. Il faut comprendre **pourquoi**\n" + "l'outil se trompe.\n" + "\n" + "-   L'outil gÃ¨re-t-il bien la **nÃ©gation** ? (*\"pas mauvais\"*)\n" + "-   Comprend-il les **adversatifs** ? (*\"beau mais lent\"*)\n" + "-   Est-il sensible Ã  l'**intensitÃ©** ? *\"un peu dÃ©Ã§u\" vs \"totalement\n" + "    dÃ©goÃ»tÃ©\"*)\n" + "-   Est-il adaptÃ© Ã  votre **domaine** ? (ex: le mot \"froid\" est nÃ©gatif\n" + "    pour un plat, mais positif pour une biÃ¨re).\n" + "\n" + "::: {.callout-note title=\"Le conseil final\"}\n" + "Aucune mÃ©trique n'est parfaite. La meilleure approche est de **combiner\n" + "une mÃ©trique quantitative robuste (F1-macro) avec une analyse\n" + "qualitative des erreurs** pour vraiment comprendre les forces et les\n" + "faiblesses de votre systÃ¨me.\n" + ":::\n" + "::::\n" + "::::::\n" + "\n" + "## PiÃ¨ges Ã  Ã©viter en analyse de sentiment {style=\"font-size:0.80em\"}\n" + "\n" + "MÃªme les meilleurs outils peuvent se tromper. Voici les piÃ¨ges les plus\n" + "courants Ã  anticiper :\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### PiÃ¨ges Linguistiques\n" + "\n" + "-   **AmbiguÃ¯tÃ©s** : l'implicite, l'ironie et le sarcasme peuvent\n" + "    totalement inverser la polaritÃ© et sont trÃ¨s difficiles Ã  dÃ©tecter\n" + "    automatiquement.\n" + "-   **PortÃ©e des \"shifters\"** : une nÃ©gation ou un adversatif (\"mais\")\n" + "    mal interprÃ©tÃ© peut fausser l'analyse d'une phrase entiÃ¨re.\n" + "\n" + "### PiÃ¨ges MÃ©thodologiques\n" + "\n" + "-   **DÃ©pendance au domaine** : un lexique entraÃ®nÃ© sur des avis de\n" + "    restaurants sera mÃ©diocre pour analyser des tweets financiers. Le\n" + "    vocabulaire et le contexte changent tout.\n" + "-   **Biais des lexiques** : un dictionnaire gÃ©nÃ©rique peut contenir des\n" + "    biais culturels ou Ãªtre inadaptÃ© au langage spÃ©cifique de certaines\n" + "    communautÃ©s en ligne (argot, mÃ¨mes).\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### PiÃ¨ges liÃ©s aux DonnÃ©es et Ã  l'Ã‰thique\n" + "\n" + "-   **Spam d'opinion (Fake Reviews)** : la prÃ©sence d'avis frauduleux\n" + "    (positifs ou nÃ©gatifs) peut complÃ¨tement fausser vos KPIs. La\n" + "    dÃ©tection de spam est un enjeu majeur.\n" + "-   **QualitÃ© des donnÃ©es** : des textes trÃ¨s courts, mal Ã©crits ou\n" + "    remplis d'emojis peuvent dÃ©grader la performance de n'importe quel\n" + "    modÃ¨le.\n" + ":::\n" + ":::::\n" + "\n" + "## De la question marketing au rapport final : la checklist d'un projet rÃ©ussi {style=\"font-size:0.70em\"}\n" + "\n" + "Un projet d'analyse de sentiment rÃ©ussi repose sur la **mÃ©thode** autant que sur les outils. Voici les Ã©tapes clÃ©s.\n" + "\n" + "### 1. Cadrer la question\n" + "\n" + "Tout part dâ€™un objectif mÃ©tier traduit en question analytique claire [@krugmannSentimentAnalysisAge2024a].  \n" + "\n" + "- *Buzz positif autour du lancement ?* â†’ **Classification binaire**  \n" + "- *Points forts et faibles perÃ§us ?* â†’ **Analyse par aspect (ABSA)**  \n" + "- *Comparaison avec un concurrent ?* â†’ **Analyse comparative**  \n" + "\n" + "### 2. Choisir lâ€™approche\n" + "\n" + "- **Lexiques + rÃ¨gles** : transparence, rapiditÃ©, exploration.  \n" + "- **Machine Learning** : performance et adaptation (+20 points en moyenne [@hartmannMoreFeelingAccuracy2023]).  \n" + "\n" + "### 3. PrÃ©parer les donnÃ©es\n" + "\n" + "- **ML** : constituer un **Gold Standard** de qualitÃ© (annotation claire, double codage, accord inter-annotateurs).  \n" + "- **Lexiques** : adapter le vocabulaire au domaine et contrÃ´ler les contresens.  \n" + "\n" + "### 4. Ã‰valuer et analyser\n" + "\n" + "- **Quantitatif** : prÃ©fÃ©rer matrice de confusion & F1-macro Ã  lâ€™accuracy seule.  \n" + "- **Qualitatif** : analyser les erreurs (nÃ©gation, ironie, implicite).  \n" + "- **Robustesse** : tester sur dâ€™autres plateformes ou pÃ©riodes.  \n" + "\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## Conclusion : de l'artisanat Ã  l'automatisation intelligente {style=\"font-size:0.62em\"}\n" + "\n" + "L'analyse de sentiment a connu une rÃ©volution. Nous sommes passÃ©s\n" + "d'approches manuelles Ã  des outils capables de comprendre le langage\n" + "avec une finesse sans prÃ©cÃ©dent.\n" + "\n" + "::::: columns\n" + "::: {.column width=\"50%\"}\n" + "### Lâ€™Ã©volution des mÃ©thodes\n" + "\n" + "-   **Hier : lexiques & rÃ¨gles (artisanat)** : MÃ©thodes transparentes et\n" + "    contrÃ´lables, excellentes pour l'exploration et pour tester des\n" + "    hypothÃ¨ses thÃ©oriques [@hartmannMoreFeelingAccuracy2023, p. 84].\n" + "\n" + "-   **Aujourdâ€™hui : Machine Learning & Deep Learning\n" + "    (industrialisation)** : Apprentissage sur donnÃ©es pour une meilleure\n" + "    adaptation au contexte et des performances nettement supÃ©rieures\n" + "    [@hartmannMoreFeelingAccuracy2023, p. 76].\n" + "\n" + "-   **Demain (et dÃ©jÃ  maintenant) : LLMs / IA gÃ©nÃ©rative** :\n" + "    ComprÃ©hension contextuelle \"sur Ã©tagÃ¨re\" (*zero-shot*) qui rivalise\n" + "    avec les modÃ¨les spÃ©cialisÃ©s, posant de nouveaux enjeux de\n" + "    reproductibilitÃ© et d'Ã©thique\n" + "    [@krugmannSentimentAnalysisAge2024a, p. 2, 16].\n" + ":::\n" + "\n" + "::: {.column width=\"50%\"}\n" + "### Les implications pour le marketing\n" + "\n" + "-   **De la description Ã  la prÃ©diction** : Au-delÃ  du comptage pos/neg :   anticipation de tendances (ex: cours de la bourse) et dÃ©tection\n" + "        de signaux faibles de crise [@hartmannMoreFeelingAccuracy2023, p. 76].\n" + "\n" + "-   **Connaissance client hyper-granulaire** : Les nuances dans des\n" + "    milliers de verbatims permettent d'affiner les personas, de\n" + "    personnaliser les messages et d'identifier des besoins non\n" + "    satisfaits pour lâ€™innovation\n" + "    [@agarwalProminentFeatureExtraction2016, p. 3].\n" + "\n" + "-   **Vigilance stratÃ©gique en continu** : L'e-rÃ©putation devient un\n" + "    **flux** d'information en temps rÃ©el qui peut alimenter des tableaux\n" + "    de bord et la prise de dÃ©cision au quotidien\n" + "    [@ahmadMachineLearningTechniques2017, p. 3].\n" + ":::\n" + ":::::\n" + "\n" + "::: {.callout-note title=\"Le message final\"}\n" + "La technologie devient de plus en plus puissante et accessible. Le rÃ´le\n" + "de lâ€™expert marketing nâ€™est plus de connaÃ®tre chaque dÃ©tail technique,\n" + "mais de **poser les bonnes questions**, d'**interprÃ©ter avec esprit\n" + "critique** et de **dÃ©cider** Ã  partir dâ€™insights fiables\n" + "[@hartmannMoreFeelingAccuracy2023].\n" + ":::\n" + "\n" + "------------------------------------------------------------------------\n" + "\n" + "## RÃ©fÃ©rences\n" + ""</script>
<script> window._input_filename = 'C:\Users\Olivier\Documents\GitHub\etudes_qualitatives_web\cours_5\cours_5.qmd'</script>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-agarwalProminentFeatureExtraction2016" class="csl-entry" role="listitem">
Agarwal, Basant, and Namita Mittal. 2016. <em>Prominent <span>Feature Extraction</span> for <span>Sentiment Analysis</span></em>. Socio-<span>Affective Computing</span>. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-25343-5">https://doi.org/10.1007/978-3-319-25343-5</a>.
</div>
<div id="ref-ahmadMachineLearningTechniques2017" class="csl-entry" role="listitem">
Ahmad, Munir, Shabib Aftab, Syed Shah Muhammad, and Sarfraz Ahmad. 2017. <span>â€œMachine <span>Learning Techniques</span> for <span>Sentiment Analysis</span>: <span>A Review</span>â€</span> 8 (3).
</div>
<div id="ref-dangSentimentAnalysisBased2020" class="csl-entry" role="listitem">
Dang, Nhan Cach, MarÃ­a N. Moreno-GarcÃ­a, and Fernando De La Prieta. 2020. <span>â€œSentiment <span>Analysis Based</span> on <span>Deep Learning</span>: <span>A Comparative Study</span>.â€</span> <em>Electronics</em> 9 (3): 483. <a href="https://doi.org/10.3390/electronics9030483">https://doi.org/10.3390/electronics9030483</a>.
</div>
<div id="ref-hartmannMoreFeelingAccuracy2023" class="csl-entry" role="listitem">
Hartmann, Jochen, Mark Heitmann, Christian Siebert, and Christina Schamp. 2023. <span>â€œMore Than a <span>Feeling</span>: <span>Accuracy</span> and <span>Application</span> of <span>Sentiment Analysis</span>.â€</span> <em>International Journal of Research in Marketing</em> 40 (1): 75â€“87. <a href="https://doi.org/10.1016/j.ijresmar.2022.05.005">https://doi.org/10.1016/j.ijresmar.2022.05.005</a>.
</div>
<div id="ref-hartmannComparingAutomatedText2019a" class="csl-entry" role="listitem">
Hartmann, Jochen, Juliana Huppertz, Christina Schamp, and Mark Heitmann. 2019. <span>â€œComparing Automated Text Classification Methods.â€</span> <em>International Journal of Research in Marketing</em> 36 (1): 20â€“38. <a href="https://doi.org/10.1016/j.ijresmar.2018.09.009">https://doi.org/10.1016/j.ijresmar.2018.09.009</a>.
</div>
<div id="ref-krippendorff2018content" class="csl-entry" role="listitem">
Krippendorff, Klaus. 2018. <em>Content Analysis: An Introduction to Its Methodology</em>. Sage publications.
</div>
<div id="ref-krugmannSentimentAnalysisAge2024a" class="csl-entry" role="listitem">
Krugmann, Jan Ole, and Jochen Hartmann. 2024. <span>â€œSentiment <span>Analysis</span> in the <span>Age</span> of <span>Generative AI</span>.â€</span> <em>Customer Needs and Solutions</em> 11 (1): 3. <a href="https://doi.org/10.1007/s40547-024-00143-4">https://doi.org/10.1007/s40547-024-00143-4</a>.
</div>
<div id="ref-landisMeasurementObserverAgreement1977" class="csl-entry" role="listitem">
Landis, J. Richard, and Gary G. Koch. 1977. <span>â€œThe <span>Measurement</span> of <span>Observer Agreement</span> for <span>Categorical Data</span>.â€</span> <em>Biometrics</em> 33 (1): 159. <a href="https://doi.org/10.2307/2529310">https://doi.org/10.2307/2529310</a>.
</div>
<div id="ref-liuSentimentAnalysisOpinion" class="csl-entry" role="listitem">
Liu, Bing. 2022. <em>Sentiment Analysis and Opinion Mining</em>. Springer Nature.
</div>
<div id="ref-mcdermottCloserLookAUROC2025" class="csl-entry" role="listitem">
McDermott, Matthew B. A., Haoran Zhang, Lasse Hyldig Hansen, Giovanni Angelotti, and Jack Gallifant. 2025. <span>â€œA <span>Closer Look</span> at <span>AUROC</span> and <span>AUPRC</span> Under <span>Class Imbalance</span>.â€</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2401.06091">https://doi.org/10.48550/arXiv.2401.06091</a>.
</div>
<div id="ref-mchugh2012interrater" class="csl-entry" role="listitem">
McHugh, Mary L. 2012. <span>â€œInterrater Reliability: The Kappa Statistic.â€</span> <em>Biochemia Medica</em> 22 (3): 276â€“82.
</div>
<div id="ref-pangOpinionMiningSentiment" class="csl-entry" role="listitem">
Pang, Bo, Lillian Lee, et al. 2008. <span>â€œOpinion Mining and Sentiment Analysis.â€</span> <em>Foundations and Trends<span></span> in Information Retrieval</em> 2 (1â€“2): 1â€“135.
</div>
</div>
</section></section>

    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="cours_5_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="cours_5_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/revealeditable/editable.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="cours_5_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="cours_5_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1250,

        height: 760,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, Revealeditable, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    

    <script>

      // htmlwidgets need to know to resize themselves when slides are shown/hidden.

      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current

      // slide changes (different for each slide format).

      (function () {

        // dispatch for htmlwidgets

        function fireSlideEnter() {

          const event = window.document.createEvent("Event");

          event.initEvent("slideenter", true, true);

          window.document.dispatchEvent(event);

        }

    

        function fireSlideChanged(previousSlide, currentSlide) {

          fireSlideEnter();

    

          // dispatch for shiny

          if (window.jQuery) {

            if (previousSlide) {

              window.jQuery(previousSlide).trigger("hidden");

            }

            if (currentSlide) {

              window.jQuery(currentSlide).trigger("shown");

            }

          }

        }

    

        // hookup for slidy

        if (window.w3c_slidy) {

          window.w3c_slidy.add_observer(function (slide_num) {

            // slide_num starts at position 1

            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);

          });

        }

    

      })();

    </script>

    

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script type="text/javascript">
      Reveal.on('ready', event => {
        if (event.indexh === 0) {
          document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
        }
      });
      Reveal.addEventListener('slidechanged', (event) => {
        if (event.indexh === 0) {
          Reveal.configure({ slideNumber: null });
          document.querySelector("div.has-logo > img.slide-logo").style.display = "none";
        }
        if (event.indexh === 1) { 
          Reveal.configure({ slideNumber: 'c/t' });
          document.querySelector("div.has-logo > img.slide-logo").style.display = null;
        }
      });
    </script>
    

</body></html>