---
title: "√âtudes qualitatives sur le web (netnographie)"
subtitle: "Introduction au NLP/TALN - Traitement des donn√©es textuelles"
author:
  - name: "Olivier Caron"
    affiliations: "Paris Dauphine - PSL"
format:
  ubd-revealjs:
    self-contained: false
    chalkboard: true
    transition: fade
    auto-stretch: false
    width: 1250
    height: 760
    toc: false
    toc-depth: 1
    code-block-height: 700px
execute:
  echo: true
bibliography: refs.bib
revealjs-plugins:
  - editable
filters:
  - editable
---

## R√©volution du texte : production & lecture {style="font-size:0.9em"}

-   Explosion de la **production textuelle** (posts, avis, X/Twitter, TikTok, LinkedIn, articles scientifiques).
-   Cons√©quence : **impossible de tout lire** ‚Üí besoin d‚Äôautomatisation (indexation, filtrage, r√©sum√©s).
-   **R√©volution de la lecture** : moteurs de recherche, curation, algorithmes de recommandation.

::: callout-note
üëâ En marketing digital : les consommateurs produisent massivement du texte (avis, posts, hashtags).\
- Exemple : des millions d‚Äôavis TripAdvisor / Google Reviews chaque jour.\
- Exemple r√©seaux sociaux : hashtags #AI, #TikTokMadeMeBuyIt, #Dropshipping qui se renouvellent en continu.\
- Exemple SEO : Google doit **s√©lectionner** des mots-cl√©s pertinents ‚Üí strat√©gie centrale en r√©f√©rencement.
:::

# Fondements th√©oriques du langage pour la netnographie {.transition-slide-ubdblue}

## Deux perspectives qui se compl√®tent {style="font-size:0.9em"}

::::: columns
::: {.column width="50%"}
### Perspective **structuraliste**

La langue comme **syst√®me** (cat√©gories, oppositions, r√®gles).\
Finalit√© : d√©crire l‚Äô**architecture** qui stabilise les usages.

\

*Exemple : le hashtag **#MondayMotivation** comme convention collective sur X/LinkedIn qui structure les pratiques.*
:::

::: {.column width="50%"}
### Perspective **pragmatique / usage**

Le langage comme **activit√©** situ√©e et sociale.\
Finalit√© : comprendre **ce que fait** un message et comment il circule.

\
\

*Exemple : le d√©tournement ironique **#MondayDespair** illustre l‚Äôusage cr√©atif et viral sur TikTok.*
:::
:::::

\
\


::: callout-note
Ces perspectives s‚Äôarticulent : la **structure** rend les √©nonc√©s intelligibles ; l‚Äô**usage** leur donne port√©e et effets.
:::

------------------------------------------------------------------------

## Saussure : syst√®me de signes et niveaux d‚Äôanalyse {style="font-size:0.9em"}

:::::: columns
::: {.column width="58%"}
-   **Langage** : capacit√© humaine de signifier.\
-   **Langue** : **code partag√©** (unit√©s, oppositions, r√®gles).\
-   **Parole** : r√©alisation **situ√©e** de la langue (style, variations).\
-   **Texte** : mat√©rialisation de la parole (post, avis, thread).

**Cons√©quence** : distinguer conventions **collectives** (formats, hashtags, routines) et innovations **singuli√®res** (m√®mes, d√©tournements).

*Exemple : la story Instagram = convention collective ; un remix TikTok ou un m√®me d√©tournant une pub de luxe = innovation singuli√®re.*
:::

:::: {.column width="42%"}

\
\

::: callout-tip
### Notions cl√©s

- La **valeur** d‚Äôun signe d√©pend des **diff√©rences** avec les autres signes.\
- Le **syst√®me** donne un cadre ; l‚Äô**usage** l‚Äôactualise et l‚Äôinfl√©chit.
:::
::::
::::::

------------------------------------------------------------------------

## Chomsky & Tesni√®re : structure, d√©pendances, g√©n√©rativit√© {style="font-size:1em"}

:::::: columns
::: {.column width="57%" style="font-size:0.75em"}

-   **Grammaire g√©n√©rative** : un ensemble **fini de r√®gles** ‚Üí une infinit√© d‚Äô√©nonc√©s.\
-   **Comp√©tence** (connaissance implicite) vs **performance** (usage effectif).\
-   **Arbres** (constituants/d√©pendances) : qui gouverne qui ? quelle **port√©e** pour la n√©gation, les modaux, les intensifs ?

### Apport interpr√©tatif

La structure **module** le sens : 

- ‚Äúpas **vraiment** satisfaisant‚Äù ‚â† ‚Äú**vraiment** pas satisfaisant‚Äù.\
- Les relations syntaxiques r√©v√®lent **cibles** (produit, marque, service) et **attributs** (prix, qualit√©, d√©lai).

*Exemple SEO : ‚Äúacheter iPhone 16 pas cher‚Äù ‚â† ‚ÄúiPhone 16 pas cher acheter‚Äù. La syntaxe change la pertinence des r√©sultats Google.*
:::

:::: {.column width="43%"}
::: callout-note
### Indicateurs r√©currents
- N√©gation\
- Modalit√© (‚Äúil faudrait‚Äù, ‚Äúon doit‚Äù)\
- Intensit√© (‚Äútr√®s‚Äù, ‚Äútrop‚Äù, ‚Äúvraiment‚Äù)\
- Comparaison (‚Äúplus/moins que‚Äù)

*Exemple : un avis ‚ÄúCe service est **trop lent**‚Äù ‚Üí intensit√© n√©gative claire d√©tectable en NLP.*
:::
::::
::::::

------------------------------------------------------------------------

## Jakobson : fonctions du langage et formats de message {style="font-size:0.75em"}

::::: columns
::: {.column width="60%"}
Les messages combinent des **fonctions** avec des dominantes variables :

1. **R√©f√©rentielle** ‚Äî informer sur le monde (faits, caract√©ristiques).  
   - ex. ‚ÄúCe t√©l√©phone a un √©cran 6,5 pouces.‚Äù
2. **Expressive** ‚Äî manifester une attitude ou une √©motion.  
   - ex. ‚ÄúJ‚Äôadore ce parfum üòç‚Äù
3. **Conative** ‚Äî orienter le destinataire (inciter, solliciter).  
   - ex. ‚ÄúAbonnez-vous maintenant !‚Äù
4. **Phatique** ‚Äî ouvrir/entretenir le canal d‚Äô√©change.  
   - ex. ‚ÄúHello TikTok, qui est l√† ?‚Äù
5. **M√©talinguistique** ‚Äî expliciter le code (d√©finitions, balises).  
   - ex. ‚ÄúRT = retweet‚Äù
6. **Po√©tique** ‚Äî valoriser la forme (style, rime, m√®me, slogan).  
   - ex. ‚ÄúJust do it.‚Äù (ou slogan g√©n√©r√© par IA)

Les **genres** (unboxing, SAV, teasing, t√©moignage) stabilisent des combinaisons de fonctions.
:::

::: {.column width="40%"}
::: callout-tip
### Exemple de campagne : **Nike**
- **R√©f√©rentielle** : ‚ÄúUne seule fa√ßon de savoir.‚Äù  
- **Expressive** : √©motion de l‚Äôathl√®te en pleine action.  
- **Po√©tique** : slogan **JUST DO IT.**  
- **Conative** : boutons ‚Äú√âquipe-toi‚Äù / ‚ÄúRegarder‚Äù.
:::

![](images/clipboard-2230655830.png){fig-align="center" width="100%"}
:::
:::::


------------------------------------------------------------------------

## Austin : le langage comme action {style="font-size:0.9em"}

> ‚ÄúDire, c‚Äôest **faire**.‚Äù

:::::: columns
::: {.column width="58%"}
-   **Locutoire** : forme et contenu litt√©ral.\
-   **Illocutoire** : **acte** r√©alis√© (remercier, promettre, bl√¢mer, recommander, alerter‚Ä¶).\
-   **Perlocutoire** : **effet** produit (convaincre, mobiliser, dissuader, apaiser‚Ä¶).

Un √©nonc√© **√©value** et **agit** : il oriente l‚Äô√©change, peut enclencher des r√©ponses, amplifier ou clore une discussion.

*Exemple : un avis Google ‚ÄúJe recommande cette boutique‚Äù = acte illocutoire de recommandation.*
:::

:::: {.column width="42%"}
::: callout-important
### Indices
- Verbes et formules illocutoires (‚Äúje recommande / d√©conseille‚Äù)\
- Traces perlocutoires (r√©ponses, relais, reconfigurations du fil)

*Exemple 2024 : un tweet ‚ÄúBoycottez Shein‚Äù = illocutoire ; la tendance **#BoycottShein** qui explose = perlocutoire.*
:::
::::
::::::

------------------------------------------------------------------------

## Firth & Harris : le sens par les contextes {style="font-size:0.9em"}

> ‚ÄúYou shall know a word by the **company** it keeps.‚Äù ‚Äî *J. R. Firth*

:::::: columns
::: {.column width="57%"}
-   **Hypoth√®se distributionnelle** : des mots partageant des **contextes** pr√©sentent des **proximit√©s de sens**.\
-   Le **voisinage** (cooccurrences, fen√™tres, d√©pendances) caract√©rise les **associations**.

**Cons√©quence** : le sens **relationnel** se lit dans les **profils de contexte** (collocations, patrons d‚Äôusage, r√©gularit√©s de voisinage).

*Exemple : Google apprend que ‚Äúmeilleur smartphone‚Äù ‚âà ‚Äútop t√©l√©phone‚Äù car ils apparaissent dans des contextes tr√®s proches.*
:::

:::: {.column width="43%"}
::: callout-note
### Pratiques d‚Äôobservation
- Rep√©rer cooccurrences fortes\
- Identifier collocations (‚Äúservice client‚Äù, ‚Äútrop + adjectif‚Äù)\
- Suivre les patrons relationnels stables

*Exemple : ‚Äúpremium‚Äù cooccurrent avec ‚Äúqualit√©‚Äù ‚Üí connotation positive ; ‚Äúprix‚Äù cooccurrent avec ‚Äútrop‚Äù ‚Üí connotation n√©gative.*
:::
::::
::::::

------------------------------------------------------------------------

## Zipf : fr√©quences, longue tra√Æne et visibilit√© {style="font-size:0.9em"}

:::::: columns
::: {.column width="50%" style="font-size:0.90em"}
-   **Loi de Zipf** : quelques formes **tr√®s fr√©quentes**, une **longue tra√Æne** de rares.\
-   **Effets** :
    -   Les unit√©s **structurelles** dominent la volum√©trie (**"colle" du discours**).
        -   ex. ‚Äúthe, and, of‚Äù ou ‚Äúle, de, et‚Äù\
    -   Les √©l√©ments **distinctifs** se situent souvent en **fr√©quence moyenne**.
        -   ex. dans des tweets politiques 2024 : ‚Äúr√©forme, climat, imp√¥t‚Äù\
    -   Les **signaux faibles** (rares) portent innovations et codes internes.
        -   ex. hashtags ponctuels : *#AIart*, *#TikTokMadeMeBuyIt*, *#BackToSchool2025*

üëâ La fr√©quence renseigne moins sur l‚Äô‚Äúimportance‚Äù que sur le **r√¥le** (structurel, distinctif, √©mergent).
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: callout-tip
### Question directrice

Que dit la **position fr√©quentielle** d‚Äôune forme sur sa fonction discursive et sa place dans le r√©pertoire d‚Äôune communaut√© ?\

- **Fr√©quent** = colle du langage (structural)\
- **Moyen** = propre au th√®me ou au groupe (distinctif)\
- **Rare** = √©mergent, innovation, code interne
:::

Exemple classique : loi de Zipf sur *Ulysses* de James Joyce.
![](images/clipboard-4009297054.png){fig-align="center" width="80%"}

::::
::::::

------------------------------------------------------------------------

## Genette : textes en r√©seau (transtextualit√©) {style="font-size:0.80em"}


:::::: columns
::: {.column width="60%"}


-   **Intertextualit√©** : citations, allusions, r√©emplois.
    -   ex. un TikTok reprend un son viral ou cite une punchline de rap.\
-   **Paratexte** : titraille, visuels, √©mojis, alt-text, l√©gendes, tags.
    -   ex. la vignette YouTube ‚Äúchoc üò±‚Äù ou les #SEO dans un post LinkedIn.\
-   **M√©tatexte** : commentaires et critiques d‚Äôautres textes.
    -   ex. un thread X qui d√©monte une campagne publicitaire.\
-   **Hypertexte** : transformations/variations (parodie, remix, d√©tournement).
    -   ex. d√©tournement humoristique d‚Äôune pub Apple sur Insta.\
-   **Architexte** : appartenance √† un **genre** (unboxing, SAV, t√©moignage, teasing).
    -   ex. le format ‚Äúhaul Shein‚Äù sur TikTok ou les ‚Äúunboxing iPhone‚Äù chaque rentr√©e.

üëâ Un message s‚Äô**inscrit** dans des **cha√Ænes** : r√©f√©rences et paratexte orientent sa lecture et sa circulation.
:::

:::: {.column width="40%"}

\
\
\


::: callout-note
### Indices de r√©seau

-   Mentions (\@, #), citations, formats de reprise (duos, stitches).\
-   R√¥le du layout et des m√©tadonn√©es dans l‚Äôorientation interpr√©tative.

*Exemple : un duo TikTok qui r√©pond √† une vid√©o originale, avec emojis + hashtag sponsoris√© ‚Üí la circulation du texte est d√©j√† orient√©e par le format.*
:::
::::
::::::

## R√©capitulatif application marketing {style="font-size:0.75em"}

| Th√©orie / outil | Exemple digital | Utilit√© marketing |
|------------------|------------------------------|-------------------------|
| Saussure (langue/parole) | Story IG (code) vs remix TikTok (innovation) | Adapter format & cr√©ativit√© au canal |
| Chomsky/Tesni√®re | Syntaxe requ√™tes SEO (‚Äúacheter‚Ä¶ pas cher‚Ä¶‚Äù) | Pertinence SEO & compr√©hension requ√™tes |
| Jakobson (6 fonctions) | Campagne Nike multi-fonctions | Conception messages & CTA efficaces |
| Austin (actes de langage) | ‚Äú#BoycottShein‚Äù (illo‚Üíperlo) | G√©rer r√©putation & crises |
| Firth/Harris (contextes) | ‚Äúpremium‚Äù ‚Üî ‚Äúqualit√©‚Äù, ‚Äúprix‚Äù ‚Üî ‚Äútrop‚Äù | Analyse de sentiment & positionnement |
| Zipf (fr√©quences) | Hashtags campagne : fr√©quent/moyen/rare | Social listening : bruit / th√®mes / signaux |
| Genette (r√©seaux) | Duos/stitches, parodies, vignettes YouTube | Strat√©gies de diffusion & formats natifs |

------------------------------------------------------------------------

## Limites et pr√©cautions d‚Äôinterpr√©tation

-   **Ironie / sarcasme / polyphonie** : contrastes forme‚Äìcontenu, indices paratextuels.\
-   **Genres hybrides** : brouillage des fonctions selon le format.\
-   **Dynamiques communautaires** : normes mouvantes, cycles d‚Äôattention.\
-   **Biais d‚Äôobservation** : moments chauds, invisibilit√©s (lurkers).\
-   **√âthique** : respect des espaces, consentements, anonymisation.

# De la th√©orie‚Ä¶ √† la m√©thodologie {.transition-slide-ubdyellow}

## Roadmap Humphreys & Wang (2018) 1/2 [@humphreys2018]

### √âtapes

::: incremental
-   **1. Research question** ‚Äî formuler une question adapt√©e √† l‚Äôanalyse textuelle
-   **2. Construct identification** ‚Äî identifier les construits (√©motion, influence, statut, etc.)
-   **3. Data collection** ‚Äî collecter les corpus (posts, avis, threads)
-   **4. Operationalization** ‚Äî transformer les construits en indicateurs (dictionnaires, mod√®les)
-   **5. Interpretation & analysis** ‚Äî relier r√©sultats et th√©orie (comparaison, corr√©lation, pr√©diction)
-   **6. Validation** ‚Äî v√©rifier robustesse (multi-op√©rationnalisation, triangulation, hold-out sample)
:::

## Roadmap Humphreys & Wang (2018) 2/2

![](images/clipboard-1874408983.png){fig-align="center" width="100%"} {.fragment}

------------------------------------------------------------------------

## Apports principaux de la d√©marche

-   **D√©couverte** : r√©v√©ler des r√©gularit√©s invisibles √† l‚Äô≈ìil humain\
-   **Pr√©cision** : mesurer avec impartialit√© √† grande √©chelle\
-   **Validit√© √©cologique** : analyser des discours en contexte naturel\
-   **Multi-niveaux** : individus, dyades, groupes, cultures\
-   **Guidelines m√©thodologiques** : dictionnaires, √©chantillonnage, validation, analyse de donn√©es textuelles clairsem√©es

------------------------------------------------------------------------

## Points d‚Äôancrage

-   **Structuraliste** : la langue comme **syst√®me** (formes, oppositions, d√©pendances).\
-   **Pragmatique / usage** : le message comme **action** situ√©e (fonctions, actes, effets).\
-   **Distribution / contexte** : le sens comme **relation** (voisinages, collocations, patrons).\
-   **R√©seaux de textes** : la signification comme **inscription** sociale (intertextes, paratextes, genres).

**Cha√Æne d‚Äôanalyse** : **Structure ‚Üí Fonction ‚Üí Contexte ‚Üí Distribution ‚Üí Acte ‚Üí R√©seau**.

# De la th√©orie‚Ä¶ √† la pratique {.transition-slide-ubdyellow}

## Pr√©-traitement du corpus

\

### Pourquoi nettoyer les donn√©es textuelles ?

-   Les textes bruts (avis, tweets, posts) contiennent du **bruit** : ponctuation, chiffres, emojis, urls‚Ä¶\
-   Le nettoyage am√©liore la qualit√© des analyses (fr√©quences, co-occurrences, mod√®les).\
-   **Objectif** : obtenir un corpus standardis√©, coh√©rent et exploitable.

------------------------------------------------------------------------

## Pr√©-traitement : op√©rations courantes

-   Passage en **minuscules**\
-   Suppression de la **ponctuation / chiffres / urls**\
-   Suppression des **stopwords** (*mots vides* : le, la, de, un‚Ä¶)\
-   **Stemming** : r√©duire les mots √† leur racine (*ex. aimer, aimait ‚Üí aim*)\
-   **Lemmatisation** : r√©duire les mots √† leur forme canonique (*aimait ‚Üí aimer*)

::: callout-note
üëâ Ces √©tapes peuvent √™tre adapt√©es selon la recherche : ne pas trop nettoyer au risque de perdre du sens ou des informations.
:::

------------------------------------------------------------------------

## Tokeniser = d√©couper en tokens (unit√©s) {style="font-size:0.68em"}

Avant toute analyse, on segmente le texte brut en **tokens** (unit√©s). C‚Äôest la base de la DTM/BoW, du TF-IDF, des cooccurrences et de la keyness. *(Le POS tagging est vu juste apr√®s.)*


:::::: columns
::: {.column width="50%"}
### Le principe : transformer la phrase en ¬´ briques ¬ª
- **Tokenisation mots** : liste de **mots** et **signes** (ponctuation, hashtags, emojis, mentions).
- Un **token** peut √™tre :
  - un **mot** (*service*, *client*),  
  - de la **ponctuation** (`,` `!`),  
  - un **hashtag** (`#AmazonPrime`),  
  - une **mention** (`@Amazon`),  
  - un **emoji** (`üòç`).

### D√©cisions FR √† documenter (avant d‚Äôanalyser)
- **Apostrophes** : `l‚Äôexp√©dition` ‚Üí `["l'", "exp√©dition"]`, `c‚Äôest` ‚Üí `["c'", "est"]`
- **N√©gation disjointe** : *ne ‚Ä¶ pas* ‚Üí ne pas supprimer **ne**
- **Hashtags/mentions/emojis** : souvent **conserver** (signal th√©matique/ton)
- **URLs / nombres** : normaliser (`<URL>`, `<NUM>`) si bruit
- **Traits d‚Äôunion** : *service-apr√®s-vente*, *click-and-collect* ‚Üí garder ou s√©parer
:::

::: {.column width="50%"}
### Exemple (FR ‚Äî Amazon) : sortie obtenue (tokenisation)
**Texte :**  
‚ÄúJ‚Äôadore le service client d'Amazon, c‚Äôest top ! üòç #AmazonPrime‚Äù

**Tokens :**  
`['J‚Äô', 'adore', 'le', 'service', 'client', "d'", 'Amazon', ',', 'c‚Äô', 'est', 'top', '!', 'üòç', '#', 'AmazonPrime']`

\
\

::: callout-tip
### Pourquoi c‚Äôest la base ?
Sans tokens, on ne peut pas **compter** (fr√©quences/Zipf), construire **BoW/TF-IDF**, ni comparer avec **keyness**.
:::

``` {.python code-line-numbers="1|2|3|4|5|6"}
import spacy
nlp = spacy.load("fr_core_news_sm")
s = "J‚Äôadore le service client d'Amazon, c‚Äôest top ! üòç #AmazonPrime"
doc = nlp(s)
tokens = [t.text for t in doc]
print(tokens)
```

:::
::::::

## Repr√©sentation : "Bag-of-Words"

:::::: columns
::: {.column width="30%" style="font-size:0.7em"}
### Le principe

-   Une fois le texte nettoy√©, il faut le transformer en chiffres pour que la machine puisse le traiter.
-   Le mod√®le **"sac de mots" (BoW)** est la m√©thode la plus simple :
    -   On repr√©sente un document uniquement par les mots qu'il contient.
    -   L'**ordre des mots** et la grammaire sont volontairement **ignor√©s**.
-   Cette approche permet de cr√©er une **Matrice Document-Terme (DTM)**.

![](images/clipboard-534031787.png)
:::

:::: {.column width="70%" style="font-size:0.55em"}
::: {.callout-note title="Exemple de DTM apr√®s stopwords FR"}
**Corpus :**

-   D1: "Produit **excellent et** pas cher"
-   D2: "Produit **m√©diocre et** tr√®s cher"
-   D3: "Produit **excellent et** vraiment pas cher"
-   D4: "Produit **m√©diocre et** assez cher"

**Matrice (DTM) :**

|        | produit | excellent | m√©diocre | cher | pas | tr√®s | vraiment | assez |
|:-------|:-------:|:---------:|:--------:|:----:|:---:|:----:|:--------:|:-----:|
| **D1** |    1    |     1     |    0     |  1   |  1  |  0   |    0     |   0   |
| **D2** |    1    |     0     |    1     |  1   |  0  |  1   |    0     |   0   |
| **D3** |    1    |     1     |    0     |  1   |  1  |  0   |    1     |   0   |
| **D4** |    1    |     0     |    1     |  1   |  0  |  0   |    0     |   1   |

Chaque ligne est un **vecteur** qui repr√©sente un document.
:::
::::
::::::

------------------------------------------------------------------------

## Pond√©ration des termes : TF-IDF

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### L'intuition

La fr√©quence brute (compter les mots) est limit√©e. Le **TF-IDF** est une pond√©ration plus intelligente qui vise √† faire ressortir les mots **sp√©cifiques** d'un document.

-   **TF (Term Frequency)** : poids d'un mot dans **un** document. Un mot fr√©quent est important *pour ce document*.
-   **IDF (Inverse Document Frequency)** : poids d'un mot dans **tout** le corpus. Un mot pr√©sent partout (ex: "le", "produit") est peu informatif, donc son poids est faible.

Un **TF-IDF √©lev√©** signale un mot-cl√© caract√©ristique.
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: {.callout-note title="Les formules"}
Pour un terme $t$ dans un document $d$ au sein d'un corpus $D$ :

-   **Fr√©quence du terme (TF)** : $TF(t,d) = \frac{\text{nombre de fois o√π } t \text{ appara√Æt dans } d}{\text{nombre total de mots dans } d}$

-   **Fr√©quence inverse de document (IDF)** : $IDF(t,D) = \log\left(\frac{\text{nombre total de documents}}{\text{nombre de documents contenant } t}\right)$

-   **Score TF-IDF** : $TFIDF(t,d,D) = TF(t,d) \times IDF(t,D)$
:::
::::
::::::

------------------------------------------------------------------------

## Statistiques lexicales exploratoires

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### "Sentir" le corpus

Avant toute analyse complexe, des indicateurs simples permettent de comprendre la nature des donn√©es :

-   **Fr√©quences de mots** :
    -   Quels sont les termes les plus utilis√©s (hors *stopwords*) -\> donne une id√©e des th√®mes dominants.
    -   Visualisation : **nuage de mots**.
-   **Hapax Legomena** :
    -   Mots n'apparaissant qu'**une seule fois** dans tout le corpus.
    -   Souvent 30-50% du vocabulaire (selon taille corpus). Ils peuvent √™tre du bruit (fautes de frappe) ou des signaux faibles (jargon √©mergent).
:::

:::: {.column width="50%" style="font-size:0.75em"}
### Richesse du vocabulaire (TTR, CTTR, MATTR, Maas...)

\

-   **Diversit√© lexicale (TTR)** :
    -   Mesure la richesse du vocabulaire utilis√© dans un texte.
    -   Le *Type-Token Ratio* est le calcul le plus simple.

::: {.callout-note title="Formule du TTR"}
$$ TTR = \frac{\text{Nombre de mots uniques (types)}}{\text{Nombre total de mots (tokens)}} $$ Un TTR proche de 1 indique un vocabulaire tr√®s vari√© ; un TTR faible un langage r√©p√©titif.
:::
::::
::::::

------------------------------------------------------------------------

## Approfondir la diversit√© lexicale

:::::: columns
::: {.column width="55%" style="font-size:0.85em"}
### Au-del√† du TTR

Le **Type-Token Ratio (TTR)** est un bon d√©but, mais faiblesse majeure -\> tr√®s sensible √† la longueur du texte. Un texte plus long aura m√©caniquement un TTR plus faible car on est forc√© de r√©p√©ter des mots.

\
¬†

### Mesures plus robustes

\
\

Pour comparer des textes de longueurs diff√©rentes, on utilise des indicateurs plus avanc√©s comme le **MTLD** (Measure of Textual Lexical Diversity).

-   **Principe** : L'algorithme calcule le TTR moyen sur des segments cons√©cutifs du texte, ce qui le rend ind√©pendant de la longueur totale.
:::

:::: {.column width="45%"}
::: {.callout-tip title="Applications en Netnographie" style="font-size:0.9em"}
Analyser la diversit√© lexicale permet de :

-   **Profiler des auteurs** : un vocabulaire pauvre et r√©p√©titif peut √™tre un indice de spams ou de faux avis g√©n√©r√©s automatiquement.
-   **Caract√©riser une communaut√©** : un jargon riche et vari√© est souvent le signe d'une communaut√© d'experts ou de passionn√©s.
-   **Segmenter des retours clients** : les commentaires tr√®s riches lexicalement peuvent contenir des insights plus d√©taill√©s que les commentaires laconiques.
:::
::::
::::::

------------------------------------------------------------------------

## Mesurer la lisibilit√© du texte (Readability)

La lisibilit√© mesure la **facilit√© de lecture et de compr√©hension** d'un texte. Elle ne d√©pend pas seulement de la richesse du vocabulaire, mais aussi de la complexit√© syntaxique.

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### Les deux piliers de la complexit√©

La plupart des scores de lisibilit√© se basent sur deux variables simples :

1.  **Complexit√© s√©mantique** : longueur des mots (en syllabes ou en caract√®res). Des mots longs sont consid√©r√©s comme plus difficiles.
2.  **Complexit√© syntaxique** : longueur des phrases (en nombre de mots). Des phrases longues sont plus complexes √† analyser pour le lecteur.

Le score le plus c√©l√®bre en anglais est le **Flesch-Kincaid Reading Ease**.
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: {.callout-note title="Scores & Applications" style="font-size:0.75em"}
#### Formule g√©n√©rale

La plupart des scores suivent une logique de ce type : $Score = A - (B \times \frac{\text{mots}}{\text{phrase}}) - (C \times \frac{\text{syllabes}}{\text{mot}})$

#### Utilit√© en marketing

-   **Auditer le contenu de marque** : le langage utilis√© sur un site web ou les r√©seaux sociaux est-il adapt√© √† la cible ? Est-il trop simple ? Trop jargonnant ?
-   **Analyser l'audience** : le niveau de langage des consommateurs dans leurs avis peut-il r√©v√©ler leur niveau d'expertise ?
:::
::::
::::::

------------------------------------------------------------------------

## Lisibilit√© en fran√ßais : les outils sp√©cifiques

::::::: columns
:::: {.column width="55%" style="font-size:0.85em"}
### Kandel & Moles : l'adaptation de Flesch

C'est la formule historique (1958) et la plus directe pour le fran√ßais. Le principe est le m√™me que pour l'anglais : combiner la longueur des mots et des phrases.

-   **Score de 0 √† 100** :
    -   **Score √©lev√© (\> 70)** : texte facile √† lire.
    -   **Score bas (\< 40)** : texte difficile (technique, acad√©mique).

::: {.callout-note title="La formule pour le fran√ßais" style="font-size:0.60em"}
Le score est calcul√© ainsi :

$Score = 207 - (1.015 \times \text{longueur moyenne des phrases})$ $- (73.6 \times \text{nombre moyen de syllabes par mot})$
:::
::::

:::: {.column width="45%" style="font-size:0.70em"}
### Alternative et pratique moderne

-   **Indice de Gunning Fog** :
    -   Une autre approche qui se base sur le pourcentage de **"mots complexes"** (g√©n√©ralement 3 syllabes ou plus).
    -   Le score estime le **nombre d'ann√©es d'√©tudes** n√©cessaires pour comprendre le texte.
-   **Outils NLP actuels** :
    -   Aujourd'hui, on utilise des biblioth√®ques Python pour faire ces calculs.
    -   **`pyphen`** : pour compter les syllabes en fran√ßais.
    -   **`textstat`** : pour calculer directement les scores de lisibilit√©.\
    -   En **R** : les packages comme `quanteda` ou `koRpus` offrent aussi ces fonctionnalit√©s.

::: {.callout-tip title="A retenir" style="font-size:1em"}
Le principe reste le m√™me : un texte simple = mots courts + phrases courtes. Les formules pour le fran√ßais ne font que calibrer cette id√©e aux particularit√©s statistiques de notre langue.
:::
::::
:::::::

------------------------------------------------------------------------

## Analyse de co-occurrences et collocations

:::::: columns
::: {.column width="55%"}
### Le sens par l'association

On d√©passe le "sac de mots" pour analyser **quels mots apparaissent ensemble**.

-   **Co-occurrence** : deux mots qui apparaissent fr√©quemment dans un m√™me contexte (ex: phrase, fen√™tre de 5 mots).
    -   Permet de cr√©er des **graphes de mots** pour visualiser les clusters th√©matiques.
-   **Collocation** : une co-occurrence si forte qu'elle forme une expression presque fig√©e.
    -   Ex: "service client", "rapport qualit√©-prix".
:::

:::: {.column width="45%"}
::: {.callout-important title="Mesurer la force d'association" style="font-size:0.9em"}
On peut quantifier si une co-occurrence est due au hasard ou √† un lien s√©mantique fort. Le **Pointwise Mutual Information (PMI)** est une mesure courante.

$PMI(x,y) = \log_2\left(\frac{P(x,y)}{P(x)P(y)}\right)$

-   $P(x,y)$ : probabilit√© de voir x et y ensemble.
-   $P(x)P(y)$ : probabilit√© de les voir ensemble si leur apparition √©tait ind√©pendante.

Un PMI √©lev√© sugg√®re un lien s√©mantique fort.
:::
::::
::::::

------------------------------------------------------------------------

## Analyse de "Keyness" (mots-cl√©s) 1/3

:::::: columns
::: {.column width="60%"}
### Qu'est-ce qui diff√©rencie deux discours ?

-   La **Keyness** identifie les mots **statistiquement sur-repr√©sent√©s** dans un corpus A par rapport √† un corpus de r√©f√©rence B.
-   C'est une m√©thode puissante pour **caract√©riser et comparer** des ensembles de textes.
-   **Applications** :
    -   Avis 5‚òÖ vs 1‚òÖ : Quels mots sont "cl√©s" pour les clients satisfaits ?
    -   Tweets avant vs apr√®s une crise : quel vocabulaire a √©merg√© ?
    -   Articles de presse : comparer le lexique Sports masculins vs f√©minins
:::

:::: {.column width="40%"}
::: {.callout-note title="Principe statistique" style="font-size:0.7em"}
Pour chaque mot, on construit un tableau de contingence :

|                       | **Corpus A (cible)** | **Corpus B (r√©f.)** |
|:----------------------|:--------------------:|:-------------------:|
| **Freq. mot X**       |          a           |          b          |
| **Freq. autres mots** |          c           |          d          |

Tests possibles :\
- $\chi^2$ : intuitif mais sensible aux faibles effectifs.\
- **Log-Likelihood** $G^2$ : plus robuste, devenu la r√©f√©rence (ex. *AntConc*, `quanteda`).
:::
::::
::::::

## Analyse de "Keyness" (mots-cl√©s) 2/3

::::: columns
::: {.column width="50%"}
### Pipeline m√©thodologique [@raoGenderBiasNews2021]

1.  **Collecte des articles** de presse canadienne (2018‚Äì2020)\
2.  **NER** : extraction des **noms et pr√©noms des personnes cit√©es**\
3.  **Coreference resolution** : associer les **citations** au bon locuteur\
4.  **Attribution du genre** :
    -   via une base interne de personnalit√©s publiques\
    -   **OU** (si non trouv√©) via une API (pr√©nom ou nom complet)\
:::

::: {.column width="50%"}
### Suite du pipeline

\

5.  **Classification des articles** :
    -   *Male corpus* = majorit√© d‚Äôhommes cit√©s\
    -   *Female corpus* = majorit√© de femmes cit√©es
6.  **Analyses linguistiques** :
    -   *Topic modelling* (LDA) ‚Üí th√®mes\
    -   **Keyness ‚Üí mots sur-repr√©sent√©s** dans chaque corpus\
    -   *Dependency bigrams* ‚Üí style de discours\
:::
:::::

## Analyse de "Keyness" (mots-cl√©s) 3/3 {style="font-size:0.75em"}

![](images/clipboard-2048161018.png){fig-align="center" width="80%"}

::::: columns
::: {.column width="50%"}
### Corpus masculin

-   Bigrams fr√©quents : *lead_give, run_allow, pass_complete, homer_hit‚Ä¶*\
-   Mots cl√©s : *touchdown, quarterback, Mariners‚Ä¶*\
-   Discours ‚Üí centr√© sur **le d√©roulement technique des matchs**.
:::

::: {.column width="50%"}
### Corpus f√©minin

-   Bigrams fr√©quents : *gold_win, medal_win, record_set, cup_win‚Ä¶*\
-   Mots cl√©s : *Rapinoe, Sinclair, FIFA, Wozniacki‚Ä¶*\
-   Discours ‚Üí centr√© sur **les victoires, les records et les sportives embl√©matiques**.
:::
:::::

üëâ Conclusion : la presse **d√©crit les hommes en action**, mais ne parle des femmes **que lorsqu‚Äôelles gagnent**.

------------------------------------------------------------------------

## Annotation morphosyntaxique (POS Tagging) {style="font-size:0.85em"}

L‚Äô√©tiquetage morphosyntaxique (POS Tagging) attribue √† chaque mot sa **cat√©gorie grammaticale** (DET, NOUN, VERB/AUX, ADJ, ADV, ‚Ä¶) et, selon les outils, des **traits morphologiques** (Genre, Nombre, Temps, etc.).

<u>Le</u>/[DET]{.bg style="--col: #325494"} <u>produit</u>/[NOUN]{.bg style="--col: #58DDB3"} <u>est</u>/[AUX]{.bg style="--col: #B10F2E"} <u>vraiment</u>/[ADV]{.bg style="--col: #999999"} <u>excellent</u>/[ADJ]{.bg style="--col: #F5C946"}

:::::: columns
::: {.column width="50%" style="font-size:0.8em"}
### √Ä quoi √ßa sert ?

- **Filtrer l‚Äôinformation** :
  - Extraire les **adjectifs** pour analyser les qualificatifs d‚Äôun produit.
  - Isoler les **noms propres** pour d√©tecter les entit√©s.
- **Pr√©parer le traitement** :
  - Indispensable pour une **lemmatisation** fiable (*port* ‚Üí *porter* vs *port*).
  - Utile pour la **stemmatisation** (*jouer*, *jouait*, *jouera* ‚Üí *jou*).
:::

:::: {.column width="50%"}
::: {.callout-note title="Le standard Universal Dependencies" style="font-size:0.9em"}
- **UPOS** : √©tiquettes universelles (DET, NOUN, VERB, **AUX**, ADJ, ADV, ‚Ä¶)  
- **XPOS** : √©tiquettes sp√©cifiques √† la langue (optionnel)  
- **FEATS** : traits (ex. Gender=Masc, Number=Sing, Tense=Pres, Mood=Ind)

Outils compatibles : **spaCy**, **Stanza/Trankit**, **UDPipe**.
:::
::::
::::::


## Analyse en d√©pendances syntaxiques (Dependency Parsing) 1/3

L‚Äô**analyse en d√©pendances syntaxiques** est une √©tape du traitement automatique du langage naturel (TALN) qui vise √† repr√©senter la structure d‚Äôune phrase √† partir des **relations de d√©pendance entre mots**.\
Elle est g√©n√©ralement formalis√©e sous forme de **graphes orient√©s** (souvent en arbres), o√π :

-   les **n≈ìuds** correspondent aux mots (*tokens*),\
-   les **arcs** repr√©sentent les relations syntaxiques (par ex. *nsubj* = sujet, *obj* = objet, *det* = d√©terminant).

------------------------------------------------------------------------

## Analyse en d√©pendances syntaxiques (Dependency Parsing) 2/3

Cette approche permet d‚Äôidentifier qui fait quoi dans une phrase et de mod√©liser des structures grammaticales complexes.\
Elle est largement utilis√©e dans des applications comme :

-   l‚Äô**extraction d‚Äôinformation** (entit√©s et relations),\
-   le **r√©sum√© automatique** et la **recherche d‚Äôinformation**,\
-   l‚Äô**analyse des discours** sur les r√©seaux sociaux.

Un cadre de r√©f√©rence majeur pour cette t√¢che est le projet [**Universal Dependencies**](https://universaldependencies.org), qui propose des annotations coh√©rentes pour de nombreuses langues.

------------------------------------------------------------------------

## Analyse en d√©pendances syntaxiques (Dependency Parsing) 3/3

![](images/clipboard-2484643215.png)

------------------------------------------------------------------------

## Exemple code (mod√®le anglais)

[**Voir l‚Äôexemple de code ici**](https://oliviercaron.github.io/systematic_lit_review/annotations.html#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing)

[![Exemple de code udpipe](images/clipboard-3249784408.png)](https://oliviercaron.github.io/systematic_lit_review/annotations.html#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing)

------------------------------------------------------------------------

## Reconnaissance d'Entit√©s Nomm√©es (NER)

:::::: columns
::: {.column width="55%" style="font-size:0.75em"}
### Identifier le "de qui / de quoi"

La **NER (Named Entity Recognition)** d√©tecte et classe automatiquement les **entit√©s du monde r√©el** mentionn√©es dans un texte.

\
\

-   [PER]{.bg style="--col: #325494"} : Personnes\
-   [ORG]{.bg style="--col: #58DDB3"} : Organisations (marques, entreprises)\
-   [LOC]{.bg style="--col: #F5C946"} : Lieux (villes, pays)\
-   [DATE]{.bg style="--col: #B10F2E"} : Dates, heures\
-   [MISC]{.bg style="--col: #8A2BE2"} : Divers (produits, √©v√©nements...) voir [GliNER](https://github.com/urchade/GLiNER) aux prochains cours

\
\
:::

:::: {.column width="45%"}
::: {.callout-tip title="Applications en netnographie"}
Quelques id√©es :

-   **Veille concurrentielle** : lister automatiquement les marques concurrentes (ORG) cit√©es.
-   **D√©tection d'influenceurs** : rep√©rer les personnes (PER) qui animent les conversations.
-   **Analyse g√©o-localis√©e** : identifier les lieux (LOC) o√π se concentrent les discussions.
-   **Tracking produits** : rep√©rer les r√©f√©rences sp√©cifiques (MISC) dans les conversations.
:::
::::

<u>[Jean Dupont]{.bg style="--col: #325494"}</u> travaille chez <u>[Google]{.bg style="--col: #58DDB3"}</u> √† <u>[Paris]{.bg style="--col: #F5C946"}</u> depuis <u>[2023]{.bg style="--col: #B10F2E"}</u>.
::::::

------------------------------------------------------------------------

## Gestion des variations : fuzzy matching

:::::: columns
::: {.column width="55%"}
### G√©rer le "bruit" textuel

Les textes web sont pleins de **variations** : fautes de frappe, accents manquants, abr√©viations.

-   Le **fuzzy matching** (correspondance approximative) regroupe des cha√Ænes de caract√®res similaires.
-   La **Distance de Levenshtein** (ou distance d'√©dition) est la m√©thode la plus connue.
    -   Elle calcule le **nombre minimal d'op√©rations** (insertion, suppression, substitution) pour passer d'un mot √† un autre.
:::

:::: {.column width="45%"}
::: {.callout-important title="Exemple concret" style="font-size:0.8em"}
Comment regrouper les mentions d'une marque ?

-   `"Decathlon"`
-   `"D√©cathlon"`
-   `"decathalon"`
-   `"d√©cahlon"`

```{r}
library(stringdist)

s1 <- "D√©cathlon"
s2 <- "decathalon"

distance <- stringdist(s1, s2, method = "lv")
cat("Distance de Levenshtein entre", s1, "et", s2, "=", distance)

```

La distance de Levenshtein entre `"D√©cathlon"` et `"decathalon"` est de **3** (D‚Üíd, √©‚Üíe, + insertion de "a").

En fixant un seuil de distance faible (ex: ‚â§ 2), on peut automatiquement consid√©rer que ces variantes d√©signent la **m√™me entit√©**. C'est essentiel pour fiabiliser les comptages.
:::
::::
::::::

## Conclusion

-   Le **texte** est devenu une mati√®re premi√®re massive.\
-   Le NLP/TAL permet :
    -   De nouveaux terrains (avis, r√©seaux sociaux, forums).\
    -   De nouvelles m√©thodes (analyse lexicale, syntaxique, s√©mantique, pragmatique).\
    -   De nouveaux objets (discours de marque, avis, interactions).

::: callout-tip
### Langage
üëâ Pour le marketing digital et la netnographie : comprendre que **le langage est √† la fois structure, sens et action**.
:::

## R√©f√©rences