---
title: "√âtudes qualitatives sur le web (netnographie)"
subtitle: "Introduction au NLP/TALN - Traitement des donn√©es textuelles"
author:
  - name: "Olivier Caron"
    affiliations: "Paris Dauphine - PSL"
format:
  ubd-revealjs:
    self-contained: false
    chalkboard: true
    transition: fade
    auto-stretch: false
    width: 1250
    height: 760
    toc: false
    toc-depth: 1
    code-block-height: 700px
execute:
  echo: true
bibliography: refs.bib
revealjs-plugins:
  - editable
filters:
  - editable
---

## R√©volution du texte : production & lecture

-   Explosion de la **production textuelle** (posts, avis, tweets, articles scientifiques).\
-   Cons√©quence : **impossible de tout lire** ‚Üí besoin d‚Äôautomatisation.\
-   **R√©volution de la lecture** : moteurs de recherche, curation, algorithmes de recommandation.

::: callout-note
üëâ En marketing digital : les consommateurs produisent massivement du texte (avis, posts, hashtags).
:::

# Fondements th√©oriques du langage pour la netnographie {.transition-slide-ubdblue}

## Deux perspectives qui se compl√®tent

:::: {.columns}
::: {.column width="50%"}
### Perspective **structuraliste**
La langue comme **syst√®me** (cat√©gories, oppositions, r√®gles).  
Finalit√© : d√©crire l‚Äô**architecture** qui stabilise les usages.
:::

::: {.column width="50%"}
### Perspective **pragmatique / usage**
Le langage comme **activit√©** situ√©e et sociale.  
Finalit√© : comprendre **ce que fait** un message et comment il circule.
:::
::::

::: callout-note
Ces perspectives s‚Äôarticulent : la **structure** rend les √©nonc√©s intelligibles ; l‚Äô**usage** leur donne port√©e et effets.
:::

------------------------------------------------------------------------

## Saussure : syst√®me de signes et niveaux d‚Äôanalyse

:::: {.columns}
::: {.column width="58%"}
-   **Langage** : capacit√© humaine de signifier.\
-   **Langue** : **code partag√©** (unit√©s, oppositions, r√®gles).\
-   **Parole** : r√©alisation **situ√©e** de la langue (style, variations).\
-   **Texte** : mat√©rialisation de la parole (post, avis, thread).

**Cons√©quence** : distinguer conventions **collectives** (formats, hashtags, routines) et innovations **singuli√®res** (m√®mes, d√©tournements).
:::

:::: {.column width="42%"}
::: callout-tip
**Notions cl√©s**

-   La **valeur** d‚Äôun signe d√©pend des **diff√©rences** avec les autres signes.\
-   Le **syst√®me** donne un cadre ; l‚Äô**usage** l‚Äôactualise et l‚Äôinfl√©chit.
:::
::::
::::::

------------------------------------------------------------------------

## Chomsky & Tesni√®re : structure, d√©pendances, g√©n√©rativit√©

:::::: columns
::: {.column width="57%" style="font-size:0.75em"}
\

-   **Grammaire g√©n√©rative** : un ensemble **fini de r√®gles** ‚Üí une infinit√© d‚Äô√©nonc√©s.\
-   **Comp√©tence** (connaissance implicite) vs **performance** (usage effectif).\
-   **Arbres** (constituants/d√©pendances) : qui gouverne qui ? quelle **port√©e** pour la n√©gation, les modaux, les intensifs ?

### Apport interpr√©tatif

\
La structure **module** le sens :

-   ‚Äúpas **vraiment** satisfaisant‚Äù ‚â† ‚Äú**vraiment** pas satisfaisant‚Äù.\
-   Les relations syntaxiques r√©v√®lent **cibles** (produit, marque, service) et **attributs** (prix, qualit√©, d√©lai).
:::

:::: {.column width="43%"}
::: callout-note
**Indicateurs r√©currents**

-   N√©gation\
-   Modalit√© (‚Äúil faudrait‚Äù, ‚Äúon doit‚Äù)\
-   Intensit√© (‚Äútr√®s‚Äù, ‚Äútrop‚Äù, ‚Äúvraiment‚Äù)\
-   Comparaison (‚Äúplus/moins que‚Äù)
:::
::::
::::::

------------------------------------------------------------------------

## Jakobson : fonctions du langage et formats de message

Les messages combinent des **fonctions** avec des dominantes variables :

1.  **R√©f√©rentielle** ‚Äî informer sur le monde (faits, caract√©ristiques).\
2.  **Expressive** ‚Äî manifester une attitude ou une √©motion.\
3.  **Conative** ‚Äî orienter le destinataire (inciter, solliciter).\
4.  **Phatique** ‚Äî ouvrir/entretenir le canal d‚Äô√©change.\
5.  **M√©talinguistique** ‚Äî expliciter le code (d√©finitions, balises).\
6.  **Po√©tique** ‚Äî valoriser la forme (style, rime, m√®me, slogan).

Les **genres** (unboxing, SAV, teasing, t√©moignage) stabilisent des combinaisons de fonctions.

------------------------------------------------------------------------

## Austin : le langage comme action

> ‚ÄúDire, c‚Äôest **faire**.‚Äù

:::::: columns
::: {.column width="58%"}
-   **Locutoire** : forme et contenu litt√©ral.\
-   **Illocutoire** : **acte** r√©alis√© (remercier, promettre, bl√¢mer, recommander, alerter‚Ä¶).\
-   **Perlocutoire** : **effet** produit (convaincre, mobiliser, dissuader, apaiser‚Ä¶).

Un √©nonc√© **√©value** et **agit** : il oriente l‚Äô√©change, peut enclencher des r√©ponses, amplifier ou clore une discussion.
:::

:::: {.column width="42%"}
::: callout-important
**Indices**

-   Verbes et formules illocutoires (‚Äúje recommande / d√©conseille‚Äù)\
-   Traces perlocutoires (r√©ponses, relais, reconfigurations du fil)
:::
::::
::::::

------------------------------------------------------------------------

## Firth & Harris : le sens par les contextes

> ‚ÄúYou shall know a word by the **company** it keeps.‚Äù ‚Äî *J. R. Firth*

:::::: columns
::: {.column width="57%"}
-   **Hypoth√®se distributionnelle** : des mots partageant des **contextes** pr√©sentent des **proximit√©s de sens**.\
-   Le **voisinage** (cooccurrences, fen√™tres, d√©pendances) caract√©rise les **associations** : par exemple *qualit√©* ‚Üî *premium*, *prix* ‚Üî *juste* / *trop*.

**Cons√©quence** : le sens **relationnel** se lit dans les **profils de contexte** (collocations, patrons d‚Äôusage, r√©gularit√©s de voisinage).
:::

:::: {.column width="43%"}
::: callout-note
**Pratiques d‚Äôobservation**

-   Rep√©rer cooccurrences fortes\
-   Identifier collocations (‚Äúservice client‚Äù, ‚Äútrop + adjectif‚Äù)\
-   Suivre les patrons relationnels stables
:::
::::
::::::

------------------------------------------------------------------------

## Zipf : fr√©quences, longue tra√Æne et visibilit√©

:::::: columns
::: {.column width="58%"}
-   **Loi de Zipf** : quelques formes **tr√®s fr√©quentes**, une **longue tra√Æne** de rares.\
-   **Effets** :
    -   Les unit√©s **structurelles** dominent la volum√©trie (colle du discours).\
    -   Les √©l√©ments **distinctifs** se situent souvent en **fr√©quence moyenne**.\
    -   Les **signaux faibles** (rares) portent innovations et codes internes.

La fr√©quence informe moins sur l‚Äô‚Äúimportance‚Äù que sur le **r√¥le** (structurel, distinctif, √©mergent).
:::

:::: {.column width="42%"}
::: callout-tip
**Question directrice**\
Que dit la **position fr√©quentielle** d‚Äôune forme sur sa fonction discursive et sa place dans le r√©pertoire d‚Äôune communaut√© ?
:::
::::
::::::

------------------------------------------------------------------------

## Genette : textes en r√©seau (transtextualit√©)

:::::: columns
::: {.column width="60%"}
-   **Intertextualit√©** : citations, allusions, r√©emplois (hashtags, duos, stitches).\
-   **Paratexte** : titraille, visuels, √©mojis, alt-text, l√©gendes, tags.\
-   **M√©tatexte** : commentaires et critiques d‚Äôautres textes.\
-   **Hypertexte** : transformations/variations (parodie, remix, d√©tournement).\
-   **Architexte** : appartenance √† un **genre** (unboxing, SAV, t√©moignage, teasing).

Un message s‚Äô**inscrit** dans des **cha√Ænes** : r√©f√©rences et paratexte orientent sa lecture et sa circulation.
:::

:::: {.column width="40%"}
::: callout-note
**Indices de r√©seau**

-   Mentions, citations, formats de reprise\
-   R√¥le du layout et des m√©tadonn√©es dans l‚Äôorientation interpr√©tative
:::
::::
::::::

# Sch√©ma int√©gr√© d‚Äôinterpr√©tation {.transition-slide-ubdteal}

## De la forme √† l‚Äôeffet : grille de lecture unifi√©e

:::::: columns
::: {.column width="62%"}
1.  **Structure** *(Saussure, Chomsky)* : cat√©gories, d√©pendances, port√©e (n√©gation, modalit√©s, intensit√©).\
2.  **Fonctions** *(Jakobson)* : dominante communicative et format.\
3.  **Contexte lexical** *(Firth, Harris)* : cooccurrences, collocations, patrons relationnels.\
4.  **Distribution** *(Zipf)* : fr√©quences, longue tra√Æne, signaux faibles / distinctifs.\
5.  **Actes & effets** *(Austin)* : nature de l‚Äôacte et traces perlocutoires dans l‚Äô√©change.\
6.  **R√©seaux de textes** *(Genette)* : r√©f√©rences, paratexte, genres, trajectoires.
:::

:::: {.column width="38%"}
::: callout-important
Finalit√© : produire une interpr√©tation **coh√©rente** d‚Äôun corpus en articulant r√®gles, usages, relations s√©mantiques, actes et inscriptions intertextuelles.
:::
::::
::::::

------------------------------------------------------------------------

## Typologie crois√©e (rep√®res d‚Äôannotation) {.smaller}
\

| Dimension | Indices typiques | Lecture |
|------------------------|------------------------|------------------------|
| **Structure** | n√©gation, modalit√©, intensif, d√©pendances | port√©e de l‚Äô√©valuation ; cible/attribut |
| **Fonctions** | items expressifs/conatifs/po√©tiques | r√¥le communicatif dominant |
| **Contexte** | cooccurrences, collocations | associations et oppositions s√©mantiques |
| **Distribution** | fr√©quences / raret√©s | structurel vs distinctif ; √©mergent vs routinier |
| **Actes / effets** | verbes illocutoires, traces perlocutoires | recommandation, alerte, mobilisation‚Ä¶ |
| **R√©seaux** | citations, hashtags, formats | ancrage intertextuel ; architexte mobilis√© |

------------------------------------------------------------------------

## √âtudes guid√©es (exemples)

::: incremental
-   ‚ÄúService impeccable, livraison rapide. Je recommande.‚Äù\
    **Fonctions** : expressive + conative ; **Acte** : recommandation ; **Structure** : cibles *service/logistique* ; **R√©seau** : format *avis court*.
-   ‚ÄúTrop cher pour la qualit√© propos√©e.‚Äù\
    **Structure** : intensification + comparaison implicite ; **Contexte** : collocation ‚Äútrop cher‚Äù ; **Acte** : dissuasion ; **Distribution** : expression fr√©quente ou niche selon la communaut√©.
-   ‚Äú#NewDrop demain. Qui est chaud ? üëÄ‚Äù\
    **Fonctions** : phatique + conative + po√©tique ; **Acte** : mobilisation ; **Paratexte** : hashtag, √©mojis ; **Architexte** : teasing de lancement.
:::

------------------------------------------------------------------------

## Limites et pr√©cautions d‚Äôinterpr√©tation

-   **Ironie / sarcasme / polyphonie** : contrastes forme‚Äìcontenu, indices paratextuels.\
-   **Genres hybrides** : brouillage des fonctions selon le format.\
-   **Dynamiques communautaires** : normes mouvantes, cycles d‚Äôattention.\
-   **Biais d‚Äôobservation** : moments chauds, invisibilit√©s (lurkers).\
-   **√âthique** : respect des espaces, consentements, anonymisation.

# De la th√©orie‚Ä¶ √† la m√©thodologie {.transition-slide-ubdyellow}

## Roadmap Humphreys & Wang (2018) 1/2

### √âtapes
::: {.incremental}
- **1. Research question** ‚Äî formuler une question adapt√©e √† l‚Äôanalyse textuelle
- **2. Construct identification** ‚Äî identifier les construits (√©motion, influence, statut, etc.)
- **3. Data collection** ‚Äî collecter les corpus (posts, avis, threads)
- **4. Operationalization** ‚Äî transformer les construits en indicateurs (dictionnaires, mod√®les)
- **5. Interpretation & analysis** ‚Äî relier r√©sultats et th√©orie (comparaison, corr√©lation, pr√©diction)
- **6. Validation** ‚Äî v√©rifier robustesse (multi-op√©rationnalisation, triangulation, hold-out sample)
:::

## Roadmap Humphreys & Wang (2018) 2/2

![](images/clipboard-1874408983.png){fig-align="center" width="100%"} {.fragment}


------------------------------------------------------------------------

## Apports principaux de la d√©marche

-   **D√©couverte** : r√©v√©ler des r√©gularit√©s invisibles √† l‚Äô≈ìil humain\
-   **Pr√©cision** : mesurer avec impartialit√© √† grande √©chelle\
-   **Validit√© √©cologique** : analyser des discours en contexte naturel\
-   **Multi-niveaux** : individus, dyades, groupes, cultures\
-   **Guidelines m√©thodologiques** : dictionnaires, √©chantillonnage, validation, analyse de donn√©es textuelles clairsem√©es

------------------------------------------------------------------------

## Points d‚Äôancrage

-   **Structuraliste** : la langue comme **syst√®me** (formes, oppositions, d√©pendances).\
-   **Pragmatique / usage** : le message comme **action** situ√©e (fonctions, actes, effets).\
-   **Distribution / contexte** : le sens comme **relation** (voisinages, collocations, patrons).\
-   **R√©seaux de textes** : la signification comme **inscription** sociale (intertextes, paratextes, genres).

**Cha√Æne d‚Äôanalyse** : **Structure ‚Üí Fonction ‚Üí Contexte ‚Üí Distribution ‚Üí Acte ‚Üí R√©seau**.


# De la th√©orie‚Ä¶ √† la pratique {.transition-slide-ubdyellow}

## Pr√©-traitement du corpus

\

### Pourquoi nettoyer les donn√©es textuelles ?

-   Les textes bruts (avis, tweets, posts) contiennent du **bruit** : ponctuation, chiffres, emojis, urls‚Ä¶\
-   Le nettoyage am√©liore la qualit√© des analyses (fr√©quences, co-occurrences, mod√®les).\
-   **Objectif** : obtenir un corpus standardis√©, coh√©rent et exploitable.

------------------------------------------------------------------------

## Pr√©-traitement : op√©rations courantes

-   Passage en **minuscules**\
-   Suppression de la **ponctuation / chiffres / urls**\
-   Suppression des **stopwords** (*mots vides* : le, la, de, un‚Ä¶)\
-   **Stemming** : r√©duire les mots √† leur racine (*ex. aimer, aimait ‚Üí aim*)\
-   **Lemmatisation** : r√©duire les mots √† leur forme canonique (*aimait ‚Üí aimer*)

::: callout-note
üëâ Ces √©tapes peuvent √™tre adapt√©es selon la recherche : ne pas trop nettoyer au risque de perdre du sens ou des informations.
:::

------------------------------------------------------------------------

## Repr√©sentation : "Bag-of-Words"

:::::: columns
::: {.column width="30%" style="font-size:1em"}
### Le principe

-   Une fois le texte nettoy√©, il faut le transformer en chiffres pour que la machine puisse le traiter.
-   Le mod√®le **"sac de mots" (BoW)** est la m√©thode la plus simple :
    -   On repr√©sente un document uniquement par les mots qu'il contient.
    -   L'**ordre des mots** et la grammaire sont volontairement **ignor√©s**.
-   Cette approche permet de cr√©er une **Matrice Document-Terme (DTM)**.
:::

:::: {.column width="70%" style="font-size:0.55em"}
::: {.callout-note title="Exemple de DTM"}
**Corpus :**

-   D1: "Produit **excellent et** pas cher"
-   D2: "Produit **m√©diocre et** tr√®s cher"
-   D3: "Produit **excellent et** vraiment pas cher"
-   D4: "Produit **m√©diocre et** assez cher"

**Matrice (DTM) :**

|        | produit | excellent | m√©diocre | cher | pas | tr√®s | vraiment | assez |
|:-------|:-------:|:---------:|:--------:|:----:|:---:|:----:|:--------:|:-----:|
| **D1** |    1    |     1     |    0     |  1   |  1  |  0   |    0     |   0   |
| **D2** |    1    |     0     |    1     |  1   |  0  |  1   |    0     |   0   |
| **D3** |    1    |     1     |    0     |  1   |  1  |  0   |    1     |   0   |
| **D4** |    1    |     0     |    1     |  1   |  0  |  0   |    0     |   1   |

Chaque ligne est un **vecteur** qui repr√©sente un document.
:::
::::
::::::

------------------------------------------------------------------------

## Pond√©ration des termes : TF-IDF

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### L'intuition

La fr√©quence brute (compter les mots) est limit√©e. Le **TF-IDF** est une pond√©ration plus intelligente qui vise √† faire ressortir les mots **sp√©cifiques** d'un document.

-   **TF (Term Frequency)** : poids d'un mot dans **un** document. Un mot fr√©quent est important *pour ce document*.
-   **IDF (Inverse Document Frequency)** : poids d'un mot dans **tout** le corpus. Un mot pr√©sent partout (ex: "le", "produit") est peu informatif, donc son poids est faible.

Un **TF-IDF √©lev√©** signale un mot-cl√© caract√©ristique.
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: {.callout-note title="Les formules"}
Pour un terme $t$ dans un document $d$ au sein d'un corpus $D$ :

-   **Fr√©quence du terme (TF)** : $TF(t,d) = \frac{\text{nombre de fois o√π } t \text{ appara√Æt dans } d}{\text{nombre total de mots dans } d}$

-   **Fr√©quence inverse de document (IDF)** : $IDF(t,D) = \log\left(\frac{\text{nombre total de documents}}{\text{nombre de documents contenant } t}\right)$

-   **Score TF-IDF** : $TFIDF(t,d,D) = TF(t,d) \times IDF(t,D)$
:::
::::
::::::

------------------------------------------------------------------------

## Statistiques lexicales exploratoires

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### "Sentir" le corpus

Avant toute analyse complexe, des indicateurs simples permettent de comprendre la nature des donn√©es :

-   **Fr√©quences de mots** :
    -   Quels sont les termes les plus utilis√©s (hors *stopwords*) -\> donne une id√©e des th√®mes dominants.
    -   Visualisation : **nuage de mots**.
-   **Hapax Legomena** :
    -   Mots n'apparaissant qu'**une seule fois** dans tout le corpus.
    -   Souvent 30-50% du vocabulaire (selon taille corpus). Ils peuvent √™tre du bruit (fautes de frappe) ou des signaux faibles (jargon √©mergent).
:::

:::: {.column width="50%" style="font-size:0.75em"}
### Richesse du vocabulaire (TTR, CTTR, MATTR, Maas...)

\

-   **Diversit√© lexicale (TTR)** :
    -   Mesure la richesse du vocabulaire utilis√© dans un texte.
    -   Le *Type-Token Ratio* est le calcul le plus simple.

::: {.callout-note title="Formule du TTR"}
$$ TTR = \frac{\text{Nombre de mots uniques (types)}}{\text{Nombre total de mots (tokens)}} $$ Un TTR proche de 1 indique un vocabulaire tr√®s vari√© ; un TTR faible un langage r√©p√©titif.
:::
::::
::::::

------------------------------------------------------------------------

## Approfondir la diversit√© lexicale

:::::: columns
::: {.column width="55%" style="font-size:0.85em"}
### Au-del√† du TTR

Le **Type-Token Ratio (TTR)** est un bon d√©but, mais faiblesse majeure -\> tr√®s sensible √† la longueur du texte. Un texte plus long aura m√©caniquement un TTR plus faible car on est forc√© de r√©p√©ter des mots.

\
¬†

### Mesures plus robustes

\
\

Pour comparer des textes de longueurs diff√©rentes, on utilise des indicateurs plus avanc√©s comme le **MTLD** (Measure of Textual Lexical Diversity).

-   **Principe** : L'algorithme calcule le TTR moyen sur des segments cons√©cutifs du texte, ce qui le rend ind√©pendant de la longueur totale.
:::

:::: {.column width="45%"}
::: {.callout-tip title="Applications en Netnographie" style="font-size:0.9em"}
Analyser la diversit√© lexicale permet de :

-   **Profiler des auteurs** : un vocabulaire pauvre et r√©p√©titif peut √™tre un indice de spams ou de faux avis g√©n√©r√©s automatiquement.
-   **Caract√©riser une communaut√©** : un jargon riche et vari√© est souvent le signe d'une communaut√© d'experts ou de passionn√©s.
-   **Segmenter des retours clients** : les commentaires tr√®s riches lexicalement peuvent contenir des insights plus d√©taill√©s que les commentaires laconiques.
:::
::::
::::::

------------------------------------------------------------------------

## Mesurer la lisibilit√© du texte (Readability)

La lisibilit√© mesure la **facilit√© de lecture et de compr√©hension** d'un texte. Elle ne d√©pend pas seulement de la richesse du vocabulaire, mais aussi de la complexit√© syntaxique.

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### Les deux piliers de la complexit√©

La plupart des scores de lisibilit√© se basent sur deux variables simples :

1.  **Complexit√© s√©mantique** : longueur des mots (en syllabes ou en caract√®res). Des mots longs sont consid√©r√©s comme plus difficiles.
2.  **Complexit√© syntaxique** : longueur des phrases (en nombre de mots). Des phrases longues sont plus complexes √† analyser pour le lecteur.

Le score le plus c√©l√®bre en anglais est le **Flesch-Kincaid Reading Ease**.
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: {.callout-note title="Scores & Applications" style="font-size:0.75em"}
### Formule g√©n√©rale

La plupart des scores suivent une logique de ce type : $Score = A - (B \times \frac{\text{mots}}{\text{phrase}}) - (C \times \frac{\text{syllabes}}{\text{mot}})$

### Utilit√© en marketing

-   **Auditer le contenu de marque** : le langage utilis√© sur un site web ou les r√©seaux sociaux est-il adapt√© √† la cible ? Est-il trop simple ? Trop jargonnant ?
-   **Analyser l'audience** : le niveau de langage des consommateurs dans leurs avis peut-il r√©v√©ler leur niveau d'expertise ?
:::
::::
::::::

------------------------------------------------------------------------

## Lisibilit√© en fran√ßais : les outils sp√©cifiques

::::::: columns
:::: {.column width="55%" style="font-size:0.85em"}
### Kandel & Moles : l'adaptation de Flesch

C'est la formule historique (1958) et la plus directe pour le fran√ßais. Le principe est le m√™me que pour l'anglais : combiner la longueur des mots et des phrases.

-   **Score de 0 √† 100** :
    -   **Score √©lev√© (\> 70)** : texte facile √† lire.
    -   **Score bas (\< 40)** : texte difficile (technique, acad√©mique).

::: {.callout-note title="La formule pour le fran√ßais" style="font-size:0.60em"}
Le score est calcul√© ainsi :

$Score = 207 - (1.015 \times \text{longueur moyenne des phrases})$ $- (73.6 \times \text{nombre moyen de syllabes par mot})$
:::
::::

:::: {.column width="45%" style="font-size:0.70em"}
### Alternative et pratique moderne

-   **Indice de Gunning Fog** :
    -   Une autre approche qui se base sur le pourcentage de **"mots complexes"** (g√©n√©ralement 3 syllabes ou plus).
    -   Le score estime le **nombre d'ann√©es d'√©tudes** n√©cessaires pour comprendre le texte.
-   **Outils NLP actuels** :
    -   Aujourd'hui, on utilise des biblioth√®ques Python pour faire ces calculs.
    -   **`pyphen`** : pour compter les syllabes en fran√ßais.
    -   **`textstat`** : pour calculer directement les scores de lisibilit√©.\
    -   En **R** : les packages comme `quanteda` ou `koRpus` offrent aussi ces fonctionnalit√©s.

::: {.callout-tip title="A retenir" style="font-size:1em"}
Le principe reste le m√™me : un texte simple = mots courts + phrases courtes. Les formules pour le fran√ßais ne font que calibrer cette id√©e aux particularit√©s statistiques de notre langue.
:::
::::
:::::::

------------------------------------------------------------------------

## Analyse de co-occurrences et collocations

:::::: columns
::: {.column width="55%"}
### Le sens par l'association

On d√©passe le "sac de mots" pour analyser **quels mots apparaissent ensemble**.

-   **Co-occurrence** : deux mots qui apparaissent fr√©quemment dans un m√™me contexte (ex: phrase, fen√™tre de 5 mots).
    -   Permet de cr√©er des **graphes de mots** pour visualiser les clusters th√©matiques.
-   **Collocation** : une co-occurrence si forte qu'elle forme une expression presque fig√©e.
    -   Ex: "service client", "rapport qualit√©-prix".
:::

:::: {.column width="45%"}
::: {.callout-important title="Mesurer la force d'association" style="font-size:0.9em"}
On peut quantifier si une co-occurrence est due au hasard ou √† un lien s√©mantique fort. Le **Pointwise Mutual Information (PMI)** est une mesure courante.

$PMI(x,y) = \log_2\left(\frac{P(x,y)}{P(x)P(y)}\right)$

-   $P(x,y)$ : probabilit√© de voir x et y ensemble.
-   $P(x)P(y)$ : probabilit√© de les voir ensemble si leur apparition √©tait ind√©pendante.

Un PMI √©lev√© sugg√®re un lien s√©mantique fort.
:::
::::
::::::

------------------------------------------------------------------------

## Analyse de "Keyness" (mots-cl√©s)

:::::: columns
::: {.column width="60%"}
### Qu'est-ce qui diff√©rencie deux discours ?

-   La **Keyness** identifie les mots **statistiquement sur-repr√©sent√©s** dans un corpus A par rapport √† un corpus de r√©f√©rence B.
-   C'est une m√©thode puissante pour **caract√©riser et comparer** des ensembles de textes.
-   **Applications** :
    -   Avis 5‚òÖ vs 1‚òÖ : Quels mots sont "cl√©s" pour les clients satisfaits ?
    -   Tweets avant vs apr√®s une crise : quel vocabulaire a √©merg√© ?
:::

:::: {.column width="40%"}
::: {.callout-note title="Principe statistique" style="font-size:0.7em"}
Pour chaque mot, on construit un tableau de contingence :

|                       | **Corpus A (cible)** | **Corpus B (r√©f.)** |
|:----------------------|:--------------------:|:-------------------:|
| **Freq. mot X**       |          a           |          b          |
| **Freq. autres mots** |          c           |          d          |

Tests possibles :\
- $\chi^2$ : intuitif mais sensible aux faibles effectifs.\
- **Log-Likelihood** $G^2$ : plus robuste, devenu la r√©f√©rence (ex. *AntConc*, `quanteda`).
:::
::::
::::::

------------------------------------------------------------------------

## Annotation morphosyntaxique (POS Tagging)

L'√©tiquetage morphosyntaxique (POS Tagging) attribue √† chaque mot sa **cat√©gorie grammaticale** (nom, verbe, adjectif, adverbe, etc.).

<u>Le</u>/[DET]{.bg style="--col: #325494"} <u>produit</u>/[NOM]{.bg style="--col: #58DDB3"} <u>est</u>/[VERBE]{.bg style="--col: #B10F2E"} <u>vraiment</u>/[ADV]{.bg style="--col: #999999"} <u>excellent</u>/[ADJ]{.bg style="--col: #F5C946"}

:::::: columns
::: {.column width="50%" style="font-size:0.8em"}
### √Ä quoi √ßa sert ?

-   **Filtrer l'information** :
    -   Extraire les **adjectifs** pour analyser les qualificatifs d'un produit.
    -   Isoler les **noms propres** pour d√©tecter les entit√©s.
-   **Pr√©parer le traitement** :
    -   Indispensable pour une bonne **lemmatisation** (ex: "port" ‚Üí *porter* vs *port*).
    -   Utile aussi pour la **stemmatisation** (ex: "jouer", "jouait", "jouera" ‚Üí *jou*).
:::

:::: {.column width="50%"}
::: {.callout-note title="Le standard Universal Dependencies" style="font-size:0.9em"}
Le projet **Universal Dependencies (UD)** propose un jeu d'√©tiquettes unifi√© (17 cat√©gories principales) pour de nombreuses langues. Cela facilite l'utilisation d'outils multilingues comme spaCy ou UDPipe.
:::
::::
::::::

## Analyse en d√©pendances syntaxiques (Dependency Parsing) 1/3

L‚Äô**analyse en d√©pendances syntaxiques** est une √©tape du traitement automatique du langage naturel (TALN) qui vise √† repr√©senter la structure d‚Äôune phrase √† partir des **relations de d√©pendance entre mots**.\
Elle est g√©n√©ralement formalis√©e sous forme de **graphes orient√©s** (souvent en arbres), o√π :

-   les **n≈ìuds** correspondent aux mots (*tokens*),\
-   les **arcs** repr√©sentent les relations syntaxiques (par ex. *nsubj* = sujet, *obj* = objet, *det* = d√©terminant).

------------------------------------------------------------------------

## Analyse en d√©pendances syntaxiques (Dependency Parsing) 2/3

Cette approche permet d‚Äôidentifier qui fait quoi dans une phrase et de mod√©liser des structures grammaticales complexes.\
Elle est largement utilis√©e dans des applications comme :

-   l‚Äô**extraction d‚Äôinformation** (entit√©s et relations),\
-   le **r√©sum√© automatique** et la **recherche d‚Äôinformation**,\
-   l‚Äô**analyse des discours** sur les r√©seaux sociaux.

Un cadre de r√©f√©rence majeur pour cette t√¢che est le projet [**Universal Dependencies**](https://universaldependencies.org), qui propose des annotations coh√©rentes pour de nombreuses langues.

------------------------------------------------------------------------

## Analyse en d√©pendances syntaxiques (Dependency Parsing) 3/3

![](images/clipboard-2484643215.png)

------------------------------------------------------------------------

## Exemple code

[**Voir l‚Äôexemple de code ici**](https://oliviercaron.github.io/systematic_lit_review/annotations.html#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing)

[![Exemple de code udpipe](images/clipboard-3249784408.png)](https://oliviercaron.github.io/systematic_lit_review/annotations.html#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing)

------------------------------------------------------------------------

## Reconnaissance d'Entit√©s Nomm√©es (NER)

:::::: columns
::: {.column width="55%" style="font-size:0.75em"}
### Identifier le "de qui / de quoi"

La **NER (Named Entity Recognition)** d√©tecte et classe automatiquement les **entit√©s du monde r√©el** mentionn√©es dans un texte.

\
\

-   [PER]{.bg style="--col: #325494"} : Personnes\
-   [ORG]{.bg style="--col: #58DDB3"} : Organisations (marques, entreprises)\
-   [LOC]{.bg style="--col: #F5C946"} : Lieux (villes, pays)\
-   [DATE]{.bg style="--col: #B10F2E"} : Dates, heures\
-   [MISC]{.bg style="--col: #8A2BE2"} : Divers (produits, √©v√©nements...) voir [GliNER](https://github.com/urchade/GLiNER) aux prochains cours

\
\
:::

:::: {.column width="45%"}
::: {.callout-tip title="Applications en netnographie"}
Quelques id√©es :

-   **Veille concurrentielle** : lister automatiquement les marques concurrentes (ORG) cit√©es.
-   **D√©tection d'influenceurs** : rep√©rer les personnes (PER) qui animent les conversations.
-   **Analyse g√©o-localis√©e** : identifier les lieux (LOC) o√π se concentrent les discussions.
-   **Tracking produits** : rep√©rer les r√©f√©rences sp√©cifiques (MISC) dans les conversations.
:::
::::

<u>[Jean Dupont]{.bg style="--col: #325494"}</u> travaille chez <u>[Google]{.bg style="--col: #58DDB3"}</u> √† <u>[Paris]{.bg style="--col: #F5C946"}</u> depuis <u>[2023]{.bg style="--col: #B10F2E"}</u>.
::::::

------------------------------------------------------------------------

## Gestion des variations : fuzzy matching

:::::: columns
::: {.column width="55%"}
### G√©rer le "bruit" textuel

Les textes web sont pleins de **variations** : fautes de frappe, accents manquants, abr√©viations.

-   Le **fuzzy matching** (correspondance approximative) regroupe des cha√Ænes de caract√®res similaires.
-   La **Distance de Levenshtein** (ou distance d'√©dition) est la m√©thode la plus connue.
    -   Elle calcule le **nombre minimal d'op√©rations** (insertion, suppression, substitution) pour passer d'un mot √† un autre.
:::

:::: {.column width="45%"}
::: {.callout-important title="Exemple concret" style="font-size:0.8em"}
Comment regrouper les mentions d'une marque ?

-   `"Decathlon"`
-   `"D√©cathlon"`
-   `"decathalon"`
-   `"d√©cahlon"`

```{r}
library(stringdist)

s1 <- "D√©cathlon"
s2 <- "decathalon"

distance <- stringdist(s1, s2, method = "lv")
cat("Distance de Levenshtein entre", s1, "et", s2, "=", distance)

```

La distance de Levenshtein entre `"D√©cathlon"` et `"decathalon"` est de **3** (D‚Üíd, √©‚Üíe, + insertion de "a").

En fixant un seuil de distance faible (ex: ‚â§ 2), on peut automatiquement consid√©rer que ces variantes d√©signent la **m√™me entit√©**. C'est essentiel pour fiabiliser les comptages.
:::
::::
::::::

## Conclusion

-   Le **texte** est devenu une mati√®re premi√®re massive.\
-   Le NLP/TAL permet :
    -   De nouveaux terrains (avis, r√©seaux sociaux, forums).\
    -   De nouvelles m√©thodes (analyse lexicale, syntaxique, s√©mantique, pragmatique).\
    -   De nouveaux objets (discours de marque, avis, interactions).

::: callout-tip
üëâ Pour le marketing digital et la netnographie : comprendre que **le langage est √† la fois structure, sens et action**.
:::
