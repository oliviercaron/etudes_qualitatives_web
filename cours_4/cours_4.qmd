---
title: "Études qualitatives sur le web (netnographie)"
subtitle: "Introduction au NLP/TALN - Traitement des données textuelles"
author:
  - name: "Olivier Caron"
    affiliations: "Paris Dauphine - PSL"
format:
  ubd-revealjs:
    self-contained: false
    chalkboard: true
    transition: fade
    auto-stretch: false
    width: 1250
    height: 760
    toc: false
    toc-depth: 1
    code-block-height: 700px
execute:
  echo: true
bibliography: refs.bib
revealjs-plugins:
  - editable
filters:
  - editable
---

## Révolution du texte : production & lecture {style="font-size:0.9em"}

-   Explosion de la **production textuelle** (posts, avis, X/Twitter, TikTok, LinkedIn, articles scientifiques).
-   Conséquence : **impossible de tout lire** → besoin d’automatisation (indexation, filtrage, résumés).
-   **Révolution de la lecture** : moteurs de recherche, curation, algorithmes de recommandation.

::: callout-note
👉 En marketing digital : les consommateurs produisent massivement du texte (avis, posts, hashtags).\
- Exemple : des millions d’avis TripAdvisor / Google Reviews chaque jour.\
- Exemple réseaux sociaux : hashtags #AI, #TikTokMadeMeBuyIt, #Dropshipping qui se renouvellent en continu.\
- Exemple SEO : Google doit **sélectionner** des mots-clés pertinents → stratégie centrale en référencement.
:::

# Fondements théoriques du langage pour la netnographie {.transition-slide-ubdblue}

## Deux perspectives qui se complètent {style="font-size:0.9em"}

::::: columns
::: {.column width="50%"}
### Perspective **structuraliste**

La langue comme **système** (catégories, oppositions, règles).\
Finalité : décrire l’**architecture** qui stabilise les usages.

\

*Exemple : le hashtag **#MondayMotivation** comme convention collective sur X/LinkedIn qui structure les pratiques.*
:::

::: {.column width="50%"}
### Perspective **pragmatique / usage**

Le langage comme **activité** située et sociale.\
Finalité : comprendre **ce que fait** un message et comment il circule.

\
\

*Exemple : le détournement ironique **#MondayDespair** illustre l’usage créatif et viral sur TikTok.*
:::
:::::

\
\


::: callout-note
Ces perspectives s’articulent : la **structure** rend les énoncés intelligibles ; l’**usage** leur donne portée et effets.
:::

------------------------------------------------------------------------

## Saussure : système de signes et niveaux d’analyse {style="font-size:0.9em"}

:::::: columns
::: {.column width="58%"}
-   **Langage** : capacité humaine de signifier.\
-   **Langue** : **code partagé** (unités, oppositions, règles).\
-   **Parole** : réalisation **située** de la langue (style, variations).\
-   **Texte** : matérialisation de la parole (post, avis, thread).

**Conséquence** : distinguer conventions **collectives** (formats, hashtags, routines) et innovations **singulières** (mèmes, détournements).

*Exemple : la story Instagram = convention collective ; un remix TikTok ou un mème détournant une pub de luxe = innovation singulière.*
:::

:::: {.column width="42%"}

\
\

::: callout-tip
### Notions clés

- La **valeur** d’un signe dépend des **différences** avec les autres signes.\
- Le **système** donne un cadre ; l’**usage** l’actualise et l’infléchit.
:::
::::
::::::

------------------------------------------------------------------------

## Chomsky & Tesnière : structure, dépendances, générativité {style="font-size:1em"}

:::::: columns
::: {.column width="57%" style="font-size:0.75em"}

-   **Grammaire générative** : un ensemble **fini de règles** → une infinité d’énoncés.\
-   **Compétence** (connaissance implicite) vs **performance** (usage effectif).\
-   **Arbres** (constituants/dépendances) : qui gouverne qui ? quelle **portée** pour la négation, les modaux, les intensifs ?

### Apport interprétatif

La structure **module** le sens : 

- “pas **vraiment** satisfaisant” ≠ “**vraiment** pas satisfaisant”.\
- Les relations syntaxiques révèlent **cibles** (produit, marque, service) et **attributs** (prix, qualité, délai).

*Exemple SEO : “acheter iPhone 16 pas cher” ≠ “iPhone 16 pas cher acheter”. La syntaxe change la pertinence des résultats Google.*
:::

:::: {.column width="43%"}
::: callout-note
### Indicateurs récurrents
- Négation\
- Modalité (“il faudrait”, “on doit”)\
- Intensité (“très”, “trop”, “vraiment”)\
- Comparaison (“plus/moins que”)

*Exemple : un avis “Ce service est **trop lent**” → intensité négative claire détectable en NLP.*
:::
::::
::::::

------------------------------------------------------------------------

## Jakobson : fonctions du langage et formats de message {style="font-size:0.75em"}

::::: columns
::: {.column width="60%"}
Les messages combinent des **fonctions** avec des dominantes variables :

1. **Référentielle** — informer sur le monde (faits, caractéristiques).  
   - ex. “Ce téléphone a un écran 6,5 pouces.”
2. **Expressive** — manifester une attitude ou une émotion.  
   - ex. “J’adore ce parfum 😍”
3. **Conative** — orienter le destinataire (inciter, solliciter).  
   - ex. “Abonnez-vous maintenant !”
4. **Phatique** — ouvrir/entretenir le canal d’échange.  
   - ex. “Hello TikTok, qui est là ?”
5. **Métalinguistique** — expliciter le code (définitions, balises).  
   - ex. “RT = retweet”
6. **Poétique** — valoriser la forme (style, rime, mème, slogan).  
   - ex. “Just do it.” (ou slogan généré par IA)

Les **genres** (unboxing, SAV, teasing, témoignage) stabilisent des combinaisons de fonctions.
:::

::: {.column width="40%"}
::: callout-tip
### Exemple de campagne : **Nike**
- **Référentielle** : “Une seule façon de savoir.”  
- **Expressive** : émotion de l’athlète en pleine action.  
- **Poétique** : slogan **JUST DO IT.**  
- **Conative** : boutons “Équipe-toi” / “Regarder”.
:::

![](images/clipboard-2230655830.png){fig-align="center" width="100%"}
:::
:::::


------------------------------------------------------------------------

## Austin : le langage comme action {style="font-size:0.9em"}

> “Dire, c’est **faire**.”

:::::: columns
::: {.column width="58%"}
-   **Locutoire** : forme et contenu littéral.\
-   **Illocutoire** : **acte** réalisé (remercier, promettre, blâmer, recommander, alerter…).\
-   **Perlocutoire** : **effet** produit (convaincre, mobiliser, dissuader, apaiser…).

Un énoncé **évalue** et **agit** : il oriente l’échange, peut enclencher des réponses, amplifier ou clore une discussion.

*Exemple : un avis Google “Je recommande cette boutique” = acte illocutoire de recommandation.*
:::

:::: {.column width="42%"}
::: callout-important
### Indices
- Verbes et formules illocutoires (“je recommande / déconseille”)\
- Traces perlocutoires (réponses, relais, reconfigurations du fil)

*Exemple 2024 : un tweet “Boycottez Shein” = illocutoire ; la tendance **#BoycottShein** qui explose = perlocutoire.*
:::
::::
::::::

------------------------------------------------------------------------

## Firth & Harris : le sens par les contextes {style="font-size:0.9em"}

> “You shall know a word by the **company** it keeps.” — *J. R. Firth*

:::::: columns
::: {.column width="57%"}
-   **Hypothèse distributionnelle** : des mots partageant des **contextes** présentent des **proximités de sens**.\
-   Le **voisinage** (cooccurrences, fenêtres, dépendances) caractérise les **associations**.

**Conséquence** : le sens **relationnel** se lit dans les **profils de contexte** (collocations, patrons d’usage, régularités de voisinage).

*Exemple : Google apprend que “meilleur smartphone” ≈ “top téléphone” car ils apparaissent dans des contextes très proches.*
:::

:::: {.column width="43%"}
::: callout-note
### Pratiques d’observation
- Repérer cooccurrences fortes\
- Identifier collocations (“service client”, “trop + adjectif”)\
- Suivre les patrons relationnels stables

*Exemple : “premium” cooccurrent avec “qualité” → connotation positive ; “prix” cooccurrent avec “trop” → connotation négative.*
:::
::::
::::::

------------------------------------------------------------------------

## Zipf : fréquences, longue traîne et visibilité {style="font-size:0.9em"}

:::::: columns
::: {.column width="50%" style="font-size:0.90em"}
-   **Loi de Zipf** : quelques formes **très fréquentes**, une **longue traîne** de rares.\
-   **Effets** :
    -   Les unités **structurelles** dominent la volumétrie (**"colle" du discours**).
        -   ex. “the, and, of” ou “le, de, et”\
    -   Les éléments **distinctifs** se situent souvent en **fréquence moyenne**.
        -   ex. dans des tweets politiques 2024 : “réforme, climat, impôt”\
    -   Les **signaux faibles** (rares) portent innovations et codes internes.
        -   ex. hashtags ponctuels : *#AIart*, *#TikTokMadeMeBuyIt*, *#BackToSchool2025*

👉 La fréquence renseigne moins sur l’“importance” que sur le **rôle** (structurel, distinctif, émergent).
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: callout-tip
### Question directrice

Que dit la **position fréquentielle** d’une forme sur sa fonction discursive et sa place dans le répertoire d’une communauté ?\

- **Fréquent** = colle du langage (structural)\
- **Moyen** = propre au thème ou au groupe (distinctif)\
- **Rare** = émergent, innovation, code interne
:::

Exemple classique : loi de Zipf sur *Ulysses* de James Joyce.
![](images/clipboard-4009297054.png){fig-align="center" width="80%"}

::::
::::::

------------------------------------------------------------------------

## Genette : textes en réseau (transtextualité) {style="font-size:0.80em"}


:::::: columns
::: {.column width="60%"}


-   **Intertextualité** : citations, allusions, réemplois.
    -   ex. un TikTok reprend un son viral ou cite une punchline de rap.\
-   **Paratexte** : titraille, visuels, émojis, alt-text, légendes, tags.
    -   ex. la vignette YouTube “choc 😱” ou les #SEO dans un post LinkedIn.\
-   **Métatexte** : commentaires et critiques d’autres textes.
    -   ex. un thread X qui démonte une campagne publicitaire.\
-   **Hypertexte** : transformations/variations (parodie, remix, détournement).
    -   ex. détournement humoristique d’une pub Apple sur Insta.\
-   **Architexte** : appartenance à un **genre** (unboxing, SAV, témoignage, teasing).
    -   ex. le format “haul Shein” sur TikTok ou les “unboxing iPhone” chaque rentrée.

👉 Un message s’**inscrit** dans des **chaînes** : références et paratexte orientent sa lecture et sa circulation.
:::

:::: {.column width="40%"}

\
\
\


::: callout-note
### Indices de réseau

-   Mentions (\@, #), citations, formats de reprise (duos, stitches).\
-   Rôle du layout et des métadonnées dans l’orientation interprétative.

*Exemple : un duo TikTok qui répond à une vidéo originale, avec emojis + hashtag sponsorisé → la circulation du texte est déjà orientée par le format.*
:::
::::
::::::

## Récapitulatif application marketing {style="font-size:0.75em"}

| Théorie / outil | Exemple digital | Utilité marketing |
|------------------|------------------------------|-------------------------|
| Saussure (langue/parole) | Story IG (code) vs remix TikTok (innovation) | Adapter format & créativité au canal |
| Chomsky/Tesnière | Syntaxe requêtes SEO (“acheter… pas cher…”) | Pertinence SEO & compréhension requêtes |
| Jakobson (6 fonctions) | Campagne Nike multi-fonctions | Conception messages & CTA efficaces |
| Austin (actes de langage) | “#BoycottShein” (illo→perlo) | Gérer réputation & crises |
| Firth/Harris (contextes) | “premium” ↔ “qualité”, “prix” ↔ “trop” | Analyse de sentiment & positionnement |
| Zipf (fréquences) | Hashtags campagne : fréquent/moyen/rare | Social listening : bruit / thèmes / signaux |
| Genette (réseaux) | Duos/stitches, parodies, vignettes YouTube | Stratégies de diffusion & formats natifs |

------------------------------------------------------------------------

## Limites et précautions d’interprétation

-   **Ironie / sarcasme / polyphonie** : contrastes forme–contenu, indices paratextuels.\
-   **Genres hybrides** : brouillage des fonctions selon le format.\
-   **Dynamiques communautaires** : normes mouvantes, cycles d’attention.\
-   **Biais d’observation** : moments chauds, invisibilités (lurkers).\
-   **Éthique** : respect des espaces, consentements, anonymisation.

# De la théorie… à la méthodologie {.transition-slide-ubdyellow}

## Roadmap Humphreys & Wang (2018) 1/2 [@humphreys2018]

### Étapes

::: incremental
-   **1. Research question** — formuler une question adaptée à l’analyse textuelle
-   **2. Construct identification** — identifier les construits (émotion, influence, statut, etc.)
-   **3. Data collection** — collecter les corpus (posts, avis, threads)
-   **4. Operationalization** — transformer les construits en indicateurs (dictionnaires, modèles)
-   **5. Interpretation & analysis** — relier résultats et théorie (comparaison, corrélation, prédiction)
-   **6. Validation** — vérifier robustesse (multi-opérationnalisation, triangulation, hold-out sample)
:::

## Roadmap Humphreys & Wang (2018) 2/2

![](images/clipboard-1874408983.png){fig-align="center" width="100%"} {.fragment}

------------------------------------------------------------------------

## Apports principaux de la démarche

-   **Découverte** : révéler des régularités invisibles à l’œil humain\
-   **Précision** : mesurer avec impartialité à grande échelle\
-   **Validité écologique** : analyser des discours en contexte naturel\
-   **Multi-niveaux** : individus, dyades, groupes, cultures\
-   **Guidelines méthodologiques** : dictionnaires, échantillonnage, validation, analyse de données textuelles clairsemées

------------------------------------------------------------------------

## Points d’ancrage

-   **Structuraliste** : la langue comme **système** (formes, oppositions, dépendances).\
-   **Pragmatique / usage** : le message comme **action** située (fonctions, actes, effets).\
-   **Distribution / contexte** : le sens comme **relation** (voisinages, collocations, patrons).\
-   **Réseaux de textes** : la signification comme **inscription** sociale (intertextes, paratextes, genres).

**Chaîne d’analyse** : **Structure → Fonction → Contexte → Distribution → Acte → Réseau**.

# De la théorie… à la pratique {.transition-slide-ubdyellow}

## Pré-traitement du corpus

\

### Pourquoi nettoyer les données textuelles ?

-   Les textes bruts (avis, tweets, posts) contiennent du **bruit** : ponctuation, chiffres, emojis, urls…\
-   Le nettoyage améliore la qualité des analyses (fréquences, co-occurrences, modèles).\
-   **Objectif** : obtenir un corpus standardisé, cohérent et exploitable.

------------------------------------------------------------------------

## Pré-traitement : opérations courantes

-   Passage en **minuscules**\
-   Suppression de la **ponctuation / chiffres / urls**\
-   Suppression des **stopwords** (*mots vides* : le, la, de, un…)\
-   **Stemming** : réduire les mots à leur racine (*ex. aimer, aimait → aim*)\
-   **Lemmatisation** : réduire les mots à leur forme canonique (*aimait → aimer*)

::: callout-note
👉 Ces étapes peuvent être adaptées selon la recherche : ne pas trop nettoyer au risque de perdre du sens ou des informations.
:::

------------------------------------------------------------------------

## Tokeniser = découper en tokens (unités) {style="font-size:0.68em"}

Avant toute analyse, on segmente le texte brut en **tokens** (unités). C’est la base de la DTM/BoW, du TF-IDF, des cooccurrences et de la keyness. *(Le POS tagging est vu juste après.)*


:::::: columns
::: {.column width="50%"}
### Le principe : transformer la phrase en « briques »
- **Tokenisation mots** : liste de **mots** et **signes** (ponctuation, hashtags, emojis, mentions).
- Un **token** peut être :
  - un **mot** (*service*, *client*),  
  - de la **ponctuation** (`,` `!`),  
  - un **hashtag** (`#AmazonPrime`),  
  - une **mention** (`@Amazon`),  
  - un **emoji** (`😍`).

### Décisions FR à documenter (avant d’analyser)
- **Apostrophes** : `l’expédition` → `["l'", "expédition"]`, `c’est` → `["c'", "est"]`
- **Négation disjointe** : *ne … pas* → ne pas supprimer **ne**
- **Hashtags/mentions/emojis** : souvent **conserver** (signal thématique/ton)
- **URLs / nombres** : normaliser (`<URL>`, `<NUM>`) si bruit
- **Traits d’union** : *service-après-vente*, *click-and-collect* → garder ou séparer
:::

::: {.column width="50%"}
### Exemple (FR — Amazon) : sortie obtenue (tokenisation)
**Texte :**  
“J’adore le service client d'Amazon, c’est top ! 😍 #AmazonPrime”

**Tokens :**  
`['J’', 'adore', 'le', 'service', 'client', "d'", 'Amazon', ',', 'c’', 'est', 'top', '!', '😍', '#', 'AmazonPrime']`

\
\

::: callout-tip
### Pourquoi c’est la base ?
Sans tokens, on ne peut pas **compter** (fréquences/Zipf), construire **BoW/TF-IDF**, ni comparer avec **keyness**.
:::

``` {.python code-line-numbers="1|2|3|4|5|6"}
import spacy
nlp = spacy.load("fr_core_news_sm")
s = "J’adore le service client d'Amazon, c’est top ! 😍 #AmazonPrime"
doc = nlp(s)
tokens = [t.text for t in doc]
print(tokens)
```

:::
::::::

## Représentation : "Bag-of-Words"

:::::: columns
::: {.column width="30%" style="font-size:0.7em"}
### Le principe

-   Une fois le texte nettoyé, il faut le transformer en chiffres pour que la machine puisse le traiter.
-   Le modèle **"sac de mots" (BoW)** est la méthode la plus simple :
    -   On représente un document uniquement par les mots qu'il contient.
    -   L'**ordre des mots** et la grammaire sont volontairement **ignorés**.
-   Cette approche permet de créer une **Matrice Document-Terme (DTM)**.

![](images/clipboard-534031787.png)
:::

:::: {.column width="70%" style="font-size:0.55em"}
::: {.callout-note title="Exemple de DTM après stopwords FR"}
**Corpus :**

-   D1: "Produit **excellent et** pas cher"
-   D2: "Produit **médiocre et** très cher"
-   D3: "Produit **excellent et** vraiment pas cher"
-   D4: "Produit **médiocre et** assez cher"

**Matrice (DTM) :**

|        | produit | excellent | médiocre | cher | pas | très | vraiment | assez |
|:-------|:-------:|:---------:|:--------:|:----:|:---:|:----:|:--------:|:-----:|
| **D1** |    1    |     1     |    0     |  1   |  1  |  0   |    0     |   0   |
| **D2** |    1    |     0     |    1     |  1   |  0  |  1   |    0     |   0   |
| **D3** |    1    |     1     |    0     |  1   |  1  |  0   |    1     |   0   |
| **D4** |    1    |     0     |    1     |  1   |  0  |  0   |    0     |   1   |

Chaque ligne est un **vecteur** qui représente un document.
:::
::::
::::::

------------------------------------------------------------------------

## Pondération des termes : TF-IDF

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### L'intuition

La fréquence brute (compter les mots) est limitée. Le **TF-IDF** est une pondération plus intelligente qui vise à faire ressortir les mots **spécifiques** d'un document.

-   **TF (Term Frequency)** : poids d'un mot dans **un** document. Un mot fréquent est important *pour ce document*.
-   **IDF (Inverse Document Frequency)** : poids d'un mot dans **tout** le corpus. Un mot présent partout (ex: "le", "produit") est peu informatif, donc son poids est faible.

Un **TF-IDF élevé** signale un mot-clé caractéristique.
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: {.callout-note title="Les formules"}
Pour un terme $t$ dans un document $d$ au sein d'un corpus $D$ :

-   **Fréquence du terme (TF)** : $TF(t,d) = \frac{\text{nombre de fois où } t \text{ apparaît dans } d}{\text{nombre total de mots dans } d}$

-   **Fréquence inverse de document (IDF)** : $IDF(t,D) = \log\left(\frac{\text{nombre total de documents}}{\text{nombre de documents contenant } t}\right)$

-   **Score TF-IDF** : $TFIDF(t,d,D) = TF(t,d) \times IDF(t,D)$
:::
::::
::::::

------------------------------------------------------------------------

## Statistiques lexicales exploratoires

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### "Sentir" le corpus

Avant toute analyse complexe, des indicateurs simples permettent de comprendre la nature des données :

-   **Fréquences de mots** :
    -   Quels sont les termes les plus utilisés (hors *stopwords*) -\> donne une idée des thèmes dominants.
    -   Visualisation : **nuage de mots**.
-   **Hapax Legomena** :
    -   Mots n'apparaissant qu'**une seule fois** dans tout le corpus.
    -   Souvent 30-50% du vocabulaire (selon taille corpus). Ils peuvent être du bruit (fautes de frappe) ou des signaux faibles (jargon émergent).
:::

:::: {.column width="50%" style="font-size:0.75em"}
### Richesse du vocabulaire (TTR, CTTR, MATTR, Maas...)

\

-   **Diversité lexicale (TTR)** :
    -   Mesure la richesse du vocabulaire utilisé dans un texte.
    -   Le *Type-Token Ratio* est le calcul le plus simple.

::: {.callout-note title="Formule du TTR"}
$$ TTR = \frac{\text{Nombre de mots uniques (types)}}{\text{Nombre total de mots (tokens)}} $$ Un TTR proche de 1 indique un vocabulaire très varié ; un TTR faible un langage répétitif.
:::
::::
::::::

------------------------------------------------------------------------

## Approfondir la diversité lexicale

:::::: columns
::: {.column width="55%" style="font-size:0.85em"}
### Au-delà du TTR

Le **Type-Token Ratio (TTR)** est un bon début, mais faiblesse majeure -\> très sensible à la longueur du texte. Un texte plus long aura mécaniquement un TTR plus faible car on est forcé de répéter des mots.

\
 

### Mesures plus robustes

\
\

Pour comparer des textes de longueurs différentes, on utilise des indicateurs plus avancés comme le **MTLD** (Measure of Textual Lexical Diversity).

-   **Principe** : L'algorithme calcule le TTR moyen sur des segments consécutifs du texte, ce qui le rend indépendant de la longueur totale.
:::

:::: {.column width="45%"}
::: {.callout-tip title="Applications en Netnographie" style="font-size:0.9em"}
Analyser la diversité lexicale permet de :

-   **Profiler des auteurs** : un vocabulaire pauvre et répétitif peut être un indice de spams ou de faux avis générés automatiquement.
-   **Caractériser une communauté** : un jargon riche et varié est souvent le signe d'une communauté d'experts ou de passionnés.
-   **Segmenter des retours clients** : les commentaires très riches lexicalement peuvent contenir des insights plus détaillés que les commentaires laconiques.
:::
::::
::::::

------------------------------------------------------------------------

## Mesurer la lisibilité du texte (Readability)

La lisibilité mesure la **facilité de lecture et de compréhension** d'un texte. Elle ne dépend pas seulement de la richesse du vocabulaire, mais aussi de la complexité syntaxique.

:::::: columns
::: {.column width="50%" style="font-size:0.85em"}
### Les deux piliers de la complexité

La plupart des scores de lisibilité se basent sur deux variables simples :

1.  **Complexité sémantique** : longueur des mots (en syllabes ou en caractères). Des mots longs sont considérés comme plus difficiles.
2.  **Complexité syntaxique** : longueur des phrases (en nombre de mots). Des phrases longues sont plus complexes à analyser pour le lecteur.

Le score le plus célèbre en anglais est le **Flesch-Kincaid Reading Ease**.
:::

:::: {.column width="50%" style="font-size:0.75em"}
::: {.callout-note title="Scores & Applications" style="font-size:0.75em"}
#### Formule générale

La plupart des scores suivent une logique de ce type : $Score = A - (B \times \frac{\text{mots}}{\text{phrase}}) - (C \times \frac{\text{syllabes}}{\text{mot}})$

#### Utilité en marketing

-   **Auditer le contenu de marque** : le langage utilisé sur un site web ou les réseaux sociaux est-il adapté à la cible ? Est-il trop simple ? Trop jargonnant ?
-   **Analyser l'audience** : le niveau de langage des consommateurs dans leurs avis peut-il révéler leur niveau d'expertise ?
:::
::::
::::::

------------------------------------------------------------------------

## Lisibilité en français : les outils spécifiques

::::::: columns
:::: {.column width="55%" style="font-size:0.85em"}
### Kandel & Moles : l'adaptation de Flesch

C'est la formule historique (1958) et la plus directe pour le français. Le principe est le même que pour l'anglais : combiner la longueur des mots et des phrases.

-   **Score de 0 à 100** :
    -   **Score élevé (\> 70)** : texte facile à lire.
    -   **Score bas (\< 40)** : texte difficile (technique, académique).

::: {.callout-note title="La formule pour le français" style="font-size:0.60em"}
Le score est calculé ainsi :

$Score = 207 - (1.015 \times \text{longueur moyenne des phrases})$ $- (73.6 \times \text{nombre moyen de syllabes par mot})$
:::
::::

:::: {.column width="45%" style="font-size:0.70em"}
### Alternative et pratique moderne

-   **Indice de Gunning Fog** :
    -   Une autre approche qui se base sur le pourcentage de **"mots complexes"** (généralement 3 syllabes ou plus).
    -   Le score estime le **nombre d'années d'études** nécessaires pour comprendre le texte.
-   **Outils NLP actuels** :
    -   Aujourd'hui, on utilise des bibliothèques Python pour faire ces calculs.
    -   **`pyphen`** : pour compter les syllabes en français.
    -   **`textstat`** : pour calculer directement les scores de lisibilité.\
    -   En **R** : les packages comme `quanteda` ou `koRpus` offrent aussi ces fonctionnalités.

::: {.callout-tip title="A retenir" style="font-size:1em"}
Le principe reste le même : un texte simple = mots courts + phrases courtes. Les formules pour le français ne font que calibrer cette idée aux particularités statistiques de notre langue.
:::
::::
:::::::

------------------------------------------------------------------------

## Analyse de co-occurrences et collocations

:::::: columns
::: {.column width="55%"}
### Le sens par l'association

On dépasse le "sac de mots" pour analyser **quels mots apparaissent ensemble**.

-   **Co-occurrence** : deux mots qui apparaissent fréquemment dans un même contexte (ex: phrase, fenêtre de 5 mots).
    -   Permet de créer des **graphes de mots** pour visualiser les clusters thématiques.
-   **Collocation** : une co-occurrence si forte qu'elle forme une expression presque figée.
    -   Ex: "service client", "rapport qualité-prix".
:::

:::: {.column width="45%"}
::: {.callout-important title="Mesurer la force d'association" style="font-size:0.9em"}
On peut quantifier si une co-occurrence est due au hasard ou à un lien sémantique fort. Le **Pointwise Mutual Information (PMI)** est une mesure courante.

$PMI(x,y) = \log_2\left(\frac{P(x,y)}{P(x)P(y)}\right)$

-   $P(x,y)$ : probabilité de voir x et y ensemble.
-   $P(x)P(y)$ : probabilité de les voir ensemble si leur apparition était indépendante.

Un PMI élevé suggère un lien sémantique fort.
:::
::::
::::::

------------------------------------------------------------------------

## Analyse de "Keyness" (mots-clés) 1/3

:::::: columns
::: {.column width="60%"}
### Qu'est-ce qui différencie deux discours ?

-   La **Keyness** identifie les mots **statistiquement sur-représentés** dans un corpus A par rapport à un corpus de référence B.
-   C'est une méthode puissante pour **caractériser et comparer** des ensembles de textes.
-   **Applications** :
    -   Avis 5★ vs 1★ : Quels mots sont "clés" pour les clients satisfaits ?
    -   Tweets avant vs après une crise : quel vocabulaire a émergé ?
    -   Articles de presse : comparer le lexique Sports masculins vs féminins
:::

:::: {.column width="40%"}
::: {.callout-note title="Principe statistique" style="font-size:0.7em"}
Pour chaque mot, on construit un tableau de contingence :

|                       | **Corpus A (cible)** | **Corpus B (réf.)** |
|:----------------------|:--------------------:|:-------------------:|
| **Freq. mot X**       |          a           |          b          |
| **Freq. autres mots** |          c           |          d          |

Tests possibles :\
- $\chi^2$ : intuitif mais sensible aux faibles effectifs.\
- **Log-Likelihood** $G^2$ : plus robuste, devenu la référence (ex. *AntConc*, `quanteda`).
:::
::::
::::::

## Analyse de "Keyness" (mots-clés) 2/3

::::: columns
::: {.column width="50%"}
### Pipeline méthodologique [@raoGenderBiasNews2021]

1.  **Collecte des articles** de presse canadienne (2018–2020)\
2.  **NER** : extraction des **noms et prénoms des personnes citées**\
3.  **Coreference resolution** : associer les **citations** au bon locuteur\
4.  **Attribution du genre** :
    -   via une base interne de personnalités publiques\
    -   **OU** (si non trouvé) via une API (prénom ou nom complet)\
:::

::: {.column width="50%"}
### Suite du pipeline

\

5.  **Classification des articles** :
    -   *Male corpus* = majorité d’hommes cités\
    -   *Female corpus* = majorité de femmes citées
6.  **Analyses linguistiques** :
    -   *Topic modelling* (LDA) → thèmes\
    -   **Keyness → mots sur-représentés** dans chaque corpus\
    -   *Dependency bigrams* → style de discours\
:::
:::::

## Analyse de "Keyness" (mots-clés) 3/3 {style="font-size:0.75em"}

![](images/clipboard-2048161018.png){fig-align="center" width="80%"}

::::: columns
::: {.column width="50%"}
### Corpus masculin

-   Bigrams fréquents : *lead_give, run_allow, pass_complete, homer_hit…*\
-   Mots clés : *touchdown, quarterback, Mariners…*\
-   Discours → centré sur **le déroulement technique des matchs**.
:::

::: {.column width="50%"}
### Corpus féminin

-   Bigrams fréquents : *gold_win, medal_win, record_set, cup_win…*\
-   Mots clés : *Rapinoe, Sinclair, FIFA, Wozniacki…*\
-   Discours → centré sur **les victoires, les records et les sportives emblématiques**.
:::
:::::

👉 Conclusion : la presse **décrit les hommes en action**, mais ne parle des femmes **que lorsqu’elles gagnent**.

------------------------------------------------------------------------

## Annotation morphosyntaxique (POS Tagging) {style="font-size:0.85em"}

L’étiquetage morphosyntaxique (POS Tagging) attribue à chaque mot sa **catégorie grammaticale** (DET, NOUN, VERB/AUX, ADJ, ADV, …) et, selon les outils, des **traits morphologiques** (Genre, Nombre, Temps, etc.).

<u>Le</u>/[DET]{.bg style="--col: #325494"} <u>produit</u>/[NOUN]{.bg style="--col: #58DDB3"} <u>est</u>/[AUX]{.bg style="--col: #B10F2E"} <u>vraiment</u>/[ADV]{.bg style="--col: #999999"} <u>excellent</u>/[ADJ]{.bg style="--col: #F5C946"}

:::::: columns
::: {.column width="50%" style="font-size:0.8em"}
### À quoi ça sert ?

- **Filtrer l’information** :
  - Extraire les **adjectifs** pour analyser les qualificatifs d’un produit.
  - Isoler les **noms propres** pour détecter les entités.
- **Préparer le traitement** :
  - Indispensable pour une **lemmatisation** fiable (*port* → *porter* vs *port*).
  - Utile pour la **stemmatisation** (*jouer*, *jouait*, *jouera* → *jou*).
:::

:::: {.column width="50%"}
::: {.callout-note title="Le standard Universal Dependencies" style="font-size:0.9em"}
- **UPOS** : étiquettes universelles (DET, NOUN, VERB, **AUX**, ADJ, ADV, …)  
- **XPOS** : étiquettes spécifiques à la langue (optionnel)  
- **FEATS** : traits (ex. Gender=Masc, Number=Sing, Tense=Pres, Mood=Ind)

Outils compatibles : **spaCy**, **Stanza/Trankit**, **UDPipe**.
:::
::::
::::::


## Analyse en dépendances syntaxiques (Dependency Parsing) 1/3

L’**analyse en dépendances syntaxiques** est une étape du traitement automatique du langage naturel (TALN) qui vise à représenter la structure d’une phrase à partir des **relations de dépendance entre mots**.\
Elle est généralement formalisée sous forme de **graphes orientés** (souvent en arbres), où :

-   les **nœuds** correspondent aux mots (*tokens*),\
-   les **arcs** représentent les relations syntaxiques (par ex. *nsubj* = sujet, *obj* = objet, *det* = déterminant).

------------------------------------------------------------------------

## Analyse en dépendances syntaxiques (Dependency Parsing) 2/3

Cette approche permet d’identifier qui fait quoi dans une phrase et de modéliser des structures grammaticales complexes.\
Elle est largement utilisée dans des applications comme :

-   l’**extraction d’information** (entités et relations),\
-   le **résumé automatique** et la **recherche d’information**,\
-   l’**analyse des discours** sur les réseaux sociaux.

Un cadre de référence majeur pour cette tâche est le projet [**Universal Dependencies**](https://universaldependencies.org), qui propose des annotations cohérentes pour de nombreuses langues.

------------------------------------------------------------------------

## Analyse en dépendances syntaxiques (Dependency Parsing) 3/3

![](images/clipboard-2484643215.png)

------------------------------------------------------------------------

## Exemple code (modèle anglais)

[**Voir l’exemple de code ici**](https://oliviercaron.github.io/systematic_lit_review/annotations.html#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing)

[![Exemple de code udpipe](images/clipboard-3249784408.png)](https://oliviercaron.github.io/systematic_lit_review/annotations.html#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing)

------------------------------------------------------------------------

## Reconnaissance d'Entités Nommées (NER)

:::::: columns
::: {.column width="55%" style="font-size:0.75em"}
### Identifier le "de qui / de quoi"

La **NER (Named Entity Recognition)** détecte et classe automatiquement les **entités du monde réel** mentionnées dans un texte.

\
\

-   [PER]{.bg style="--col: #325494"} : Personnes\
-   [ORG]{.bg style="--col: #58DDB3"} : Organisations (marques, entreprises)\
-   [LOC]{.bg style="--col: #F5C946"} : Lieux (villes, pays)\
-   [DATE]{.bg style="--col: #B10F2E"} : Dates, heures\
-   [MISC]{.bg style="--col: #8A2BE2"} : Divers (produits, événements...) voir [GliNER](https://github.com/urchade/GLiNER) aux prochains cours

\
\
:::

:::: {.column width="45%"}
::: {.callout-tip title="Applications en netnographie"}
Quelques idées :

-   **Veille concurrentielle** : lister automatiquement les marques concurrentes (ORG) citées.
-   **Détection d'influenceurs** : repérer les personnes (PER) qui animent les conversations.
-   **Analyse géo-localisée** : identifier les lieux (LOC) où se concentrent les discussions.
-   **Tracking produits** : repérer les références spécifiques (MISC) dans les conversations.
:::
::::

<u>[Jean Dupont]{.bg style="--col: #325494"}</u> travaille chez <u>[Google]{.bg style="--col: #58DDB3"}</u> à <u>[Paris]{.bg style="--col: #F5C946"}</u> depuis <u>[2023]{.bg style="--col: #B10F2E"}</u>.
::::::

------------------------------------------------------------------------

## Gestion des variations : fuzzy matching

:::::: columns
::: {.column width="55%"}
### Gérer le "bruit" textuel

Les textes web sont pleins de **variations** : fautes de frappe, accents manquants, abréviations.

-   Le **fuzzy matching** (correspondance approximative) regroupe des chaînes de caractères similaires.
-   La **Distance de Levenshtein** (ou distance d'édition) est la méthode la plus connue.
    -   Elle calcule le **nombre minimal d'opérations** (insertion, suppression, substitution) pour passer d'un mot à un autre.
:::

:::: {.column width="45%"}
::: {.callout-important title="Exemple concret" style="font-size:0.8em"}
Comment regrouper les mentions d'une marque ?

-   `"Decathlon"`
-   `"Décathlon"`
-   `"decathalon"`
-   `"décahlon"`

```{r}
library(stringdist)

s1 <- "Décathlon"
s2 <- "decathalon"

distance <- stringdist(s1, s2, method = "lv")
cat("Distance de Levenshtein entre", s1, "et", s2, "=", distance)

```

La distance de Levenshtein entre `"Décathlon"` et `"decathalon"` est de **3** (D→d, é→e, + insertion de "a").

En fixant un seuil de distance faible (ex: ≤ 2), on peut automatiquement considérer que ces variantes désignent la **même entité**. C'est essentiel pour fiabiliser les comptages.
:::
::::
::::::

## Conclusion

-   Le **texte** est devenu une matière première massive.\
-   Le NLP/TAL permet :
    -   De nouveaux terrains (avis, réseaux sociaux, forums).\
    -   De nouvelles méthodes (analyse lexicale, syntaxique, sémantique, pragmatique).\
    -   De nouveaux objets (discours de marque, avis, interactions).

::: callout-tip
### Langage
👉 Pour le marketing digital et la netnographie : comprendre que **le langage est à la fois structure, sens et action**.
:::

## Références