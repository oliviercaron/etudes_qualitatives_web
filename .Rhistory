library(tidyverse)
library(rvest)
# Define the URLs of the pages to scrape
urls <- c("https://akadeus.com/announcements?q=marketing",
"https://akadeus.com/announcements?q=computational+social+science")
# Function to scrape job offers
scrape_jobs <- function(url) {
page <- read_html(url)
html_nodes(page, xpath = "(//*[contains(@class, 'xx-12')])[3]//a") %>%
map_df(~{
offer <- .x
# Attempt to extract each piece of information, handling missing values
title <- tryCatch(str_squish(html_text(html_node(offer, "h2"))), error = function(e) NA)
employment_type <- tryCatch(str_squish(gsub(".*:", "", html_text(html_node(offer, ".params div:nth-child(3) p")))), error = function(e) NA)
location <- tryCatch(str_squish(gsub(".*:", "", html_text(html_node(offer, ".params div:nth-child(2) p")))), error = function(e) NA)
posted_date <- tryCatch(str_squish(gsub(".*:", "", html_text(html_node(offer, ".params div:nth-child(4) p")))), error = function(e) NA)
url <- tryCatch(str_squish(paste0("https://www.akadeus.com", html_attr(offer, "href"))), error = function(e) NA)
data.frame(
title = title,
employment_type = employment_type,
location = location,
posted_date = posted_date,
url = url
)
})
}
### Get the job description of each job
# Scrape all URLs
all_jobs <- map_df(urls, scrape_jobs)
# Remove duplicates
all_jobs <- all_jobs %>%
distinct(title, employment_type, location, posted_date, url, .keep_all = TRUE)
# Function to scrape job details
scrape_job_details <- function(job_url) {
job_page <- read_html(job_url)
list(
field = tryCatch(str_squish(str_remove(html_text(html_nodes(job_page, xpath = "//div[contains(@class, 'box-3')]/div[p/span[contains(text(), 'Discipline:')]]/p")), "Discipline:")), error = function(e) NA),
company = tryCatch(str_squish(str_remove(html_text(html_nodes(job_page, xpath = "//div[contains(@class, 'box-3')]/div[p/span[contains(text(), 'Company:')]]/p")), "Company:")), error = function(e) NA),
description_text = tryCatch(str_squish(html_text(html_nodes(job_page, "#description"))), error = function(e) NA)
)
}
# Get additional details for each job
additional_details_df <- map_df(all_jobs$url, ~{
details <- scrape_job_details(.x)
data.frame(
field = ifelse(is.na(details$field), "", details$field),
company = ifelse(is.na(details$company), "", details$company),
description_text = ifelse(is.na(details$description_text), "", details$description_text),
stringsAsFactors = FALSE
)
})
# Combine the additional details with 'all_jobs'
all_jobs <- bind_cols(all_jobs, additional_details_df)
# Save results
filename <- paste0("data/akadeus_jobs-", Sys.Date(), ".rds")
saveRDS(all_jobs, filename)
View(additional_details_df)
View(all_jobs)
